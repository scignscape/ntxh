\documentclass{article}

\input{ngml/ngml-setup-commands}
\input{ngml/ngml-sdi-commands}
\input{ngml/ngml-deco-commands}

\AtEndDocument{\immediate\write18{cd /home/nlevisrael/gits/ntxh/wip-sebi/ar/code/cpp/qmake-console/projects/gtagml/ngml-sdi-console; ./run-with-args.sh /home/nlevisrael/gits/ntxh/wip-sebi/ar/dev/consoles/gtagml/sdi/t1 (3rd copy)/t1 (3rd copy).gt.tex /home/nlevisrael/gits/ntxh/wip-sebi/ar/dev/consoles/gtagml/sdi/t1 (3rd copy)/t1 (3rd copy).gt.sdi.ntxh /home/nlevisrael/gits/ntxh/wip-sebi/ar/dev/consoles/gtagml/sdi/t1 (3rd copy)/t1 (3rd copy).gt.sdi-prelatex.ntxh; cd -;}}




\p{The question of whether computers can be programmed to understand
language may be philosophical, but it overlaps with
broad methodological bifurcations: after all, linguists
\i{are} programming computers to \q{understand} language, at
least to some approximation.  Given that computational
linguistics is now a well-established practice, we can
consider how this program for investigating the nature of
language orients into linguistics as a whole: to what degree
are the computers really \q{understanding} their linguistic
input?  How much does \i{behavior} consistent with language-understanding
suggest actual understanding?  Is linguistic competence mostly a
behavioral phenomenon, or something more holistic and (inter-) subjective?
Are the imperfections of automated Natural Language Processing
inevitable, and if so, does that foreclose the possibility of
\NLP{} engines being considered truly linguistic?  That is,
should we treat flawed and oversimplistic (but practically useful)
\NLP{} software \ndash{} or \q{personas} driven by this software, like
\q{digital assistants} \ndash{} as bonafide (if rather primitive)
participants in the world of human language?  Or are they merely
machines that simulate linguistic behavior without manifesting
real linguistic behavior, as a computer simulation of a
celestial galaxy is not a real galaxy?
}

\p{These are methodological as well as thematic questions.  There is a
wide swath of formal and computational linguistics, for instance, for
which the measure of a theory is its chance of being operationalized
on \NLP{} terms and within \NLP{} tools, yielding automated systems whose accuracy and/or
computational efficiency competes favorably with other systems.
Faithfulness to how \i{humans} process language is at most a secondary
concern.  Conversely, there is a broad literature in Cognitive Linguistics
and the Philosophy of Language for which uncovering the cognitive and
interpretive registers through which \i{we} understand, produce, and
are affected by language is the main goal.  For scholars chasing
that telos, failure to encode theoretical models in mathematical
or software systems is not \i{prima facie} an explanatory limitation
\ndash{} conversely, we might take this as evidence that cognitive models
are addressing the deep, subtle realities of language that are
opaque to computer simulation.
}

\p{Then there is hybrid work, like attempts to formalize
Cognitive Grammar (Matt Selway \cite{MattSelway},
Kenneth Holmqvist \cite{KennethHolmqvist}, \cite{HolmqvistDiss}), or
other branches of Cognitive Linguistics
(cf. Terry Regier's influential \cite{TerryRegier}),
or Conceptual Space Theory as initiated by
Peter \Gardenfors{} (which has seen several attempts at
mathematical-computational formalization, such as
Frank Zenker, Martin Raubal, and Benjamin Adams's
metascientific perspectives \cite{RaubalAdams},
\cite{RaubalAdamsCSML}, \cite{Zenker}, and more recent
Category-Theoretic structures linked to mathematicians
such as Bob Coecke and David Spivak \cite{InteractingConceptualSpaces}).
To this list we could add research that extends beyond
language alone to broader cognitive-perceptual and
conceptual themes, like formal descriptions rooted in
Husserlian analyses by phenomenologists whose methods
encompass some computer-scientific techniques, like
Barry Smith (as in \cite{BittnerSmithDonnelly}) and
Jean Petitot (see \cite{JeanPetitot}); we can see
these accounts as generalizing cognitive-linguistic
theories by noting the phenomenological basis
of linguistic phenomena, as articulated by (say) Olav
K. Wiegand (\cite{OlavKWiegand}, \cite{WiegandGestalts})
and Jordan Zlatev (\cite{JordanZlatev}).
In each of the works just cited (prior anyhow to the
last three)
we can find formal/computational models whose
rationale is, in large part, to
shed light on human cognitive processes
(albeit not necessarily translating to practical
\NLP{} components in any straightforward way).
}
