`section.Linguistic Structure and the Accretion of Detail`
`p.
As I see it, the primary task for linguistic analysis 
is to document how linguistic constructions 
signify propositional content.  The centrality of 
`i.cognitive` linguistics, and cognitive grammar, 
derives from observing how constructions do 
not in the general case just `q.transparently` or 
`q.passively` connote predicate structures, 
the way that `AdjN; patterns mechanically 
call up predicate-subject predications.  
Instead of recapitulating predicate structure 
directly, language structure reflects 
propositional or `i.interpretive` attitudes, 
narrative, causative, or integrative 
interpretations which convey how 
speakers track and convey situations.  
In short, rather than seeing linguistic 
structure as a passive vehicle for 
rendering logically-ordered ideas, 
we should treat linguistic performances 
as dynamic processes which `i.build up 
to` propositional contents, manifesting 
evolutive principles which (often 
subconsciously) depend on speakers' 
situational immersion as well as 
abstractic syntactic and semantic conventions.   
`p`

`p.
This perspective summarizes my thematic or 
philosophical motivation for the specific 
formalizing approach I take here 
with respect to Cognitive Grammar.  
My goal, as cited earlier, is to develop 
formal models which would be 
recognized as structural variations on 
popular representations in 
formal linguistics %-- dependency grammar, 
constituency grammar, categorial 
grammar, type-theoretic semantics 
%-- while also being faithful to 
the cognitive-grammatic perspective.  
In particular, the structural parameters 
exposed by formal models %-- e.g., 
phrase boundaries or inter-word 
relations %-- should as much as possible have cognitive-grammatic 
interpretations, referring to central notions such as 
cognitive schema, conceptualization, 
and landmark/trajector configurations. 
`p`

`p.
Aside from philosophy, I also have more mundane 
considerations: to properly situate 
cognitive grammar in an overall linguistic 
contexts, it helps to have an intermediate perspective 
which allows the contrasting priorities, methodologies, 
or scientific commitments of cognitive grammar 
alongside other linguistic `q.schools` to be 
assessed together.  One important paradigmatic 
area of contention, I think, is that cognitive 
grammar appears to de-emphasize the logical 
substratum of semantics which, on other 
perspectives, is the central artery of 
language itself.  There is a nontrivial core 
of language within which propositional content 
is encoded in linguistic constructions 
following entrenched rules.  Within `i.this core`/, 
language acts like a sort of `q.meta-logical` 
system: not something logically structured 
%-- in the formal sense of predicate 
(plus maybe modal, temporal, epistemic, etc.) logic 
%-- in itself, but a system whose structural 
principles can be shown to communicate 
logical structures under suitable 
substitutions and transformations.  
Cognitive grammar should indeed accommodate 
these cases; but I think they are neither 
predominant nor prototypical in language 
as a whole, so they should not be reified as a 
the canonical filter for distinguishing semantics 
proper from pragmatics (or from theories 
of extra-linguistic reasoning).   
`p`

`p.
This implies that while linguistic constructions 
encode propositional content, we need a 
detailed (and cognitively `q.active`/) 
theory of how, in formulating and understanding 
linguistic performances, we map constructions to 
their correlative propostions.  
Constructions are not in the general case 
direct `q.wrappers` for a given propositional
arrangement %-- like `AdjN; for predicate-subject; 
instead we have to analyze the internal structure 
of constructions to elucidate how they contribute 
to an overarching communication for rational content.    
`p`

`p.
This interpretation for the rationale behind 
constructional analysis moreover helps 
us posit a cognitive grounding for 
our choice of linguistic representation.  
The frameworks through which language structures 
are described are typically oriented around 
grammatic (and by extension semantic) rules 
%-- insofar as one takes phrases (a mid-level 
scale intermediate between words and sentences) 
as a structural primitive, for example, then 
phrase-descriptions serve the representational 
purpose of delineating what makes valid 
phrases well-formed.  Conversely, if 
we take inter-word relations as the focal 
structural primitive, sentences are well-formed 
if they have a coherent collection of 
such relationships.  More to the point, 
we want to explain `i.why` sentences are 
(felt as) well-formed.  With a focus on 
phrase-structure, we can explain well-formdeness 
in terms of how phrases are nested together.  For 
example, we can say that subphrases have some
singular synopsis which allows them to play some 
expected structural role in a larger phrase 
%-- a verb-phrase standing in for a verb, say.  
Or, in terms of inter-word relations, we 
can identify the structure within a sentence such 
that each word is integrated into the whole 
%-- i.e., each word has relations to some other 
word, with the overall chain of connections spanning the full 
sentence %-- and moreover the sentence 
possesses specific relations (such as a verb to a subject) 
marking that the sentence conveys a complete idea. 
`p`

`p.
Thematically, a linguistic representation is, 
in effect, both a theoretical posit and a 
presentational or pedagogical device illustrating 
a theory.  By `q.linguistic representation` I 
mean specifically, in this context, a 
digram or otherwise annotated rendering of a sentence 
which permits explanatory elements to be 
interspersed among the words, such as 
lines or curves connecting or encircling 
groups of words, as well as testual notations 
such as Part of Speech labels.  The point 
of these visual displays is to convey, 
in effect, a `i.data structure` which supplements 
to original sentence with extra 
theoretically-motivated content, such as 
Parts of Speech associated with individual 
words, relational labels associated with 
word-pairs, and set-constructions on words 
representing phrases.  Such a data structure 
summarizes an account of why the sentence 
is valid, and carries the meaning it does, 
in terms of a grammar and semantics whose 
principles are laid out by the relevant theory: 
so the presence of a labeled word-pair, 
in the context of dependency grammar, 
embodies a theoretical commitment to 
some collection of interword relation-types 
as the backbone of grammar.  That is, 
the theoretical explanation for why grammar 
works as it does in some particular 
sentence can be summarized by visually 
restaging the sentence as a connected 
network %-- that is, a `i.labeled graph`/, 
with Part of Speech labels on words 
and/or `q.dependency` labels (in the sense 
of `q.Universal Depencies` for 
multi-lingual dependency grammar) on 
graph-edges.
`p`

`p.
Such diagrammatic presentations are therefore at 
one level proxies for lengthier textual analyses 
of a sentence's grammatic operation, as some 
theory sees it.  However, in addition to 
this expository role, interword or phrasal 
data structures are `i.posits` of the theory in 
the sense that for each sentence there is 
deemed to be at least one (typically one optimal) 
data structure which captures the sentence's 
functional propriety; how it functions as a 
correct embodiment of the language system. 
To the extent that a sentence has one 
clear meaning, then a systematic linguistic 
theory will generally hold that there is 
one clear mechanism `i.through which` 
the sentence has that meaning.  This 
is not to deny that people may process the 
same sentence a little differently, 
but %-- excluding cases of actual ambiguity or 
obfuscation %-- each person's 
conceptualization of a sentence will be 
similar enough that differences in 
reception (at least among competent speakers) 
can be ignored.
`p`

`p.
In that case, we can not only posit that 
the meaning of `i.the neighbors dogs were 
barking` (spoken in a `q.normal` context) 
is necessarily to report on the vocalizations 
of some canines, but we are permitted to 
assume a necessary marshaling of 
syntactic and semantic processing to 
explain `i.why` every competent speaker 
would read that propositional content into 
that sentence.  So for each sentence there is a 
canonical processing, a structural or processual 
organization which inheres in the sentence as an 
objective feature of how it functions as a 
valid exercise of the language system, no less 
intrinsic than its meaning.  The 
`q.data structures` which annotate sentence are 
implicitly, then, I would argue, targeting 
this processual reification: they are a way of 
putting theoretical flesh on the underlying 
hypothesis that sentences acquire their meaning 
through processually conventionalized routes.  
`p`

`p.
For sake of discussion, I will refer to any 
schematic reconstruction of a sentence 
(or potentially a larger or smaller linguistic 
unit) as a `q.processual data structure`/, 
meaning some formal model representing 
the process through which language 
artifacts acquire their meaning (which in 
turn can be associated with some propositional 
content).  By `i.data structure` I mean 
that for a given sentence we can posit 
a larger structure composed of explanatory 
parameters which document how a given 
syntactic or semantic principle is manifest 
in a given word's, interword-relation's, or 
phrase's functioning within the sentence.  
Alongside phrases, relations, and parts of 
speech %-- that is, these being elements 
of processual data structures which 
attach to words individually or collectively 
%-- parameters can include morphological 
`q.tags` asserted on words (indicating that 
the word is presented in a manner signifying 
case or tense, say); links between words and 
a lexicon; and indications of details such as vocal stress 
patterns, disfluency, intonation, and other performative givens 
which can affect a sentence's meaning even if they are 
not normally treated as part of syntax or semantics.
`p`

`p.
Different theories will recognize a different inventory 
of relevant parameters (although a notation may refer 
in ad-hoc ways to details which other theories would represent 
more formally; e.g., words may be boldfaced or capitalized 
to indicate vocal emphasis, even if the relevant theory 
does not usually consider speech patterns).  We can 
therefore adopt a rather abstract, metatheoretical 
perspective by considering which theoretical 
parameters are internally utilized by which theories.  
For their central analysis, for example, theories 
may include only phrase-structures, only interword relations, 
or both; they may include only words as the 
canonical lexical elements or admit certain smaller-scale 
units, like `q.'s` for possessives; they may or may not 
pair stuctural re-presentations of sentences with 
structurally annotated lexicons, where for example an 
identifier code associated with a word in (what I am 
calling) a processual data structure matches the 
word to a lexical entry.  Representational paradigms 
can also differ in how they handle (if at all) 
various communicative units which are not usually 
lexified, such as proper-name acronyms, punctuation, 
interwoven dialog (where a pause or interruption 
at a certain point may be deemed semiotically 
relevant), or speech effects in general.     
`p`

`p.
As I have already suggested, my goal here is to 
propose a formal model which is appropriate 
for cognitive grammar %-- mostly preserving 
the philosophical commitments of key figures 
such as Langacker and Talmy (at least as a goal) 
and yielding representations which help 
to document cognitive activity sited in linguistic 
formations.  Ideally, insofar as cognitive grammar 
would give a particular treatment for a sentence 
%-- focusing on a landmark/trajector configuration, 
let's say %-- the `q.processual data structure` 
used to encapsulate such analysis would 
comprise parameters which thematically notate 
components in the cognitive-grammatic treatment 
and diagram how they relate to particular 
words (or word-pairs or phrases).  
`p`

`p.
Minimally, my proposed repesentations are 
derived from Dependency Grammar in that 
interword relations are taken as the crucial 
theoretical construct (more so than phrases).  
As a result, the `q.processual data structure` 
associated with any sentence can be seen 
as a directed, labeled graph, or 
`q.parse graph`/, with words represented as 
graph nodes.  (I will generally 
argue against isolating non-word lexical 
elements, so e.g. a possessive like 
`i.Warren's` is treated as one node, not two).  
Nodes are then labeled with grammatical 
categories, and edges between nodes labeled 
with notations suggesting the kind 
of relationship obtaining between the incident nodes. 
`p`

`p.
My system of node and edge labels is also influenced 
by categorial grammar; in particular, I adopt the conventional 
that certain grammatic categories are derived from 
other categories.  Insofar as words from one category 
are used in conjunction with a word from another 
category, resulting in a phrase or transoformation 
assignable to a third category (potentially the 
same as the second), the first category is 
derivative on the latter two.  The adjective 
category is derivative on `i.noun` because 
adjectives are modifiers which trigger some 
reconceptualizing of a noun-idea, resulting in 
a new, or at least altered, noun (technically 
perhaps a noun phrase but conceptually a noun).  
Or, consider a preposition like `i.toward`/, 
which combines with a noun to produce a 
form of adverb (a locative designation which 
modifies a verb, as in `i.walk toward the store`/).  
Here the categorial ascription for 
`i.toward` is derived from the `i.noun` and `i.adverb` 
(in a fixed order: `i.toward` conceptually 
transforms a noun `i.to` an adverb).  
`p`

`p.
In general, for a pair of grammatic categories 
(not necessarily distinct) there is a potential 
additional category profiling conceptual 
transitions which produce an instance of 
the second category in the presence of the 
first.  To use more mathematical language, 
the derived category profiles transformations 
which `i.input` the first category and 
`i.output` the second.  This construction is 
similar to the maxim in mathematical type theory 
that functions between two types constitute a 
third type, or in computational type theory 
that procedures with respective tuples of 
input and output types dervice a further type. 
`p`

`p.
A common framework holds that the essential 
linguistic types %-- or grammatic categories 
%-- are `i.nouns` and `i.propositions`/; 
I use the latter term for sentences as well 
as clauses, contained within sentences, that 
embody a complete propositional idea.  All further 
categories can then be derived as `q.transformations` 
that take inputs and produce outputs from these 
core categories, or prior derived categories 
recursively.  In particular, verbs profile 
transformations that produce propositions from nouns.  
In Categorial Combinary Grammar, a verb can 
be characterized via notation like `NSlashP;, 
meaning that a verb (phrase) combines with a noun (phrase)  
`i.preceding` the verb to yield a proposition, e.g., 
a complete sentence: `i.the dogs barked`/.  
This representation would also distinguish combinations 
by word order (the modifier preceding or following 
the modified, or `q.target`/; the two forms of 
sequence marked by using either back or forward 
slashes).  Here I abstract from word-order and use 
an arrow, borrowing from type theory, to represent 
either back or forward slash: so the idea that a 
verb expects a noun to form a proposition would be 
written `VNounToProp; (this notation will be further 
clarified below).    
`p`

`p.
Here I will sketch a framework that combines the 
basic intuitions of categorial and dependency 
grammars: a word whose categorization belongs 
to a derived category serves to transform or 
modify some `q.target` word; this in turn can 
be modeled as a relation `i.between` the modifier and 
the target, and the `q.graph` of these relations 
forms the core of a parse graph.  At the 
same time, I will suggest conceptual interpretation 
of relationships; I do not picture formal models 
as merely observing grammatic `q.behaviors` 
(cf. Langacker Intro p. 93).  The idea that 
adjectives transform nouns into `q.other nouns` 
can be given a strictly behavioral gloss by 
reading it as a structural condition: when occurring 
in well-formed sentences, an adjective links to a noun 
(or noun-phrase) to produce a noun-phrase that substitutes for 
a nominal lexeme in larger phrases.  So for any adjective 
we can `i.find` the noun it modifies and find how the 
resulting phrase is used as a noun in some larger phrase 
%-- the fact that this `q.search` resolves successfully 
is mandated by sentence validity, and failure to 
find the requiste context for the adjective 
is a signal that the enclosing sentence is not, 
in fact, well-formed.   
`p`

`p.
In contrast to a purely behavioral description, however, 
we can interpret these same phenomena conceptually.  
Once we encounter a lexeme which appears adjectival, 
we `i.conceptually` expect to find a noun which it 
modifies.  We cannot conceive `i.black`/, say, 
apart from some object whose surface or appearance 
is black.  Assuming that a sentence originates from a 
speaker's rational and honestly-portrayed interaction 
within a situation, the speaker would have no reason 
to enunciate `i.black` without cognizing the color, 
and therefore cognizing a predicated object.  
Likewise for any other adjective; in this 
sense adjectives create conceptual expectations that 
window onto speakers' rational construals of situations.  
Sentences fulfill expectations by presenting words 
or phrases that complete ideas that seem to have been 
left open by the previously spoken (or written) sentence-fragment.  
`p`

`p.
Sometimes expectations refer backward, as often in 
personal pronouns (`i.I invited John, but he's on vacation`/) 
%-- we expect `i.he` or `i.she` to proxy a referent priorly 
established in the discourse, maybe the sentence.  
In the more general case though they refer forward, 
so we can say that the presence of lexemes from 
`q.derivative` grammatic categories creates an 
expection of a conceptual completion that is then 
satisfied by a subsequently occurring word or phrase.  
Sentences are grammatically correct, then, insofar 
as they `i.do` resolve their midstream expectations.  
Grammatical behavior %-- e.g. that adjectives must be 
followed by nouns %-- is therefore not forced 
to be a theoretical primitive, but instead can be 
analyzed as the conventionalization of conceptual 
expectations and resolutions.  Language, on this 
perspective, reveals certain recurring patterns on 
how expectations are created and then fulfilled; 
when sufficiently entrenched as well-formedness 
criteria, these patterns `i.become` grammatical behavior.  
`p`

`p.
When expectations are left unresolved, we may not 
necessarily experience the results as conceptually 
lacking: hearing someone say only `i.there is a black` 
(with no `q.modifiand`/) probably does not result in out 
feeling a sense of `i.conceptual` incompleteness.  
Rather, we assume that the sentence has been 
interrupted, or that on the face it is grammatically 
wrong (for whatever reason: maybe the speaker is  
incompetent, or was interrupted, or is still deciding 
what to say next).  The fact that we experience 
mismatched expectations as violations of syntactic 
rules, rather than conceptually anomalies, may cloak 
the fact that these expectations are intrinsically 
conceptual.  However, this comports with my theory of 
the origin of grammatic intuitions: we are used 
to the flow of expectations to accord with the 
unfolding of grammar.  We `i.become` used to this 
alignment the more that we immerse ourselves 
in language; as a result, we come to subconsciously 
register the posing and resolving of expectations, 
being more explicitly aware of the linguistic 
materialization of these patterns than their 
conceptual substrate.  Once the agreement between 
the smooth creation and dissolving of expectations' 
incompleteness is disrupted, we `i.experience` this 
defect as an anomaly in linguistic form.  
`p`

`p.
Via such a theory, I hypothesize then that grammatic 
rules are emergent phenomena whose origins lie in 
conceptual expectations, and specifically in patterns 
such that expectations are raised and then satisfied.  
Once these patterns become entrenched 
%-- in particular, via grammatic categories %-- they 
can nevertheless be given a formal treatment.  
I will now examine the specific formal model introduced 
here.   
`p`

`subsection.Cognitive Transform Grammar`
`p.
I will refer to the framework proposed here as 
`q.Cogitive Transform Grammar`/.  On this theory, 
the full grammatic interpretation of a sentence 
can be given, at least in germinal form, through 
relationships between two words.  The 
grammatic pattern, in turn, emerges from cognitive 
relations enacted between paired words.  
In particular, one word is a `i.modifier` and a 
second is a `i.ground` or `i.target`/.  The modifier's 
effect is to reconceive or complete the concept 
(or conceptual nexus) already established for the target.  
`p`

`p.
I adopt certain representational conventions which are, 
as much as possible, motivated by cognitive tendencies 
rather than being formally arbitrary.  Nevertheless, as a 
formal systems, representations in general will sometimes 
have rules driven by a desire to reduce data structures' 
parameters, rather than by deep theoretical reasoning.  
For example, I will generally avoid including phrases 
or any other `q.above-word-scale` elements in parse graphs.  
It would certainly be possible to iconify both words and 
phrases via graph nodes, with one form of inter-node 
relation being the inclusion of a word in a phrase.  
I choose however the leave phrase-hierarches implicit, 
partly for the theoretical reason that phrases are 
(I believe) `i.conceptually` derived from the accumulation 
of conceptual refinements via `q.cognitive transforms`/, 
so I'd like to preserve this intuition in the notation.
`p`

`p.
In a case like `i.toward the store`/, which 
(as suggested earlier) I read as `q.transforming` a noun 
to an adjective, the ground of this transform evidently 
a phrase, `i.the store`/.  I will use `q.ground` 
informally for a concept altered by a modifier, whether 
expressed in a word or phrase.  However, formally speaking 
I represent `q.transforms` as graphs only between words.  
Note that `i.the store` itself represents a transformation: 
the determinant `q.the` serves to clothe the generic 
concept `i.store` into a more context-specific referent.  
The concept then modified by `i.toward` is 
`i.store` only `i.after` it is `q.acted upon` by the 
effect of the `q.the`/-modification.  
Rather than picturing this as a relation between a modifier 
and a phrasal ground, we can also see this situation as a 
`q.chain` of modifications, one presupposing another.      
`p`

`p.
With the analogy of `q.functional` types in mathematics 
or computers, we can see intermediate modifications 
as having an `i.input` and an `i.output`/.  Here, 
`i.the` `q.inputs` a noun (`i.store`/) and `q.outputs` 
an altered version of that concept; in particular, one 
now cognized under the aegis of a singular determinant.  
The output of `i.the` is then an input for 
`i.toward`/, which adds its own alteration to the 
evolving `q.store` concept.  We can accordingly trace 
this chain as a series of steps between individual words, 
each step representing how one word modifies a concept 
priorly modified by its predecessor in the chain.  
This kind of picture helps motivate the idea of modeling 
`q.cognitive transforms` wholly via inter-word relations.  
The graph structure in the case of `i.toward the store` 
is simple, in that the transform evince a linear chain 
backward through the sentence: `StoreTheChain;.  
The arrows in this `q.graph` (subgraph, technically) 
point from the target to the modifier: `i.the` is 
a modifier for `i.store`/, but a target for 
`i.toward`/.  This indicates that `i.the` stands in for a 
transform whose `i.output` becomes `i.toward`/'s `i.input`/.  
`p`

`p.
Carrying these ideas over to a formal model, phrases are 
excluded from direct representation because it may be tacitly 
understood with any intermediate target-modifier pairing 
%-- `q.intermediate` in the sense that the target is 
also a modifier for a different target %-- that the 
`q.arrow` direction represents not just the single target 
word as a `i.ground` for modification, but the collection 
of prior transforms forming a chain leading `i.to` that 
target.  For example, `i.the` is target for `i.toward`/, 
but conceptually this means that the accumulated concept 
resulting from `i.the`/'s own modification of its own 
ground is assumed to be carried along in the 
`i.the`/`i.toward` interaction (notationally, the 
`i.the`/`i.toward` arrow, or directed graph-edge).     
`p`

`p.
The `i.processual data structures` I propose for modeling 
Cognitive Transform Grammar are a variety of hypergraph 
built around edges representing cognitive transforms, 
via modifier/target pairs.  The model stipulates that 
each word can be the target for at most one modifier.  
This means that one can form a chain following from one target 
to another, uniquely, and I stipulate that for any single 
sentence such chains will always lead to a single 
`q.root` word.  At this level of description the parse 
graphs are therefore `i.trees`/.  I will however introduce 
certain additional structures through which parcse-graphs 
actually become a form of hypergraph, albeit with acyclic 
directed edges, that is, with a kernel tree-like structure. 
`p`

`p.
I also stipulate that all the edges in a parse-graph 
%-- all the cognitive transforms, representationally 
%-- can be given a specific ordering.  
At least locally, ordering has a theoretical 
basis as can be seen from the `i.toward the store` 
case: the `i.toward` transform presupposes the one 
for `i.the` in the sense that the latter precedes 
it in the output-to-input chain.  The rationale 
for an `i.overall` ordering, across an entire 
sentence, is more complex, but will hopefully 
emerge in my following discussion. 
`p`

`p.
While each word may have at most one modifier, a modifier 
may transform multiple targets.  Consider 
`i.The dogs were barking very loudly`/.  I will 
present an analysis by considering word-pairs 
(in this sentence, but not necessarily in general, adjacent 
`visavis; sentence order).  Here `i.were barking` 
establishes a past progressive tense: I read this as a 
transform which yields a verb (i.e., a conceptual 
outcome which profiles an event or process according to 
the overall ideational desiderata for verbs, for example 
in Lang Intro. p. 108).  More precisely, `i.barking` is 
(I claim) conceptually adjectival, but by blending this concept 
with a temporal reference frame, we employ a conventionalized 
modification which refocuses the original concept toward 
a profiling of something bearing the concept as an 
act on that thing's part %-- cf. `i.I am hungry for` as a 
less ornate vernacular replacing `i.I hunger for`/.  
When the adjective is a gerund %-- therefore morphologically 
based on a verb %-- the transform `i.to` the verb 
category uncovers the original verb, but with added 
temporal specification.  There is more to say about 
this treatment of progressives, but I will forestall 
the analysis for now.    
`p`

`p.
Moving on within `q.barking very loudly`/, the
transform relationship between 
`i.very` and `i.loudly` seems straightforwardly 
adverbial: the modification alters an adverb, 
here adding a measure of incremental emphasis 
(a contrary `q.decremental` transform would be 
hedges like `i.rather` or `i.a little`/).  
Also `i.the` modifies `i.dogs` via singular determinant, 
reiterating my sketch for `i.the store`/.  These, then, 
are basic word-pairs in `i.The dogs were barking very loudly`/.  
Next, `i.very loudly` `q.outputs` an adverb
(it also `q.inputs`/) one, which means the outcome of 
that transformation needs to link with a verb, to become 
its ground %-- specifically, here, the verb concept 
resulting from `i.were barking`/.  So the outcome of 
one transform becomes a modifier for the outcome of 
a second.   
`p`

`p.
Following the principle that targets link in chains 
%-- an edge between one modifier-word and a second 
meaning that the `q.output` of the former's transform 
becomes `q.input` to the latter %-- we here have 
the structure that `i.were`/, which is the modifier 
in `i.were barking`/, is then the target for 
`i.very`/, which is the modifier in `i.very loud`/.  
(This may feel counterintuitive in that 
`q.were` seems like an auxiliary word, so really 
what is being modified here is `i.barking`/: 
semiotically, the key communication is presumably 
`i.barking loundy`/; as I will discuss below, the 
transform structure linking sentences, on this 
model, does not necessarily foreground lexemes 
which are the most semantically important).  
I delay considerations of sentences' overall meaning, 
according to which some ideas may emerge as more 
central than others; here I want to sketch the 
series of transforms through which the overall meaning 
arises.  In this spirit `i.very` links to `i.were`/, 
as modifier-to-target, because of how the transforms 
are ordered: the kind of transform signified by an 
adjective logically depends on a verb, so that 
`i.were`/, whose ouput supplies that verb, 
precedes `i.very` in the formal transform-order.    
`p`

`p.
Also, `i.very` now has two targets.  We have 
`i.very loud`/, which yields a refined 
(here an `q.augmented`/) adverb, and `i.very` 
(encapsulating `i.very loud`/) adverbially modifying 
`i.were barking`/.  I will differentiate multiple 
targets for one modifier in terms of `q.stages`/.  
Here, `i.very` encompasses two different `i.stages` 
of transformation: first, it modifies an adverb 
to form a new adverb; then, in a second stage, 
the outcome modifies a verb ground.  I adopt the 
notational convention that directed edges in a 
parse graph are labeled with a number designating 
their stage: so in a minimal example the links 
between `i.very`/, `i.loudly`/, and `i.were` could 
be expressed as `WereVeryLoudlyGraph;: the subscripts on the 
edges disinguish the first transform-stage for `i.very` 
from the second.   
`p`

`p.
Indirectly, stages also may profile phrases: the phrase 
`i.very loudly`/, for instance, represents the first-stage 
transform for `i.very`/; formally, then, the combination 
of a modifier-node with a specific stage designation 
serves as kind of notational proxy for a phrase.  As will 
be developed further, below, I treat edges sharing a 
stage and a modifier as grouped together, an aggregative 
structure which converts parse-graphs into `i.hypergraphs`/.  
The aggregation which bundles certain edges together, 
under certain circumstances, I call a `i.channel`/; 
here I can then employ certain concepts in a theory 
of `q.channelized hypergraphs` that I have 
elsewhere written about in a computational context.
`p`

`p.
An adverb like `i.very`/, in contexts where it modifies a 
different adverb, implies two stages because the 
transform output (itself an adverb) `q.expects` a further 
ground.  A different sort of transform combination 
is represented by transitive verbs, which need both a 
subject and object to arrive at a complete idea.  
I will still analyze the verb's effects as a sum of 
individual transformations involving separate 
modifier/target pairs.  The verb-to-subject connection 
seems somehow privileged, since it is omnipresent; 
whereas verb-to-object, and still more so 
verb-to-direct-object, is less universal.  Most 
transitive verbs also have intransitive versions; 
and ditransitive verbs also transitive ones: |+|

`sentenceList,
`sentenceItem; `swl -> --- ->  I walked earlier this morning. -> syn ;;
`sentenceItem; `swl -> --- ->  I walked for two hours. -> syn ;;
`sentenceItem; `swl -> --- ->  I walked the dogs earlier this morning. -> syn ;;
`sentenceItem; `swl -> --- ->  I brought wine to the party. -> syn ;;
`sentenceItem; `swl -> --- ->  John brought Champagne! -> syn ;;
`sentenceItem; `swl -> --- ->  I brought Champagne for John. -> syn ;;
`sentenceItem; `swl -> --- ->  I gave Champagne to John. -> syn ;;
`sentenceItem; `swl -> --- ->  I wrote a check for the charity. -> syn ;;
`sentenceItem; `swl -> --- ->  I wrote a check to the charity. -> syn ;;
`sentenceItem; `swl -> --- ->  I gave a check to the charity. -> syn ;;
`sentenceItem; `swl -> --- ->  I gave a donation to the charity. -> syn ;;
`sentenceList`

|.|

The point of these examples is that not every 
instance of verb-modification should be read as 
a transitive or ditransitive verb with its implicit 
direct or indirect objects; and in many constructions 
direct or indirect objects may seem to be optional, 
in the sense that the verb can express a complete 
idea without them.  To what degree do these represent 
distinct senses for the verb, or just 
different options for refining the verb's meanings 
via modifiers?  I will argue that these questions 
evoke different intuitions about how cognitive 
transforms modify the conceptual meanings 
we attribute to verbs. 
`p`

`subsection.Transform `q.Columns` and Verb Objects`
`p.
Insofar as a verb profiles an event or action, there 
are many desiderata that can potentially be predicated 
of the profiled phenomena %-- `i.where`/, `i.when`/, 
and `i.for how long` the action occurred; for whose benefit; 
and so forth.  In general these details are available 
as supplements to the core process profiled by the verb 
itself, and are introduced linguistically by subordinate 
clauses.  The duration of time for my walk, or what landmarks 
I walked passed, are evidently not central enough to 
the meaning of `i.walk` to have special status as 
direct or indirect objects.  Where I walked `i.to` may or 
may not be seen as a direct object, depending on whether 
`i.walk` is construed as fundamentally describing a 
goal-directed movement (like `i.visited`/): |+|

`sentenceList,
`sentenceItem; `swl -> itm:walkedto ->  I walked to the store. -> cog ;;
`sentenceItem; `swl -> --- ->  I visited the store. -> cog ;;
`sentenceItem; `swl -> itm:walkedtoward ->  I walked toward the store. -> cog ;;
`sentenceItem; `swl -> --- ->  I walked past the store. -> cog ;;
`sentenceItem; `swl -> itm:walkedaround ->  I walked around the puddle. -> cog ;;
`sentenceList`

|.|

That is, to what degree does `i.to` in 
(`ref<itm:walkedto>;) describe a spatial path analogous to 
(`ref<itm:walkedtoward>;)-(`ref<itm:walkedaround>;) %-- as such basically augmenting 
the information in `i.walk` somewhat 
tangentially %-- or is (`ref<itm:walkedto>;) a special 
sense of `i.walk` which is more akin 
to `i.go` or `i.headed toward`/?  
To preposition `i.to` may be singled out 
as implying the more goal-oriented 
interpretation on `i.walk`/, but arguably 
there are similar examples with other prepositions: |+|

`sentenceList,
sentenceItem; `swl -> --- -> I'm headed toward the store. -> cog ;;
sentenceItem; `swl -> --- -> This bus is rerouted along Queen Street. -> cog ;;
sentenceItem; `swl -> --- -> Traffic was diverted around the highway. -> cog ;;
sentenceItem; `swl -> --- -> The steps lead through the underpass. -> cog ;;
sentenceItem; `swl -> --- -> The boat is heading under the bridge. -> cog ;;
sentenceItem; `swl -> --- -> Please make an omelet for the dogs. -> cog ;;
sentenceItem; `swl -> --- -> Please make the dogs an omelet. -> cog ;;
`sentenceList`

|.|

It seems as if `i.toward` in `i.headed toward`/, 
for instance, is a direct object for 
`i.head` insofar as it does more than add 
details about setting; the verb `i.headed` 
is intrinsically incomplete without 
clarification of a direction one heads `i.toward`/. 
`p`

`p.
In some cases, though, movement verbs take two or more 
spatial or path specifications, only one of which 
appears to be a direct object: |+|

`sentenceList,
`sentenceItem; `swl -> --- ->  I'm heading out.  -> cog ;;
`sentenceItem; `swl -> --- ->  I'm heading out to the store. -> cog ;;
`sentenceItem; `swl -> --- ->  We have to drive to the entrance. -> cog ;;
`sentenceItem; `swl -> --- ->  We have to drive past the highway. -> cog ;;
`sentenceItem; `swl -> --- ->  We have to drive past the highway to the entrance. -> cog ;;
`sentenceList`

|.|

I would hypothesize that our conceptual expectations 
call for one somehow primary or `i.reified` goal-specification, 
and other spatial information gets separated out as 
extra detail along with many other possible elaborations 
on an action-profile (time, duration, purpose).  
In short, the grammatical expectations of direct and 
indirect object represent a conventionalized way 
of packaging and subdividing the  
content which may be associated with a verb: certain 
facets of detail are grammatically highlighted, but 
the level of detail actively expected through the 
verb is restricted relative to the full detail which 
could potentially be situationally added.
`p`

`p.
Note that, compact ditransitive forms like 
`i.I brought John some wine` notwithstanding, 
indirect objects typically occur last in sentence 
order, after a subject and direct object.  
Indirect objects can then be grouped along with 
potentially numerous `q.satellites` trailing away from 
the verb itself: 
  
`sentenceList,
`sentenceItem; `swl -> --- ->  We have to go to the counter by the cashier near 
the front of the store for a ticket. -> cog ;;
`sentenceItem; `swl -> --- ->  The waiter carved some duck for Grandma at the 
table with an ornate knife. -> cog ;;
`sentenceList`

Only some of these add-ons are feasible as direct or indirect 
objects, e.g., candidates for a dropped preposition as in 
`i.carved Grandma some duck`/.  
`p`

`p.
Every detail added to a verb-concept cognitively 
transforms the verb in some way, but syntactic 
patterns suggest that only certain such transforms 
are `q.reified`/, or marked via distinct  
components of subject or direct or indirect object.  
An intransitive verb without `i.some` detail 
may feel incomplete, but this is probably situational; 
it is hard to imagine senses where an unadorned 
verb-plus-subject construction would have any 
conceptual specificity outside of context: |+|

`sentenceList,
`sentenceItem; `swl -> itm:studied ->  I studied. -> cog ;;
`sentenceItem; `swl -> itm:studiedmath ->  I studied math. -> cog ;;
`sentenceItem; `swl -> --- ->  I studied last night. -> cog ;;
`sentenceItem; `swl -> --- ->  I studied for two hours. -> cog ;;
`sentenceItem; `swl -> --- ->  I studied in a bookstore. -> cog ;;
`sentenceList`

|.|

The first sentence seems incomplete, although it is fine 
if anchored in surrounding discourse, e.g. after
`i.What did you do last night`/?  Such incompleteness 
does not seem to imply that the intransitive form 
of `i.study` is less useful or impactful than 
the transitive; instead, the two forms profile the 
action of `q.studying` with different degrees of 
emphasis on its relation to surrounding detail.  
The final three sentences profiles the action as 
a completed process, but rather generically: the 
specific information focuses on temporal or 
spatial surroundings where the action transpired, 
more than considerations we might deem `q.internal` 
to the action.  On the other hand, (`ref<itm:studiedmath>;) makes 
no specific reference to where, when, or for how long 
the studying occurred, but it gives more info 
about the studying itself.  Given that comparison, 
(`ref<itm:studied>;) seems more like (`ref<itm:studiedmath>;) in asserting no parameters 
spatiotemporally contextualizing the action, but 
this may not be true in the actual dialog where 
(`ref<itm:studied>;) is produced; as a standalone sentence (`ref<itm:studied>;) is 
more likely to be heard as acquiring completeness 
from prior discourse.  On this kind of 
evidence, whether or not a verb takes 
a direct object depends on whether there is 
some `i.internal` detail which the sentence 
highlights, or whether the communicated details 
are more `q.external` to the action-concept in the 
sense of framing the action in a spatial, temporal, 
durational, and functional context.    
`p`

`p.
Another way to review this line or argument is to 
consider how a direct object is implicated in 
the verb-to-subject relationship.  Given 
an intrinsitive setting, the verb-subject combination 
profiles an action with some conceptual completeness, 
however much in just an outline or minimal-information 
fashion.  To the degree that our conceptualization 
of that action is schematically complete, we are then 
in a position to fill in `q.external` 
(e.g. spacetime-positioning) details, which are cognized 
as refinements of the action-sketch.  In a `i.transitive` 
case, however, the verb/subject combination still 
leaves some essential lacunae.  To say `i.I brought`/, 
without its logical continuation, is to present 
a propositionally embryonic content which is too 
preliminary to be further elucidated with desiderata 
of space, time, duration, or purpose.  In this sense 
`i.brought`/, or other necessarily transitive 
verbs, excite logical expectations that need to be 
resolved `q.before` (in some formal sense of sequencing) 
the external details are assimilated.     
`p`

`p.
According to the standard Categorial model, verbs are 
transformations (or modifications or `q.functions`/) 
which produce propositions from nouns: whereas 
`i.the dogs` is conceptually abstract and unspecific, 
`i.the dogs were barking` achieves someting like 
propositional closure.  This means that the verb 
category is `i.derivative` on nouns and propositions; 
and that the verb is a `i.modifier` whereas the noun 
is a `i.ground` thus modified.  This account is complicated, 
however, by `i.transitive` verbs raising expectations even 
in the presence of their noun-subject: here it seems 
as if verbs need `i.two different` grounds, or 
perhaps a multi-part ground with two different nominal 
foundations (subject and object), to produce a 
propositional signification as is its grammatic and 
conceptual role.   
`p`

`p.
Schematically, the outcome of a verb/subject pairing 
in the case of a `i.transitive` verb is not a proposition, 
but an intermediate position which needs a further noun-target 
to complete its propositional process.  The relationships 
between the verb and its subject and object, both, then, 
are somehow incomplete and interdependent.  I will still 
analyze them as two distinct two-word relationships; however, 
the cognitive status of these relationships is 
influenced by their mutual dependency.  In general, a verb 
transforms a noun by enmeshing it in a propositional context: 
with `i.The dogs were barking` we mentally comport to 
`i.the dogs` in a manner reflecting their status as a propositional 
focal point: the intellectual content rationalized via 
the sentence's idea emerges from some property or action 
that will be predicated of the dogs.  This dynamic remains 
if force for transitive verbs: in a fragment like 
`i.John brought`/, however incomplete, we are 
still being prepped for a logic wherein it will be 
some facticity about John that anchors the 
assertion's rational content.  
`p`

`p.
Even for transitive verbs, then, the verb exercises a 
cognitive transform on the subject, revising the 
`q.mood` through which we entertain the subject as an 
intellectual focus: here we attend to that concept 
in the guise of a predicative anchor, something 
whose factuality supplies the empirical basis 
for construing the sentence as an assertion of 
propositional attitudes (`q.factuality` here meaning 
an overall metaphysical participation in rationalizable 
states of affairs).  From this kind of reasoning I 
argue that the model of verbs modifying subject-nouns 
as their targets is well-founded, irregardless of 
any distinctions between transitive, intransitive, and 
ditransitive verbs.  In a transitive case, though, 
the verb/subject remains propositionally incomplete, 
so that the verb then needs an `i.additional` 
target (the direct object), which it then modifies in turn.
`p`

`p.
The proposal that verbs modify direct objects may seem 
less plausible than in the case of subjects: after 
all, the direct might seem more, on semantic grounds, 
to be modiying the verb than vice-versa.  To 
`i.study math` or `i.walk away` may seem to name a 
special kind of studying and walking.  Moreover, 
sometimes an object seems to be `q.part of` a verb, 
in the sense of being lexically or semantically 
attached to it: consider nominalizations like 
`i.goalscorer` or `i.prizewinner`/.  In these 
cases, informal semantic observations would imply 
that the direct object is modiying the verb 
%-- giving some `q.base` verb a new meaning.  I 
do not rule out occasions when a verb-to-object 
structure would actually be analyzed with the 
verb as the target; however, I also think 
there is a cognitive premise for preserving the 
verb-as-modifier in typical transitive cases.     
`p`

`p.
To the degree that `i.math` is a scholastic 
discipline, for example, it fits within constructions 
like `i.study math`/, `i.pass math`/, `i.fail math`/, 
`i.flunk math`/, `i.repeat math`/.  Part of the 
conceptual repertoire we attach to almost any noun is a 
sense of how the noun may be involved with profiles 
of actions, events, or processes, even if not as 
a verb's subject.  These potentialities tend to 
emerge from a noun's status as person, place, thing, 
institution, abstraction, and so forth.  
There are certain actions which we can envision 
being predicated of a restaurant as `i.subject`/, 
say: it may `i.open` (or `i.close`/),
`i.serve wine`/, `i.take reservations`/, 
or `i.hire a sommelier` (these senses focus on 
the restaurant as a social entity more than a building 
or location).  Conversely, other aspects of 
`i.restaurant` present as a direct object: 
since we commonly judge restaurants based on the quality 
of food and service, they are targets of 
assessment verbs such as `i.like`/, `i.recommend`/,
or `i.review`/.  Since they are also locations that 
can serve as destinations or end-points of a spatial 
displacement, we can `i.visit`/, `i.see`/, or 
`i.stumble upon` them.  As commercial enterprises 
they are potentially `i.inspected`/, `i.shut down`/, 
`i.shuttered`/, `i.reopened`/, (by new owners), 
`i.sold`/, or `i.venerated`/.        
`p`

`p.
In the presence of combination with a verb, conceptual 
aspects of direct objects are therefore highlighted 
which reflect something's disposition to be 
included in a predication actionally anchored elsewhere.  
Part of the nature of math is to be `i.studied`/; 
part of the nature of a restaurant is to be `i.liked`/.  
So we can approach the verb's effects, cognitively 
modiying the object's concept, as to foreground 
these conceptual aspects (whose exact nature will 
depend on the kind of entity the noun profiles). 
`p`

`p.
On this theory, then, a verb transforms a subject by 
focusing in on its concept as a ground of 
predication; something whose facticity permits 
rational construals.  On the other hand, a verb 
transforms a direct object by highlighting how it 
becomes part of the empirical parameters constituting 
a state of affairs; it is not the thing whose nature 
anchors a facticity, but something whose relation 
to such an anchor constitutes one of its parameters 
of factical specificity.  Subjects and objects thereby 
have distinct epistemic roles in situational 
reasoning, and verbs transform subjects and objects in 
part by foregrounding aspects of their concepts 
which are relevant to those roles.   
`p`

`p.
Via such considerations I claim that modeling verbs as 
modifiers for both subjects and direct objects is 
cognitively plausible, even if on strict semantic 
considerations we might reverse the 
status of modifier and ground in the verb/object case.  
In particular, a transitive verb simultaneously 
modifies both its subject and object.  I distinguish 
this construction, however, from examples such as 
adverbs, which (as I argue above) also have two 
(or more) different targets, representing different 
`q.stages` of modification.  Here, I use alternative  
terminology: I do not treat the verb/subject and 
verb/object modifications as different `i.stages`/, 
but rather as co-existing transformations 
within `i.one` stage.  Note that different transform-stages 
are in some functional sense independent of one another: 
I can, say, form a chain of adjectives 
(`i.her favorite slinky black cocktail dress`/).  
Each stage adds on more detail while also deferring the 
resolution of the adjectival expectation until the 
eventual noun.  The effect is then a `q.chain` of stages 
where new modifiers could potentially be inserted, or 
to some degree their order be reversed, implying some 
conceptual autonomy among the re-conconceptualizations 
which each stage triggers.  By contrast, the 
verb/subject and verb/object transforms are more tightly 
coupled; the presence of each fundamentally determines 
how the cognitive process which fills in the other's 
significance plays out.  Also, unlike stages, 
these co-existing transforms cannot be chained 
indefinitely; at most verbs can have subjects 
and direct and indirect objects.    
`p`

`p.
For sake of argument, I will call transforms such as 
those between verbs and subjects or objects 
`i.columns`/, in lieu of `i.stages`/.  The idea of 
`q.column` derives from a premise that verbs are 
conventionally understood as intransitive, transitive, 
or ditransitive, and on that basis garner 
explicit expectations of one, two, or three target 
nouns.  Each noun thereby fits within a pre-ordained 
constructional template, rather like the 
columns of a table. 
`p`

`p.
To be sure, verbs may `i.also` be modified by 
their own modifiers, so that prior transform stages 
precede the transform columns.  In 
`i.I brought wine belatedly`/, the adverb's modification 
is a different stage from the propositional completeness 
of `i.I brought wine`/, and serves mostly to decorate 
the verb with added detail.  Structurally, 
`i.belatedly` modifies `i.brought` at one stage and 
then (the output of this transform) modifies 
`i.I` and `i.wine` as subject and object.  Notationally, 
then, `i.belatedly` is a modifier for all three 
of the other words (and the sentence's root).  
In a parse-graph, we need to track two different 
structures differentiating multiple transforms: 
the `q.stage` difference between `i.belatedly` 
as adverb and (upon transform-output) as verb; 
and the `q.column` difference between verb/subject 
and verb/object.  I accordingly use two 
different indices, writin a stage number first and 
then a column number, for edge labels.  Visually, 
a graph labeled via this system might look like 
`BelatedlyBroughtIWine;.`footnote.
I use the notation with open-tail and closed-tail 
arrows to show graphs inline with text, rather 
than needing figural diagrams: an open circle 
at the start of an arrow indicates that the 
modifier at one end of the arrow is not the 
word visually near to the arrowhead but, rather, 
an emphasized node elsewhere in the line; the 
point here is to avoid a `q.stack` of arrows 
all pointing to the same node.
`footnote`  
`p`

`p.
My theoretical contrast between `i.stages` and 
`i.colums` %-- calling for distinct 
representational parameters %-- has the consequence that 
parse-graphs may differ by virtue of whether 
transforms are treated as distinct stages or 
as distinct within one stage.  I would argue 
that most structure within a sentence fits the looser 
`q.multi-stage` pattern rather than the proscriptive 
`q.multi-column` coupling as with transitive and ditransitive 
verbs.  That is, there are not many forms of cognitive 
transformation where the interdependence of two or 
three transforms is so tight as to spur 
grammatic entrenchment (where, say, expectations of 
direct and maybe indirect objects become entrenched 
in a partition of verbs into three subcategories).  
Apart from verbs, there are only a few cases 
where I believe multiple columns (as opposed to 
stages) are called for analytically.  
One example comes from constructions like 
`i.I saw Mary, Paul, and Peter`/: here I find 
`i.and` to be plausibly a modifier which takes 
several grounds as distinct columns.  
I say this because there seems to be no conceptual 
reason to see the aggregation as occupying different 
`q.conceptual` stages, apart from the sentence 
order.  Here too, the transforms seem to be 
`q.bound together`/. 
`p`

`p.
Order of exposition can of course be relevant, 
as in `i.I visited London, Paris, and Frankfurt`/: 
we are more likely to hear this as asserting the order 
in which the speaker traveled to those cities.  
Still, the net effect is to aggregate the three 
places as a combined fulfillment of `i.to`/: 
we mentally construct an internally structured 
locative picture, with the three cities as 
points in the totality.  That is, the effect of 
`i.and` is to modify our construal of the location 
references in the city-names: we come to treat them 
not as particular locations, but as points in a larger 
aggregate.  This aggregate may be further structured 
by construing a temporal order; but 
such an ordering effect supplemental to the basic 
idea of forming a location-collection from a 
disparate set of locations.  I would say that 
each location is a `q.column` in aggregate 
formation because they conceptually transition from 
being isolated to being aggregated collectively; 
I do not perceive a conceptual sense of the aggregate 
being logically built up in stages.   
`p`

`p.
Another pattern of construction I would consider 
`q.multi-column` are those involving subordinate 
clauses as sub-sentence propositions, or perhaps 
propositions minus the subject:  
`i.I thought he left already` or `i.a bag 
for carrying the groceries`/.  Unless we want to 
posit an `q.unmarked` transform of a proposition 
to a noun, a verb like `i.thought` can be 
parsed as taking a proposition (rather than a noun) 
for a direct object.  In the second example, I contend, 
`i.for` takes some elements of verb constructions 
(a verb and direct object) and yields an 
adjective (`i.for carrying the groceries` can modify 
a noun).  I consider the `q.direct object` transforms 
here as `q.columns`/, tightly bound to a paired 
transform (whether verb/subject or preposition/verb).  
In these cases the analysis probably reflects  
similarities to the normal transitive verb as a 
compound transform with both grounds being 
(categorially) a noun.  
`p`

`p.
I will focus further discussion on this canonical case, then.  
In particular, I will explore how `q.column-based` 
constructions contrast with `q.stage` transforms in the 
accretion of conceptual detail associated with a verb.
`p`

`subsection.The Cognitive Distinction between Stages and Columns` 
`p.
A verb can be conceptually expounded upon in many ways; only a 
few are syntactically privileged through transitive or 
ditransitive constructions.  We can cite grammatic evidence 
for this discrepancy; consider: |+|
 
`sentenceList,
`sentenceItem; `swl -> --- ->  I baked a cake for Grandma. -> syn ;;
`sentenceItem; `swl -> --- ->  I baked Grandma a cake. -> syn ;; 
`sentenceItem; `swl -> --- ->  I gave a cake to Grandma. -> syn ;;
`sentenceItem; `swl -> --- ->  I gave Grandma a cake. -> syn ;;
`sentenceItem; `swl -> --- ->  I baked and gave Grandma a cake. ->> (?) -> syn ;;  
`sentenceItem; `swl -> --- ->  I baked Grandma a cake and gave it to her last night. -> syn ;;
`sentenceItem; `swl -> --- ->  I baked Grandma a cake with the recipe she gave me. -> syn ;;
`sentenceList`

|.|

The idea `i.Grandma's cake` can be expanded via different
avenues, but only one of which can serve in any sentence 
as an indirect object, suitable for prepositionless 
ditransitive syntax.
`p`

`p.
Having observed this apparent norm in grammar, we 
can then ask `i.why` English, at least, is 
structured this way.  Indeed, elaborations which 
are `q.reified` one context can be relegated 
to secondary added detail %-- `i.dereified`/, 
so to speak %-- elsewhere: 

`sentenceList,
`sentenceItem; `swl -> --- ->  I'm heading out. -> syn ;;
`sentenceItem; `swl -> itm:heading ->  I'm heading out to the store. -> syn ;; 
`sentenceList`

In the first sentence `i.out` reads like a direct 
object, giving a direction and destination to 
`i.heading`/; but in (`ref<itm:heading>;) it comes across as more 
tangential.  Perhaps `i.out to the store` serves 
as a compound path-desription; or perhaps 
`i.heading out` is a compound verb, roughly the 
same as `i.leaving`/.  In either case for (`ref<itm:heading>;), 
`i.out` augments rather than intrinsically specifies 
the action concept: it either ornaments the path 
construal by noting that going `i.to the store` 
includes leaving the place where the speaker 
is currently; or it merges with `i.heading` to 
form a de facto lexical unit wherein departure from 
the current location is semantically part of the 
profiled action.
`p`

`p.
The theoretical problem these examples can pose is 
that the `i.cognitive transform` model, as I call it, 
qua formal representation, may come across as 
overdetermined.  We should at least consider the possibility 
that no exclusive analysis of the contrast between (say) 
`i.heading out` and `i.heading out to` matches 
our actual linguistis processing.  Perhaps mentally we 
somehow allow `i.out` to `q.float`/, vaguely attaching 
to `i.heading` as an extra specifier, `i.and` perhaps 
as an entrenched compound, and perhaps also 
attached to `i.to the store` as a path elaboration. 
`p`

`p.
To choose one analysis over another is to notate the 
parse differently: reading `i.out to the store` as 
more of a phrasal unit implies `i.out` modifying 
`i.to the store`/; while `i.heading out` as a couple 
implies that `i.out` modifies `i.head`/, either 
as a detail-adding adverb or as part of a lexically 
recurring compound verb.  Each alternative produces 
a different parse-graph, so mapping the sentence 
to one graph or another implies the `q.correctness` 
of one appraisal over the other.  A `q.cognitive 
transform grammar` has to justify that this 
determinism is not arbitrary; not an artifact of 
a representational technique imposing a theoretical 
straightjacket on phenomena which are more fluid 
and underdetermined. 
`p`

`p.
To address this, consider scenarios where someone might 
actually enunciate (`ref<itm:heading>;).  Perhaps two people are studying 
together in a library; the speaker interrupts the other's 
concentration to explain that she's leaving.  
Or, vary the situation somewhat: the addressee looks 
up and sees her standing up and taking her bag.  
Perhaps she varies the intonation somewhat, 
adding a pause between `i.heading` and `i.out to the store`/.  
Given the nonverbal interactions between the two people, 
the speaker may (subconsciously, perhaps) respond to 
the other's cue that he sees her going `i.somewhere`/.  
She might, circumstances being different, be heading 
`i.to the stack`/, or `i.to the washroom`/.  
It is not obvious that her planned movement 
entails leaving the building, which would be 
the normal interpretation of `i.heading out`/.
`p`

`p.
In this reading of circumstances, there is a conceptual 
gap between `i.heading` and `i.out` because 
the addressee already knows (or so the speaker intimates) 
that she is heading `i.somewhere`/.  The 
components `i.heading` and `i.out` therefore have different 
epistemic status, so to speak; the `i.out` part is 
`q.new information` from the addressee's point of view 
in a way that `i.heading` is not 
(he might indeed anticipate that she `i.is` going 
somewhere out of the building, but that is only a 
likelihood given that she has plausible destinations 
`i.in`/side).  It is at least possible that these 
differences are reflected in the intonation and 
delivery of the sentence, maybe not deliberately.  
The speaker could be distracted, saying the 
first two words (maybe in response to a quizzical look) 
and then needing to focus on completing the sentence.  
We are not usually conscious of `q.processing time` 
when `i.composing` a spoken sentence, but occasionally 
there are gaps as attention ebbs and flows from 
linguistic processes, and these may reveal 
conceptual discontinuities in the artifact that 
results.  Of course, the speaker might also 
consciously group `i.I'm heading` and 
`i.out to the store` together (respectively) vocally, 
responding to the cue I proposed that the other person 
knows she is heading `i.somewhere`/.  
Conversely, she may actually express the 
idea with a different audible gap, as if two sentences: 
`i.I'm heading out.  To the store`/.      
`p`

`p.
With speech variations, then, the speaker may in fact 
present the sentence in patterns that convey 
intent in subtly different ways.  In that eventuality, 
different parses are in fact appropriate.  If 
(as I've focused on) the key difference in the current 
example lies with whether `i.out` is attached to 
`i.to the store` or to `i.heading`/, and in the second 
case as a regular adverb or part of a compound phrase, 
then enunciation patterns could incline us to one 
or another reading.  With an explanation of how these 
differences emerge, we can see how the parse alternatives 
for `i.out` actually point to slightly different content 
with respect to how the sentence relates to dialogic 
context.  The speaker may be responding to different cues 
and different assessments of the listener's epistemic 
assessment and inquiry %-- what is particularly relevant 
for her to tell him, from his point of view.  
`p`

`p.
This does not mean that anyone saying (`ref<itm:heading>;) would necessarily 
be thinking through the possible variations, or even that 
vocalization has to reflect divergent patterns in conceiving 
the sentence as it is spoken.  However, such differences 
`i.might` be communicated via alternative intonations.  If 
the sentence is `q.neutral`/, not audibly implying one 
interpretation or another, then I would argue that it is 
in such a restricted sense ambiguous, not fully disclosing 
which `i.epistemic` pattern orients it.  Such ambiguity is 
barely noticeable here, because the construals are only 
slightly different.  However, the speaker could 
`i.potentially` craft the sentence aroud the idea that 
her addressee wants her to clarify `i.where` she is 
going; or conversely that, reading his book, she 
has to get his attention to tell him that she is going 
somewhere in the first place.  This divergence 
yields competing framings for the epistemic background 
she attributes to him; and in turn the sentence relates 
to this background in slightly competing ways.  
If we agree that how expressions orient to epistemic 
backgrounds is part of their meaning, then the 
parse-differences do reflect some measure 
of ambiguity in (`ref<itm:heading>;)'s precise meaning.        
`p`

`p.
This reading, to be sure, depends on a form of 
ambiguity where alternative meanings do not 
specifically conflict with one another.  
For a similar, more `q.semantic` example, 
consider the double sense of a word like 
`i.rice` in, say, a `i.rice pilaf`/: |+|

`sentenceList,
`sentenceItem; `swl -> riceyellow ->  The rice has a nice yellow color that comes from turmeric. -> amb ;;
`sentenceItem; `swl -> riceburn ->  Make sure the rice doesn't burn. -> amb ;;
`sentenceList`

|.|

In these cases we can hear `i.rice` as designating rice 
itself `i.inside` the pilaf, or else the pilaf as a whole, 
which also has other ingredients (compare `i.I haven't 
yet added the rice to the pilaf`/).  Such  
difference, strictly speaking, propagates to (`ref<riceyellow>;) 
and (`ref<riceburn>;) 
%-- we might be concerned about `i.some rice grains` 
burning, or observe that rice grains are stained by 
turmeric.  We might also worry about the pilaf 
(other ingredients too) burning, or notice that the 
whole dish has a yellow color.  In terms of propositional 
content, however, the competing precise facts are 
similar or compatible enough that we may place them 
together: (`ref<riceburn>;) worries about burning both the rice and 
the whole dish, without the technical possibility of 
differentiating them (qua referents of `i.the rice`/) 
being consciously noted by (`ref<riceburn>;)'s speaker.  So (`ref<riceburn>;) 
may reveal an ambiguity does not really decide which 
meaning is preferred.  Whoever hears (`ref<riceburn>;) may therefore 
conclude that, while a speaker `i.could potentially` 
intend one meaning expressly, the potential difference 
might not even be noticed when formulating the 
sentence.  In the latter case the precise meaning 
of (`ref<riceburn>;) may be read as a kind of superposition of 
the two fine-grained alternatives.    
`p`

`p.
Another case of `q.partial` ambiguity comes to mind in light 
of one of Langacker's case studies, which involves the 
similarities between the following (despite variant constructions 
on the subordinate clause): |+|

`sentenceList,
`sentenceItem; `swl -> itm:discovered ->  The effect was discovered by some scientists who were 
working in this lab. -> amb ;;
`sentenceItem; `swl -> --- ->  The effect was 
discovered by some scientists working in this lab. -> amb ;;
`sentenceItem; `swl -> itm:discoveredlab ->  The effect was discovered by some scientists in this lab. -> amb ;;
`sentenceList`

|.|

I find that a greater divergence of meaning between the sentences 
comes out if we substituting something else for `i.effect`/; say, 
`i.vandalism`/: |+|

`sentenceList,
`sentenceItem; `swl -> itm:vandalism ->  The vandalism was discovered by some scientists who were working in this lab. -> amb ;;
`sentenceItem; `swl -> itm:vandalismworking ->  The vandalism was discovered by some scientists working in this lab. -> amb ;;
`sentenceItem; `swl -> itm:vandalismlab ->  The vandalism was discovered by some scientists in this lab. -> amb ;;
`sentenceList`

|.|

The presumed circumstances are that a specific act of vandalism 
resulted in a specific observable damage or disruption 
(broken equipment, or a spray-painted wall, etc.), and 
this `i.evidence` of vandalism is `q.discovered`/.  
A variation is that the discoverers came across the 
vandals during the act.  A still more unusual (but not 
logically impossible) reading is something like 
an archaeology lab discovering evidence of ancient vandalism 
from analysis of artifacts.  These variations point to how 
potential for ambiguity can be broader than we realize, because 
we tend to instinctively rule out contrary interpretations 
in context.  The most straightforward reading of 
(`ref<itm:vandalism>;)-(`ref<itm:vandalismlab>;), 
though, is that vandalism occurred in the lab and was 
discovered after the fact.
`p`

`p.
We can still conceive two somewhat different scenarios, though: 
one reading (implied more strongly in (`ref<itm:vandalism>;)) is that 
the discovery happened `i.while` working in the lab.  
Note that `i.working in the lab` can be evaluated 
on two different time frames: this could refer to 
work done physically present in the lab, over a few 
hours; or more diffusely to the fact of someone 
having an institutional affiliation with the lab, 
presumably spending time there doing research, 
but not necessarily connecting facts of the people 
to the actual time and place of being in the lab. 
In `i.One of the researchers got 
married/pregnant/cancer while 
working in the lab`/, we would not guess 
that the wedding, or any love's consummation, 
happened `i.in the lab` itself (but consider 
replacing `i.pregnant` with `i.drunk` or 
`i.burned`/).  Langacker's original examples 
show some of this potential double-sense also: 
were the scientists literally `i.in the lab` 
at the moment they `q.realized` `i.the effect` 
exists (assuming there was such a single moment)?  
For (`ref<itm:discovered>;)-(`ref<itm:discoveredlab>;) that does not really seem relevant; 
i.e., we do not appear to need to resolve that 
question to make sense of their meaning.  
For (`ref<itm:vandalism>;)-(`ref<itm:vandalismlab>;) however the distinction `i.might` be 
relevant.  If `i.working in the lab` just asserts 
the discoverers' affiliation, they may have seen 
damage as soon as they entered the lab (and were 
not actually working), or perhaps even remotely 
(perhaps noticing something amiss on a computer network).  
Whether they were physically present, and what they 
were doing at the time of discovery 
(maybe or maybe not `i.working` in the lab) could 
influence our appraisal of the vandalism's details.
`p`

`p.  
At least, we can imagine someone hearing 
(`ref<itm:vandalism>;)-(`ref<itm:vandalismlab>;) 
as finding it relevant to know whether 
the discoverers were concretely 
`i.working in the lab` at the time they realized 
the lab was vandalized.  The sentences, then, 
are ambiguous on that matter; it is plausible 
that someone would press for clarification if 
they are told only (`ref<itm:vandalism>;)-(`ref<itm:vandalismlab>;).  Moreover, I think 
(`ref<itm:vandalismlab>;) makes it slightly more likely that we would 
infer `i.working` as applying to the `i.time` of 
discovery, because (`ref<itm:vandalismworking>;) profiles `i.working in the lab` 
as a grounded process, via a finite clauses.  By 
extablishing somewhat disparate `q.probabilities` 
in the space of alternative readings, 
(`ref<itm:vandalism>;)-(`ref<itm:vandalismlab>;) have, 
we should recognize, some non-isomorphism in 
meaning.  It is, however, entirely possible that 
their addressees would fail to notice or attend 
to this variation.  In practice, 
(`ref<itm:vandalism>;)-(`ref<itm:vandalismlab>;) could 
well be indeterminate in terms of whether the 
lab-affiliates were specifically `i.working` 
at the time of discovery, without that imprecision 
propagating to a gap in signification in its 
proper discourse context.  The actual meaning of 
the sentences would then perhaps be some sort of 
disjunction among their ignored granular potentials.
`p`

`p.
I use the `q.rice` and `q.vandalism` examples to motivate my reading 
of `i.I'm heading out to the store`/: even if 
a theory (here, Cognitive Transform Grammar) 
proposes competing parses which seem more 
sharply differentiated than communicative 
intent warrants, we can treat these alternatives 
as `q.superpositions` of slightly different 
meanings reflecting discrete construals which 
the speaker `i.could potentially` mark deliberately, 
but could also either ignore or neglect to notice.  
We might analyze one parse-graph (say, 
`i.heading out` as a compound verb) as a reasonable 
`q.default` interpretation in the sense that it 
formulates the sentence most compatibly with 
how the speaker and addressee would assess its 
epistemic context, to the degree that they 
consciously do so.  But alternative parses 
may indeed present minimally alternative meanings, 
which have some conceptual presence insofar as 
the addressee might, consciously or not, 
recognize that the speaker could in fact 
be conceiving the sentence through one of 
those alternative forms.  The speaker may  
`i.compel` that impression by using an intonation 
pattern less consistent with the `q.default` 
parse, but `i.failure` to signal such a 
deviation does not decisively communicate 
that the variant meanings (reading `q.meaning` 
here very narrowly) are specifically `i.not` intended.    
`p`

`p.
With that said, cases like `i.heading out to the store` 
do reveal that a sentence can be given different parses 
which each satisfy the conditions stipulated in 
my proposed Cognitive Transform Grammar.  Such 
differences are not theoretical anomalies; they reflect 
potential variation in meaning, but admittedly 
often minor and subtle ones.  To make the theory more 
detailed, I would like to address which criteria 
point to one parse or another, given the potential 
triviality of their semantic separation.  
In short, taking the representational rules 
and parameters %-- the column/stage 
distinction and the conformance of modifier/target 
articulation to a tree-form, leaf-to-root orientation 
%-- as given, what conceptual patterns are 
revealed by, or philosophically legitimate, 
this structural paradigm?  Can we give cognitive 
motivation for why linguistic performances may be 
organized in a system which my representational 
norms would diagram?  I will explore this 
methodological rationale-apologia in the next section.
`p`

