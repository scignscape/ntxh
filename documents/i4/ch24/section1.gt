`section.Semantics and Situational Change`
`p.
Most of the time, language 
reflects our pragmatic concerns.  
Situations serve as a backdrop 
for goal-directed activity, and 
the circumstances obtaining 
at any moment serve as both a 
parameter on and, to the degree 
that we act deliberately, a 
byproduct of our actions.  
If we ride a bus to the dog 
park, we are on the bus 
`i.because` we have decided 
on that course of action for 
the afternoon, but the bus 
is also a constraint; it 
creates situations for us that 
we occupy rather than explicitly 
architect.  If the bus is stuck 
in traffic, we have no way to 
get there faster.  Rain keeps us indoors; 
cars cannot drive except on roads; 
locked doors must be opened with keys.  
The affordances of constructed objects 
are also djinns producing states 
of affairs that we must adapt to.
In this sense our situational 
awareness is also always projecting 
forward, protaining the immediate 
future, subtly modulating 
plans in response to the 
not-fully-anticipated turns 
that situations take.  
`p`


`p.
Ultimately, I would argue, it is this 
enactive-protaining register that 
forms the predominant mode 
of linguistic semantics.  What we 
`i.mean` is usually reflective of 
how we anticipate our actions in 
the immediate context of our 
situations to proceed, moving 
forward, in the immediate future.  
Linguistic utterances are, in short, 
canonically, formulaic 
expressions of temporal intentions 
in this sense, i.e., `q.intentions` 
in the sense of intending-to-act or 
intending-to-do.  Of course, 
we do not spend all of our linguistic 
lives simply asserting our plans, 
but such pragmatic intentionality 
forms the substratum of language proper, 
I would argue.  Such intentionality 
is still an underlying semantic 
paradigm when we switch from 
raw expository statements to 
questions, conversation turns, prompts 
for others' opinions, and in general 
the techniques we use to form 
collaborative plans via dialog.  
`p`


`p.
In sum, then, language departs from 
underlying cognitive schemata 
largely through the gap between 
merely experiencing present 
situations to co-ordinating 
near-future actions that follow 
from present-moment situational 
episodes.  Stella is accordingly 
working in a linguistic register 
proper when she uses words to 
project forward in time, via articulations 
that incorporate the present moment 
but are not wholly contained in it 
(`q.eat park outside`/, `q.want park/beach`/, `q.come bye 
outside`/, `q.play outside` after Christina's `q.what now`/, 
and so forth).  The complexity of linguistic constructions, 
of course, will mirror the degree of detail 
and breadth of planning spanned by the current 
discourse.  Stella's relatively simple 
phrases stand at one extreme; something 
like a political party's platform 
paper, sketching out years' worth of 
legislation and programs (however realistic or not) 
at the other.  But it is reasonable to 
argue that the crucial dimension of 
language proper is not syntactic complexity 
itself; instead, complexity of form 
is a metaphenomenon reflecting the 
intricacy of the anticipations which 
language communicates.  Simple plans 
are no less vehicles of language 
than elaborate ones.    
`p`


`p.
On this account, it is impossible to 
theorize linguistic meaning without 
describing how hearers receive 
speakers' statements as asserting 
or formulating near-future plans.  
Addressees must understand 
how word-meanings, in the context 
of their proper grammatic forms, 
translate to anticipated 
actions.  This kind of meaning, of 
course, depends heavily on 
prelinguistic knowledge, and 
on all parties to a conversation 
having succinct correlations 
in their respective beliefs to 
co-operate productively.  
If two people talk about 
taking a bus to the park, 
let's say, they need 
to have prior understand 
of what that would 
entail, such as the pragmatics 
of boarding a bus, where to 
get off, and so forth.  
This embodied knowledge 
is not a predicate that could be 
built via syntax and semantics 
alone, like a journalistic 
reportage (`q.today the new Prime 
Minister visited the King`/) 
stating a (relatively self-contained) 
fact.  We might indeed 
say that the meaning of that 
Prime-Minister sentence is wholly 
expressed through its propositional 
content, but a more quotidian 
speech-act such as `q.let's take the 
bus to the park` is less illocutionary, 
its meaning deriving less from any 
proposition mimicked by its 
construction and more from 
how it solicits prelinguistic 
knowledge %-- prelinguistic `q.scripts`/, 
one might say %-- that would enable 
the actions proposed. 
`p`


`p.
From an enactive/pragmatist perspective, 
we (as language users) have a substantial 
repertoire of `q.scripts` which represent 
learned know-how, enabling our 
competent achievement of concrete 
goals (riding to the park, and so forth).
Such scripts are not propositions, nor 
are they facts that language can convey 
in propositional form (like `q.The Prime 
Minister visited the King`/).  Rather, they 
are competences which we have at 
some level abstracted and represented 
such that they could be referenced 
indirectly through language.  There is 
nothing in the phrase `q.ride the bus` that 
conveys the propriocentric patterns of climbing 
on board (and the geospatial acuity to 
know where to get off).  Nonetheless, 
expressions like `q.take the bus` serve 
as proxies to these pragmatic packages.  
Linguistic meaning, in short, often 
takes the form of nominating various 
enactive-prelinguistic scripts 
with which an addressee (by assumption) 
is acquainted.        
`p`


`p.
Not all expressions work by `q.proxy` 
to this degree, of course (as compared 
for instance to describing facts 
via logical constructions), but 
insofar as language such as 
`q.ride the bus` depends for its 
semantics on already-familiar 
enactive `q.scripts`/, we cannot 
treat meaning as something 
`i.internal` to language, something 
structurally replicated in linguistic 
form.  I have attempted more 
detailed analyses to motivate 
what I see as an essential deviation 
between language and logic (see [], for 
example), a line of argumentation 
which I won't pursue here for long, 
but a thumbnail version is that 
most language does not work the 
way `q.logical positivist` (among others) 
paradigms have claimed, where 
language serves in effect as an 
informal version of the kind of 
predicate compositionality modeled 
more rigorously by formal logic.  
Sometimes it does: `q.(Rishi) Sunak visited 
(King) Charles` 
individuates two actants to a predicate 
relation and names this relation directly, 
all through straightforward lexical and referential 
means.  But most linguistic constructions 
do not work by reciprocating 
logical constructions.  A more typical 
speech-act is something like 
`q.let's take the bus to the park`/, 
whose apparent meaning doesn't have a 
direct propositional content in the 
first place (the intended idea is more 
involved than just, say, the expected 
fact of them soon `i.being at the park`/) 
and, to the degree that predicates are 
implicit in the thought conveyed, the 
sentence does not work by structurally 
embodying them.  Instead, the sentence's 
effect is, more, to inspire 
in the listeners imaginings of, and (to 
the degree that they endorse the plan) 
anticipations of the practical 
and experiential episodes that would 
comprise, in sequence, `q.going (by bus) 
to the park`/.  The sentence works 
by invoking a script which the 
hearer (presumably) knows reasonably well.  
`p`


`p.
Arguments to the effect that language 
`q.invokes scripts` more than `q.models 
propositions` are consistent, 
I think, with various theories 
of language that purport to offer an 
alternative to `q.analytic` philosophy 
of language arguably over-invested 
in language being a kind of symbolic 
(or symbolized) logic.  These (countering-Analytic-paradigm) 
approaches would include, for instance, Cognitive Grammar 
and Construction Grammar, probably alongside 
`q.embodied` notions in Cognitive Linguistics 
(Lakoff and Johnson, for example), or 
Petitot/Doursat `q.morphodynamics`/, 
speech-act or conversation-oriented 
models in the tradition of Grice or 
Searle, or ethnolinguistic (and `q.eco-`/linguistic) 
approaches to language as an anthropological 
phenomenon more than a `q.system` to be 
structurally analyzed.  To this list I would 
add Vakareloff's `q.Interface Theory of Meaning,` 
which I have claimed 
applies to artificial (programming) languages 
as well as Natural Language.  In the 
formal-language context, the value of 
such as `q.interface theory`/, as I intimated 
then, involves the formal-semantic 
paradigm (manifest to some degree in 
computer science, for example in the 
design of the `q.Semantic Web`/) according to 
which programming-language semantics 
should be evaluated in logical (and set-theoretic) 
terms.  That is to say, expressions in programming 
languages are (within the paradigm being 
disputed) logical elements such as 
predicates/relations, sets, and set-members, and 
by sufficiently intricate aggregates 
of such logical building-blocks we can 
form computational simulacra of 
empirical objects.  Logically constructing 
propositions about such objects (or their 
states and properties) enables objects to 
form the `q.semantics` of programming and database/data-modeling 
languages, so that such languages' semantics 
is constituted by the logical approximations 
relating computational models to their 
presumptive referents.     
`p`


`p.
Against such a `q.logical` paradigm, I argued 
in Chapter 20 for a `q.procedural` perspective, in which 
the semantics of computational languages 
should be seen as constituted by the 
collection of procedures that can be 
invoked through (any given) language 
(in any given context).  Such 
`i.procedures` semantically 
implicate empirical objects (by 
presenting information about them, 
showing them pictorially, simulating 
then virtually, and so forth), but 
we should not reason as if the 
structures of computer code 
somehow `q.describe` the objects 
in question.  Instead, computer code 
engineers a space of procedural 
responses to user actions in which 
object-representation, to the 
degree that it is perceived as 
such by the user, is an 
`q.emergent property` of the 
overall computational system.  
Outside the indeterminacy of 
such `q.emergence`/, the actual 
`q.semantics` of computer languages 
should be sought in the procedures 
that create representations of 
objects for users' benefit. 
`p`


`p.
Of course, computer code exists on multiple 
levels, and while we might 
agree that higher-level code depends 
for its meaning on procedures that 
are bound to code-symbols, those procedures 
are implemented via lower-level code, 
and so on down the compiler stack, so 
that eventually we reach a machine 
language whose semantics is logic 
gates and memory addresses rather 
than procedure-calls as such.  
However, these lowest-level 
layers %-- where computations are 
actually manifest on a physical 
level %-- have less resemblance 
to real-world objects than 
computer code at higher levels.  
The layered nature of code-implementation 
motivates a model wherein any 
`q.natural` semantics for computational 
systems is an emergent property, not a 
logical construction.  I defer 
to Vakarelov's `q.interface 
theory` in both contexts:  
the overt meaning of a linguistic 
expression (a speech-act in natural 
language, or a code-statement 
in programming) is an `q.interface` 
to some underlying script/procedure 
which resides not at the level of 
the explicit language, but on a 
deeper or hidden level (the repertoire 
of pragmatic scrips held by a 
person using language; the 
space of compiled routines known 
to a programming-language runtime and 
available to be called from application code).  
Natural language invokes `q.cognitive procedures` 
(like `q.imagining riding the bus`/) much 
like high-level code notates 
instructions to call low-level functions.  
`p`



`p.
I contend, therefore, that something 
like an `q.interface theory` yields 
a useful paradigm with payoffs 
in both natural language and 
Software Language Engineering.  
Granted, philosophical paradigms 
are not especially consequential 
in the latter domain unless 
they imply some specific tactic 
or norm for the design and/or 
implementation of coding 
languages (their compilers, static-analyzers, 
and/or runtimes).  It may not be obvious 
how argumentation that the semantics 
of computers is basically one of `q.procedures` 
and not `q.logic` practically affects any 
of these latter topics.  Elsewhere I have 
presented analyses hoping to show that 
there is at least some practical consequence 
that might compel new language-engineering ideas, 
for example in more rigorously formalizing 
non-set-theoretic type theories and potentially 
new stategies for code analysis 
(alluded to via `q.constructor channels` 
and my overall suggestions to the 
effect that we should formulate compiler design and 
code-verification via structures that can be 
translated to query-evaluations over hypergraphs). 
This is, however, I concede, a fairly 
narrow domain of practical application.  
I have not clarified how detecting a 
concordance between `q.interface theories` 
in natural and computer languages 
yields any substantive insights 
in either context.
`p`

`subsection.The (provisional) semantics of syntactic 
dis-ambiguation`

`p.
The central idea of `q.interface` theories of meaning, 
as I see it, is that linguistic structures do not 
(at least fully) encode meanings in full 
detail, but rather defer to extra-linguistic 
cognitive processes; language proper 
defines parameters and specifications on 
such extra-linguistic faculties, but does 
not logically reciprocate whatever mental 
operations substantiate cognitive processes 
themselves.   Having argued that shared 
understanding is `i.pre`/-linguistic, 
I would add that cognitive processing is 
`i.also` outside language, so that 
language proper is mostly a link or 
inter-connection from one to the other: 
syntax and semantics `i.starts with` 
joint situation/environment models 
and compels each conversant to 
supply new cognitions, somehow 
altering or re-envision these surrounding, 
with language being the conduit between 
a joint attention and a subsequent 
re-staging of the environment, both 
of which as predominantly `i.extra`/-linguistic.       
Linguistic utterances 
then become figured as intermediate 
constructions that bridge but largely 
remain separate from these cognitive subsystems.
`p`


`p.
One potential counter-argument to this 
formulation is that fully constructing a 
linguistic expression (e.g., a sentence), 
so that it may serve such intermediary 
role, would therefore appear to be a 
mental operation outside of actual 
meaning-comprehension, because 
on this theory `i.extra`/-linguistic 
cognitive processes flesh out 
meaning proper.  This suggests that 
`i.as` linguistic, or during the 
`q.processing stage` where 
expressions are `i.only` linguistic 
artifacts (not yet subject to 
extra-linguistic cognitive scrutiny), 
expressions do not `q.have` meaning 
`i.per se`/, and so are in effect 
meaningless.  But, if so, how can 
we have coherent linguistic expressions 
in the first place?  After all, what 
differentiates valid utterances 
from (logical or grammatical) nonsense 
is (apparently) that proper expressions are 
meaningful in some sense.  For example, 
properly parsing a sentence would 
appear to be a necessary step toward 
aggregating linguistic content 
to serve as material for extra-linguistic 
cognitions.  If there is no preliminary 
meaning, how can we actually distinguish 
correct parses than ones which 
yield gibberish, even if they 
satisfy certain criteria 
(such as pairing up words based 
on part of speech)?  How can 
we rule out grammatically plausible 
but logically nonsensical,  
parses, or filter interpretations 
that are syntactically reasonable 
but depend on mapping words 
to lexical options that are
contextually unlikely?   
`p`


`p.
In short, a further complication with regards 
to `q.interface` semantics, as I see it, 
concerns the role of meaning-anticipation 
in syntactic parsing.  An idealized 
view of language might hold that 
we perceive parse-trees first, and 
fill in semantic content later; i.e., 
that parsing and lexical comprehension 
are two distinct processing stages.  
This might be how one would design an 
artificial language, but in practice 
there seems to be at least circling 
between the two processes, where appeals 
to semantic coherence help resolve 
syntactic ambiguities.  Assuming, 
with link and dependency grammars, that 
parse-structures can be modeled as 
graphs, most sentences have many 
candidate graphs which are not 
ruled out by syntactic desiderata 
alone (such as parts of speech).  
Barring outright `q.eats shoots and leaves` 
style ambiguity, only one parse-structure 
will typically emerge as a the most 
sensible reading `i.given` the 
resulting meaning, but assuming that a full 
semantic interpretation functions 
as a litmus test for rejecting less-likely 
parses would violate the model according 
to which we mentally form a parse-graph 
`i.first` and `i.then` deduce its 
intended meaning, by filling 
in the words' lexical (and, as needed, 
referential/anaphoric) content. 
`p`


`p.
Of course, a simplistic way to address this 
problem is to envision our minds 
subconsciously testing many different 
parse-graphs, potentially `q.reading` thousands 
of different interpretations of a 
sentence %-- giving each a fully-specific 
meaning if possible %-- and only 
after all this work scoring one reading as 
the most likely.  Such an explanation, 
which by stipulation we could never 
consciously verify anyhow, is not 
very satisfying (barring strong 
neurolinguistic evidence that processing 
really does branch out in parallel to 
this extent), because it basically just 
papers over an apparent theoretical 
gap by vague appeals to unknowable 
cognitive machinery.  A more compelling 
analysis would provide some model 
of how the parse-graph space could be 
pruned `i.without` full semantic 
reconstruction, perhaps allowing 
`i.partial`/, but noticeably limited, 
appeals to sentence-constituents' 
lexical (and semantic/referential/anaphoric) 
interpretations.  Dependency grammar, 
for example, provides empirical data 
indicating how metrics of word-distance 
and `q.edge crossings` factor in to 
parses being more or less likely, 
but this is still only a provisional 
analyses %-- many sentences' 
actual parse-graphs have configurations 
that would be deemed improbable based 
on such metrics in isolation, and 
even when they prune the parse-space 
correctly there can still be 
many reasonable readings that 
must be further disambiguated. 
`p`


`p.
I will not present empirical data supporting 
these proposals, but in light of my 
arguments in Chapter 20 I'd like to 
summarize at least the rudiments of a 
theory to further refine our models 
of parse-space.  In general we seek 
to find criteria that would eliminate 
candidate graphs by considerations 
`i.other than` explicit semantic 
meaning, because with such 
restrictions in effect one can 
`q.quickly` narrow size of 
parse-structures that are legitimate 
contenders to be `q.correct` readings 
of each sentence.  Part-of-speech 
data, for example, can play such an 
eliminative role, since only 
in specific contexts can a pair 
of nouns, say, or a pair of verbs, 
enter into head/dependent relationships.  
In practice, however, part of speech 
is fluid; quite a few constructions 
implicitly treat nouns as adjectives 
alongside other nouns (like `q.pet` in 
`q.pet store`/), or treat nouns as 
verbs (e.g., `q.to primary` in politics), 
nouns-as-verbs-as-adjectives (`q.iced tea`/), 
etc.  Graph-pruning needs to ensure 
that valid part-of-speech migrations 
are not misclassified, which again begs 
the question of how to know what 
interpretations to reject `i.without` 
fully realizing the potential meanings 
that could be attributed to such 
interpretations. 
`p`


`p.
A minimal criterion for parse-structures 
being acceptable is that they present 
sentences which build up to some (relatively) 
complete idea, although this still needs 
to account for partial expressions 
that addressees mentally complete (imagine 
someone holding out a glass and saying 
`q.could you please?`/, implying without 
stating a proposition related to 
someone filling the glass).  This 
appears to be a fairly rigid system 
within language, which can 
without oversimplification be modeled 
via mathematical formalisms, such as 
Lambda Calculus.  Actually, the 
role of Lambda Calculus in this context 
would lean toward type theory 
%-- even in untyped calculi there is a 
provisional distinction between 
functions and their arguments, and 
type-checking can be progressively 
refined as our type-models become 
more granular.  So the essential 
detail, represented in Lambda Calculus 
via beta-reduction, would be how 
type-tuples under the influence of 
functional types collapse to single 
types, and iteratively such reduction can 
occur over multiple stages (for sub-expressions), 
yielding, in the linguistic context,
the stipulation that (complete) sentences 
have `q.propositional` types.  In chapter 20 
I argued that lambda calculi and their 
variations (Sigma Calculus, calculi with 
exceptions, and so forth) can be represented 
via `q.channels` and encoded via hypergraphs; 
this represents a small extension to the 
concept of type-reduction, because reductions 
are type-checked across multiple channels.  
Aside from that, we can further analyze to 
what extent semantic information can be 
encoded in type-systems; in [] for 
example I distinguished between different 
levels of type-granularity (`q.macro-types`/, 
`q.meso-types`/, and `q.micro-types`/), 
with the idea that types of `q.intermediate` 
granularity  
could provide a mechanism for parse-pruning 
which rejects semantically implausible 
graphs on bases that are still heuristic 
and simpler than full-scale semantic interpretation.
`p`


`p.
Elaboration of my attempted extensions 
along these lines %-- via channels and meso-types 
%-- is outside the scope of the current discussion; 
I merely want to point out that type-theoretic 
approach can offer rigorous models of 
parse-pruning and that the effectiveness
of pruning `q.algorithms` increases to 
the degree that type systems become 
finer-grained.  This is true both for 
natural and programming languages, as 
evidenced by how strongly-typed language 
support more rigorous modes of 
static analysis.  Type systems which 
encompass `q.dependent types`/, typestates, 
and/or detailed `q.type-class` extensions 
progress further into the realm of 
encoding semantic information via 
type-attributions; these seem like good 
candidates for emulating how humans 
create provisional semantic models of 
sentences without fully completing 
all lexical/semantic/referential/anaphoric 
details.  However fine- or coarse-grained 
the recognized type system, the key 
structural claim in any case is that 
type-reductions cascade from terminal 
nodes to root nodes in tree-like 
(or directed-acyclic) subgraphs, and that 
this represents one universal 
constraint through which candidate 
parses can be eliminated.
`p`


`p.
Alongside such type-theoretic models, I also believe 
that interword relations along the lines 
investigated by Link Grammar supply a different 
and orthogonal class of constraints, because 
sentences appear to have predictable regularities 
in terms of contexts where specific forms 
of interword-links are permissible.  In [], 
I argued (inspired by work such as that 
of Lucas Champolion, as well as more 
generically from Cognitive Grammar and Link Grammar 
overall) that the most important framework 
for modeling pair-relations as parse-criteria 
is that of `q.thematic relations`/, focusing 
on the theta-roles and grammar-cases that 
link verbs to their profiled constituents 
(subjects and objects, and then via further 
detailing the various locative, benefactive, 
instrumentive, and etc. case-forms).  Each pairing 
between a verb and its thematically 
related associated words or phrases adds a 
level of detail to the state or event 
profiled by the verb, as this is postulated 
by the speaker.  The total collection of 
a verb's thematic relations represents the 
verb's state/event within an epistemic 
packages, mediated by the speaker's 
propositional and perspectival attitudes.  
Parse-graphs only make sense if thematic 
relations together sum together in ways 
that are epistemically coherent.  
This, then, presents an additional 
layer of criteria that can be imposed 
on parse-spaces to distinguish credible 
from dubious parse-candidates.  I defer 
to work such as Langacker [] for 
actual descriptions of `q.epistemic coherence`/; 
here I will simply say that certain lineups 
of thematic relations are more coherent 
than others, and this can be grounds 
for accepting or rejecting candidate 
parse-graphs.   
`p`


`p.
In sum, then, I propose that both type-reduction 
and thematic relations are systems that 
introduce parse-acceptability criteria, and 
both systems can operate at once over 
possible parse-graphs to eliminate 
spurious candidates (while still remaining 
uncommitted to full semantic realizations).  
Moreover, I believe these two systems 
are quite apparent in both natural and 
programming languages.  Deciding amongst 
competing parse-graphs is not necessarily an 
issue for compilers in the latter case, because 
most computer dialects do not accept 
any sort of syntactic ambiguity comparable 
to natural language; the parse-structures 
of code-expressions should be fully 
determinate from rules that can be enforced 
mechanistically with compile-time information.  
However, parse-graphs for computer code only 
indicate how arguments are connected 
to procedures; there can still be ambiguity 
in the relation of procedure-symbols to 
the specific implementations which are 
intended to be called at the relevant 
code-points at runtime.  In this context 
compilers and/or runtimes have to apply heuristic 
tests for symbol/procedural mapping,
often involving `q.topological sort` algorithms 
and metrics grading type-coercions.  Here 
a type-theoretic infrastructure plays a 
pruning role analogous to  
parse-graph multiplicities in natural 
language.  Also, procedures' 
pre- and post-conditions can serve as 
criteria on graph-edges structurally 
equivalent to thematic relations 
in natural language: consider the idea 
of overloading a procedure operating 
on two lists (or vectors, arrays, stacks, queues, etc.) 
by implementation-bodies 
differentiated via typestates: two 
empty lists, one empty list, two same-sized lists, and 
so forth.    
`p`


`p.
With respect to `q.interface theories of meaning`/, 
the type-reduction/thematic-relation systems 
offer a plausible model of how 
parse-graphs can be selected even while 
parsing is understood to be functionally 
prior to cognitive `q.scripts` that yield 
the full-scale semantics for linguistic 
expressions.   
`p`



`subsection.From Natural to Computer Languages`
`p.
Although it would take more work to make 
this proposal rigorous, I believe that the 
co-existing structures of type-reduction 
and thematic-relations serve as structural 
criteria in both natural and programming 
languages, yielding constraints on 
syntactic and/or semantic processing 
which allow some decisions to be made 
%-- parse-graph pruning in the former 
case, function-symbol resolution in the 
latter %-- that foreshadow but 
do not depend on complete semantic 
information.  While similarities between 
programming and natural languages 
are in general pretty superficial 
%-- to reason otherwise would 
minimize the subtlety and indeterminacy 
of human speech, which is complete 
different than the mechanistic 
engineering of software code %-- 
I think these systems in particular 
are structurally complex, relatively 
speaking, and operationally 
non-trivial, revealing interesting 
overlaps between these two forms 
of language notwithstanding 
their ontological contrasts. 
`p`


`p.
If these are shared structures across 
both natural and computer language, 
one might reason that similar 
formations would likewise apply 
to `q.robot` languages, to the degree 
that %-- as I hypothesized above 
%-- an optimal robot language would 
lie at some intermediate distance 
between human speech context-sensitivity/indeterminism 
and computer code's mechanism.  
`p`

`p.
If it is true that the proper semantics 
for computers and analogous computationally-engineered 
artifacts (such as robots) is `i.procedural`/, 
so that the `q.meaning` of an expression in 
`q.language` (however rigid or artificial) is 
the procedures which it designates or which 
supply its implementation, then analyzing this 
semantic requires explaining the 
environment within which procedures 
operate.  This does not mean only 
one single procedure %-- the context 
that obtains prior to its starting and 
subsequent to its ending %-- but from a broader 
vantage point the settings in which 
we can speak of groups of procedures 
executed in sequence, forming an 
aggregate unit of computational activity.  
As I pointed out at the start of Chapter 20, 
most software applications are designed 
to enter passive states awaiting user 
input.  It is only after a user-driven 
`i.event` %-- due `i.gestures` such as 
clicking a mouse button or tapping a keyboard 
letter/symbol %-- that applications launch a 
series of procedures responding to 
the user's (presumed) intent.  Typically 
the series concludes with some visible 
change to application state (typically something 
the user sees on-screen) and then the 
initial passive state is re-entered.  
As such, the canonical context for software procedures on 
aggregate is the bounded by the 
`i.initial` user action (which sets parameters 
on how the application reacts) and the 
eventual (usually on-screen) content 
presented to the user.  To the degree 
that computers have `q.semantics`/, 
we should analyze such semantics in 
terms of whatever intermediate 
processing connects the start of 
these sequences (user gestures) to 
the end (user-visible content).   
`p`


`p.
In the case of robotics, the details are 
similar, except that most robots do 
not primarily function merely by 
presenting information on-screen (unlike 
personal computers or even `i.en situ` 
computer-like devices with touch screens, 
e.g., interactive transit displays).  
A `GUI; console can be one part of a 
robot's equipment, but more broadly 
users expect robots to fulfill user 
intentions by moving themselves and/or 
external objects.  Although robot 
actions might be preprogrammed 
(and they can be semi-autonomous, 
deciding some actions on their own), 
to sustain the analogy with other 
computing systems let's consider 
the case where a robot launches a 
series of actions in response to an 
explicit request by a human user 
(`q.lift the yellow box` or something similar).  
In that case, the robot should respond to the 
request by moving and/or entering a configuration 
where it may physically comply.  (In some 
cases the user input might be provided 
in advance, with the expectation that 
the robot only responds to such information 
actively under certain circumstances; for 
example, robots might be instructed to 
perform some task only after they sense 
a particular kind of change in their environment).
As with `GUI; front-ends to traditional 
applications, the robot's procedures 
propagate in response to user input, 
and have a well-defined end-point, but 
here the terminus of a procedure-sequence 
would (primarily) not be something 
visible on-screen, but rather a  
robot changing its location and/or configuration 
in physical space (possibly affecting 
some external object in the process).   
`p`


`p.
The units of `GUI; presentations are 
`q.application windows` (visible screen areas), 
inside of which are `q.controls` such as 
buttons, labels, scroll bars, magnitude-indicators 
(consider how we drag an icon to partially fill 
or empty a bar, to zoom in or out on a text or graphic 
display) and dividing lines; within those 
controls, in turn, can be text (including numbers) or 
other displays of textual and/or quantitative 
information.  Therefore, the `q.end state` of a 
series of procedures, at the application level, 
would be a change in visible `GUI; display 
through some of these constituent elements.  
Likewise, in the case of robots, 
the components of a robot's `q.configuration` 
would be angles of gears, extenders, wheels, 
and whatever mechanical devices robot's use 
to move and reposition themselves.  At 
the culmination of a procedure-set enacted 
in response to user input, then, the robot 
will in general be a different state with 
respect to their location and the orientation of their 
arms, graspers, mounted cameras, or whatever 
other mechanical equipment they have on-board.  
We can see these physical gadgets as analogous 
to windows, controls, and text/number displays 
in the `GUI; context. 
`p`


`p.
Based on that analogy, deciphering the semantics 
of reactive `GUI; programming can be an 
indirect pathway to formulating semantic 
models appropriate for robots, because 
the constituent parts of `GUI;s provide 
structural analogs (with respect to 
the origination and telos of procedure-sequences 
reacting to user input) to robots' 
movements and configuration.  In both 
contexts, the `q.semantics` of the 
computational system is determined by 
how procedures react to user actions so as 
to yield state-changes (to `GUI;s' visible 
contents and robots' orientations, respectively) 
that are `q.correct`/, or consistent with 
their initial intent, from the user's point of 
view (`q.correctness` in this sense taking 
the place of being `q.meaningful`/, for the 
purpose of semantic formalization). 
`p`


`p.
Given the analogy of `GUI; state to robots' 
orientation, an analysis of `GUI; structures (intended to 
be included in an overall procedural semantics 
for computer code), which will be the focus of 
the following section, can perhaps serve as a 
starting point for further work in robotics and 
other areas that generalize and extend the 
familiar desktop-computing environments. 
`p`

