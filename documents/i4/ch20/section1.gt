`section.Hypergraph Data Modeling`

`p.
I claimed in the introduction that a software 
application's primary role is to await 
user actions and then, in response, 
produce some visual change (in the on-screen display) 
which presents information to the user 
(presumably information relevant to their 
original action), along with possible 
side effects (like saving a file).  
On this account, studies of applications' 
behavior would reasonably focus on 
the starting and ending points of these 
action/reaction cylces: how do we articulate 
the full space of possibilities for users 
to iniatiate actions within the application?  
For mouse-and-keyboard desktop setups, for instance, 
an action like `q.left click` on the mouse 
can be performed at any point in an application's 
window (or windows), and mouse-events could 
click one of several buttons, or turn the 
scrool wheel, and they can be modified by 
pressing certain keys.  In some contexts, likewise, 
users enter data by typing on a keyboard.  
Applications need to systematically model 
all of these possibilities so that they 
can create a data structure which carries 
all relevant details user actions, which 
in turn is requisite for responding correctly 
(left-click and right-click usually have 
different `i.meanings`/, for example).  
At the other end, applications need to subdivide 
their display window into parcels of screen-space 
so that data updates are located in useful 
visual contexts (continuing the above 
example, the Montreal score should be placed 
near the Habs logo, and likewise for Toronto).  This, 
of course, means that the computer screen is 
not just a `q.picture`/; it is an organized system 
which can be analyzed through data models and 
types.  And such analyses can potentially be 
extended to robots and/or Virtual Reality, which 
are not just `TwoD; screens but possess 
`ThreeD; physical or visual-immersive 
(and maybe synaesthetic) configurations. 
`p`


`p.
Well-designed applictions have multiple features and 
are easy or intuitive to use: this means that 
users have a variety of options for 
leveraging applications' capabilities, and 
that it is not difficult for users to 
learn or infer the steps needed to prompt 
their application toward their desired course 
of action.  Applications can generally become 
`q.better` %-- more featureful and intuitive 
%-- by being flexible and subject to continuous 
improvement; that is, applications should be 
designed to acquire more functionality 
over time, and to update their interactive 
interface based on the concrete experience of 
users who may find different features easier 
or harder to access.  For example, specific 
operations might be exposed in different ways, 
in that the user has multiple options for 
initiating certain responses (for example, the 
effects of clicking on a certain button might 
be duplicated by pressing a specific key on 
the keyboard, or by activing the mouse's scroll wheel 
%-- e.g., scrolling down, hitting an on-screen `q.down` 
button, or pressing the down-arrow key).  Many 
applications also allow plugins or extensions to 
adjust the visual displays in ways not envisioned 
by the program's original designers.`footnote.
I adopt the convention that a `q.program` is a 
self-contained software component, something 
that can be executed, and an `q.application` 
is one kind of program: one with a visible 
user interface.  Most programs are applications, 
on these definitions (when discussing technical 
`VM; matters sometimes however we can use 
the word `q.program` in a different sense, as a 
self-contained sequence of `VM; operations).
`footnote`  
This flexibility helps ensure that applications 
can improve and be useful, but more specifically 
they are engineering goals: there are steps 
which developers can take to maximize 
applications' ability to adapt and evolve.     
`p`


`p.
Aside from a generic desire to build `q.quality` 
software, engineering applications for 
future adaptation also prompts develoeprs to 
design software in rigorous, well-documented 
ways.  Applications can be thought of, 
rather metaphorically, as virtual/digital `q.piping` 
linking a tableau of potential user actions (via the 
mouse, keyboard, and etc.) to a space of 
possible screen-configurations.  A software 
engineer's goal is to build up this intermediate 
`q.plumbing` in an orderly rather than haphazard 
manner, so that future programmers have a clear 
picture of how the application's functionality 
can be augmented (without affecting its 
current behavior, unless a conscious decision is 
made to alter the application's pragmatics 
based on user feedback).  Users initiate 
actions so as to invoke application features, 
for example: to organize responses systematically, 
it is important to have an efficient structural 
breakdown of all the functionality which 
the application makes available, by analogy 
to how books might be organized on the 
shelves of a library.  But this structuring 
principle also promotes extensibilty: 
once a system is in place to enumerate 
functionality, it is easier to add 
new features because there is greater 
transparency in how new features can 
`q.slot in` alongside their predecessors.  
Similar points apply to the visual 
display of information: the more 
systematically we model how data types 
recognized by an application are translated 
to visual form, the more readily we can build 
new display units %-- such as isolated 
windows or dialog boxes %-- to display 
`i.new` data types, formulated in the 
course of providing new functionality. 
`p`


`p.
Planning for continuous-adaptation therefore 
implies that application should 
deliberateively model the functionality 
they `i.expose` as features available 
to users: improvements can either 
provide alternative (perhaps more 
user-friendly) ways to invoke these 
same features, or to create 
new features that fit comfortably 
with the existing application 
by honoring its protocols and 
user-pragmatic conventions.  
An important dimension of software design, 
then, is formulating the protocols 
and concrete implementations 
through which applications 
`q.expose` functionality. 
`p`



`p.
Consider an example from the domain of 
image-processing (which will be the focus of 
Chapter 21): Computer Vision software 
will typically have many built-in 
functions that can be used to transform 
and/or extract data from graphics 
images (i.e., pictures, such as 
photographs or satellite images, or individual 
frames lifted from videos).  Exposing 
these capabilities means offering ways 
for users to initiate an image-processing 
workflow.  The result of the workflow 
might be a modified version of the original 
image, or some extracted data structure 
that can be outlined or visualized.  Because 
workflows are often chained together or, 
in general, aggregated to form more complex 
workflows, `q.exposing` functions also means 
allowing operations to be dynamically 
invoked by software, so that although a user 
will manually initiate an overarching 
functionality there may be many 
behind-the-scenes intermediay stages where the 
most users would not directly perceive.  
In this kind of environment applications 
will typically offer an `API; (Application 
Programmable Interface) and/or an 
`ABI; (Application Binary Interface, which 
is more low-level) such that important 
features can be accessed directly through 
user actions `i.and` indirectly 
as intermediate processes launched in response 
to some higher-level user action.`footnote.
I mention `ABI;s here in the sense that 
application-procedures might be exposed 
to be called directly with raw data values, 
in contrast to what I will later call 
`q.meta-procedures` whose inputs and outputs 
are padded with extra layers of indirection.
`footnote`
Moreover, the results of Computer Vision 
workflows will typically be represented 
to users in the same application as 
where they initiate workflows, so 
applications need to expose functionality 
for altering their visual display in 
accord with the details of specific 
pipelines (e.g., presenting a new image 
in a new window).  In short, applications
need to expose both analytic/processing 
functionality and display/visualization 
functionality.   
`p`



`p.
To `q.expose` functionality is to 
offer multiple ways that functionality 
may be accessed: by users directly; by 
engines which step through workflows; 
by application `q.macros`/, which 
are (for some programs) programmable 
sequences of user-actions that typically 
are performed together (the macro 
can applow multiple actions to be 
initiated with one single actio); 
by `q.updates` which can add new 
features without software needing 
to be re-installed; by `q.personalization` 
features which allow programs to enter 
different states depending on the 
identity of their current user; by 
configuration files; and 
by `q.scripting` environments 
where code written in a programming 
langauge (typically one with 
an interpreter that can be embedded 
in standalone software, such as Lisp or 
Python) can modify or fine-tune application state 
and performance.  Supporting such 
personalization and fine-tuning is itself a 
feature that makes software more user-friendly, 
but (for reasons I mentioned `visavis; 
rigorous design) also prompts developers 
to architect software in well-organized ways, 
with a logical model of user actions, visual 
displays, and all the coding that connects 
the one to the other. 
`p`


`p.
An important dimension of application development, 
accordingly, is that of modeling and formalizing 
how applications expose functionality and 
User Interface details.  Virtual Machines, 
in turn, are a useful tool for 
analyzing the features exposed by applications 
(and how they are implementationally tied to 
the application as a whole).  This is the 
primary scenario where I will consider 
`VM; designs as theoretical artifacts in their own right.
`p`


`subsection.Hypergraphs as General-Purpose Data Models`
`p.
Ultimately, all of a program's functionality 
is achieved via procedures, which are provided 
by the software code base (perhaps along 
with third-party libraries that get re-used, 
sometimes as high-level source code and sometimes 
as compiled resources).  As such, one way to  
`q.expose` functionality is simply to allow 
external code (that is, code which is not 
explicitly developed as part of an 
application's core code base) to call 
procedures which `i.are` in the code base.  
The vast majority of such procedures, however, 
are `q.internal,` intermediate computations 
that would not be meaninful for appropriate for 
external access.  Accordingly, applications 
need a more over-arching model of exposed-features 
to ensure that external code utilizes 
internal capabilities in an orderly fashion.  
`p`


`p.
In general, functionality is exposed to 
external components by constructing a specific 
procedure whose role is to be an `q.entry point` 
for externally-invoked features.  That 
is, we assume that any exposed `q.functionality` 
requires multiple procedures to be realized, 
and one entry-point is necessary to 
invoke a larger package of procedures which 
collectively implement an operation that 
we can `i.conceptually` regard as `q.one` 
function.  For example, if an exposed 
capability (in a Computer Vision program) 
is running a superpixel segmentation on a 
`TwoD; image via color-watershed, there will 
be many intermediate procedured needed to 
complete that computation, but we can reason 
about the segmentation as one identifiable 
step in an image-processing pipeline.  
It is a `i.conceptual` function unit even if 
it is not `q.one` function, in the sense of 
one single source-code procedure.  I propose 
to use the term `q.meta-procedure` to 
describe functions that are conceptually 
singular but implementationally multiple, in 
this sense.   
`p`


`p.
Application-level capabilities often require 
certain details to be specified %-- continuing 
the superpixel example, such an operation 
would need to know which image to target, and 
potentially would need certain threshold 
parameters to be specified (superpixels 
are relatively small image-regions of 
similar color, but `q.how` small and similar 
depends on input values that might vary 
from one run to another).  The `q.output` 
of such a segmentation would be a 
data structure (typically a `q.labeling` 
image, which adds an extra number to each 
pixel %-- alongside its existing 
color channels, such as red, green, and blue %-- 
naming the superpixel to which it belongs); 
for visualization, sometimes superpixel 
segmentations will also be displayed by outlining 
the superpixels with a colored boundary 
(visually distinct from the underlying image).  
Thus a superpixel algorithm has inputs and 
outputs analogous to a single procedure.  
However, insofar as such an algorithm is not 
one procedure but rather (in my terminology) 
a `q.meta` procedure, these inputs and outputs 
are not delivered simply as binary 
data values (memory addresses or `CPU; registers) 
but rather need to be marshaled and 
encoded between the software component 
which invokes the metaprocedure and 
the application which exposes it.  
Unlike the execution-sequence `i.within` 
one component, where one procedure 
can call other procedures directly, 
for such `q.meta` procedures there 
needs to be a series of steps 
wherein input parameters are 
built up using a common protocol
which both components can understand, 
and output results likewise 
encoded in reverse.  The procedure/metaprocedure 
contrast is analogous to the difference 
between a face-to-face conversation between 
two parties and a long-distance negotiation 
where diplomats (or lawyers, etc.) exchange 
offers and proposals and counter-offers 
according to a fixed set of rules.  Unlike 
in-person dialog, such indirect 
communication is less open-ended, and 
relies on trustworthy intermediaries 
to convey messages and information without 
distorting their meaning. 
`p`


`p.
What diplomats, lawyers, and mediators 
may be to human communication, their 
analogues in Information Technology 
would be data-sharing protocols 
and `API;s.  Usually, software components 
which interact via these indirect, 
carefully mediated pathways can potentially 
have divergent implementations %-- they may 
be written in different languages, adhere 
to different coding paradigms, and so 
forth.  Therefore, data has to be transferred 
from one component to another via neutral 
formats which are amenable to both 
sides: data in one context should be 
encapsulated in a neutral package and 
decoded (without distortion) on the 
other environment, and vice-versa.  
External-programming interfaces therefore 
depend on data representation systems 
which alow for information to be restructed 
according to the needs of different 
computing environments, while maintaining 
structural integrity (i.e., decoding the 
data back to its original form should 
produce an exact replica of the data prior 
to its originally being encoded). 
`p`


`p.
Ensuring data integrity across divergent 
programming environments is a complex 
task: when being passed between 
components data is necessarily `i.serialized`/, 
or convert from its innate binary/in-memory 
form to a textual or numeric encoding, and 
then reconstituted into a new binary 
package which should be `q.equivalent to` 
the original (we can define `q.equivalence` here 
in terms of bi-directionality: re-encoding the data 
and sending back from target to source, then 
re-decoding, should yield a copy of the original; or, 
more rigorously, modifying a smaller part 
of the received data and then back-sending 
should yield a duplicate of the original 
`i.except for` the specific change).  Data-serialization 
formats need to be designed to ensure that 
information is not lost in the encoding/decoding 
process: for example, a quantity which 
originally has floating-point type (so it `i.could` 
have non-integer values) might get encoded as an integer 
if, in fact, on a specific occasion it has no 
fractional part; then, on decoding, the 
value might be interpreted `i.as` an integer 
(rather than a `b.float` which happens to 
have an integer value), which in turn could 
corrupt future calculations (in some contexts 
arithmetic operations performed on an integer 
paired with a `b.float` will cause the 
floating-point value to be truncated to an 
integer, yielding incorrect results in 
an algorithm which expects both 
values to be `b.float`/s) and/or 
corrupt data sent back to its source.  
Similar incompatibilities may exist 
between expected units of measurement 
(metric versus Imperial, for instance) 
or value-ranges (it is not obvious from a
single number what are the sensible range 
of values which the number could take on, if 
modified: magnitudes for inividual pixel-colors, 
for instance, in most image-formats are 
restricted to the range 0-255; percentages 
are often limited to 0-100; angles 
in degree to 0-359, and so forth).  
Failure to anticipate the full set 
of metadata conventions and standards 
which are prerequiste for multiple 
software components to act on shared 
data is a common source of data-corruption.  
`p`


`p.
For these reasons, data-sharing protocols 
need to be designed around detailed and 
`q.expressive` representations, meaning 
that it is possible to systematically 
describe all facets of data profiles 
(types, ranges, units, scales, metadata) 
that could potentially be sources of 
ambiguity and encoding/decoding errors.  
To be sure, a lot of data-sharing happens 
through relatively simple formats 
(such as `JSON; %-- JavaScript Object Notation 
%-- or `CSV;, comma-separated values) 
which lack these higher-level guidelines, 
but such formats typically work in 
contexts where networking conventions 
are clearly defined %-- effectively 
relying on programmers' discipline and 
informal documentation to take the place 
of stipulations formally encoded in data 
protocols.  In more `q.critical` contexts 
which should be less susceptible to programming errors 
%-- or for more open-ended protocols 
where networking between disparate end-points 
should not depend on programmers diligently 
honoring informal specifications %-- developers 
would tend to prefer more rigorous 
representations, such as `XML; (with 
validators and predefined tag and attribute sets) 
or `RDF; (Resource Description Framework), 
associated with the Semantic Web (in conjunction 
with explicit Ontologies).    
`p`


`p.
In this chapter I will discuss options for `i.hypergraph` 
representations (which in some sense generalize 
`RDF;, considered to be `q.graph-oriented`/, but, 
unlike hypergraphs, not internally multi-scale).  
I claim that hypergraphs are more effective 
at permitting rigorous data profiles to 
be described and confirmed (i.e., we can 
formulate hypergraph data paradigms that are 
more expressive still than, for instance, 
`XML; and `RDF;) while retaining the necessary 
attributes of formal verifiability and 
transparency.  Indeed, hypegraph models 
in various forms have been proposed as 
extensions to both `RDF; (for example, in 
the transition from graph database engines 
to Hypergraph engines such as HyperGraphDB, 
Grakn, or AtomSpace) and `XML; 
(in the context of `q.concurrent` markup 
and related supersets of `XML; trees, 
which tend to focus on allowing tags 
to overlap one another instead of 
being strictly nested, as they are 
in `XML; and its variants, notably `HTML;).   
`p`

`p.
Although data (meta) models are an important 
theoretical topic (particularly when 
the discussion turns to optimization, so that 
we are considering not only `i.whether` 
queries or validations can be completed, but 
how to do so efficiently), here I am 
equally concerned with practical software concerns: 
in particular, the coupling between `i.representing` 
information and `i.exposing` application 
functionality.  The most common reason we seek 
to (digitally) encode data is to send it between 
separate components (including ones designed 
with little or no explicit inter-connections, 
except for joint participation in data-sharing 
capabilities which have to be implemented 
`i.ex post facto`/).  Metamodels are most 
valuable when they permit inter-operative 
capabilities in an additive manner: applications 
should be able to expand the scope of 
other applications with which they might network.  
Representational systems which engender 
computational artifacts (parsers, for syntax, and 
validators, for semantics, let's say) that can be 
implemented, embedded, and leveraged by applications 
as their capabilities are refined to support new 
protocols are most effective when the amount of 
effort consumed by the requisite programming 
is minimized.  Data-sharing protocols should be 
engineered to pass through application-integration 
phases as quickly as possible, but likewise 
applications should be architected to accommodate 
new data-sharing initiatives without 
substantial re-coding.  
`p`


`p.
Generically, we can describe a metamodel as 
relatively `q.expressive` to the degree that 
data structures and their concomitant semantic 
paradigms can be transparently encoded 
according to modeling system's rules.  
Expressivity might imply a level of 
redundancy, or at least superficial 
redundancy when viewed from the 
sole perspective of data encoding.  
For example, so-called `q.Industry 
Foundation Classes` %-- widely used 
in `AEC; (Architecture, Engineering, 
and Construction) technology and 
`BIM; (Building Information 
Management) %-- employ two different 
sorts of data annotations (called 
`q.attributes` and `q.properties) which 
both are roughly analogous to `XML; 
`q.attibutes`/.  The `IFC; attribute/property 
distinction might seem locally superfluous 
in that asserting a given data-point via a 
property rather than an attribute 
(or vice-versa) does not appear to 
convey greater information %-- the 
information is borne by the 
field's value, not by its property-or-attribute 
classification.  However, this distinction  
is not semantically vacuous; 
its significance emerges in the larger 
scale of schema-standardization and validation.  
Data fields asserting properties 
of objects (in the sense of real-world 
physical materials incorporated into building designs) 
are classified as either `i.attributes` or `i.properties`/, 
with the distinction being that attributes are fixed within 
schemata for objects of any given kind, whereas property-sets 
can be introduced in objects' context more flexibly.  
In type-theoretic terms, attributes are immutable parameters 
in types' schema, such that objects of the same type have 
the same attributes, whereas properties are not bound to 
types with equal force (usage patterns might dictate 
that, for example, common type-instances share property-sets 
`i.in some context`/, but these are not essential maxims 
of the type itself).
`p`

`p.
In the realm of bioinformatics, 
A similar distinction is made in the 
context of `DICOM; (Digital Imaging and Commmunications 
in Medicine) wherein `q.tags` (which have descriptive labels 
but also two-part numeric codes) are encoded using a system 
that distinguishes `q.Standard Data Elements` from 
`q.Private Data Elements`/: 
tags encoded with a numeric pair whose `q.Group` 
(first) Number is odd.  `lPACS; (Picture Archiving System) viewers 
(software that recognizes the `DICOM; format) will ignore 
Private Data Elements by default, so the Standad/Private 
distinction is intrinsic to protocols through which 
`DICOM; data is processed.  This distinction is not 
functionally identical to `IFC: attributes/properties, 
but reveals similar motivations insofar as data specifications 
are also guidelines for implementing software which 
manages data structures conformant to a given standard.  
Standardization projects' tasks include definine requirements 
on software as well as data representation, and it is 
logistically significant to distinguish standardized 
parameters that software `i.should` recognize as a 
compliance-criterion from non-standard kinds of values 
that particular users or groups of users working 
within a given protocol may want to introduce internally.   
`p`


`p.
The `BIM; attribute/property and `DICOM; Private/Standard 
distinctions are suggestive illustrations of challenges 
encountered when applying generic data-modeling principles 
to specific domains.  Most general-purpose representation 
frameworks (consider `XML; and `RDF;, for instance) lack a 
mechanism to directly express disjunction in parameters' 
level of standardization, as concretely found in these 
examples (not to imply that such details could 
not be represented indirectly, e.g. via meta-attributes 
or `DTD; stipulations, but the point is that 
one is thereby leveraging the affordances of a 
given representation scheme to accommodate semantic 
distinctions not specifically anticipated by that 
scheme, rather than organically encoding the 
semantics to begin with).  Also, note that for 
fields indexed by character-strings descriptive labels 
are designed to be meaningful for human users/readers, but 
in most modeling approaches labels do not have an 
`q.internal structure` recognized by the framework 
(at least if consider, say, `XML; namespaces as separate 
labels from element names).  The `DICOM; pattern wherein 
two-part numeric codes are employed for something 
akin to namespace/element separation, and then the 
use of an odd/even to signal Private/Standard tag rules, 
is also an idiosyncratic formulation which does 
not have a natural correlate in multi-domain modeling protocols.   
`p`


`p.
Data-representation theories which are grounded 
solely in `q.logical` reasoning, or mathematical 
representation, can miss such real-world 
complications: if we start from symbolic 
logic (or from a mathematical picture of 
graphs or trees as formal systems) we might 
be inclined to recognize `i.properties` 
(essentially metadata on graph sites, which 
is how properties work in conventional 
Property Graph database engines), or `i.attributes` 
in the `XML; sense (metadata on tree-nodes), 
but our theoretical framework could neglect to 
consider the possibility that a data-sharing 
protocol might need two `i.different` 
property/attribute mechanisms.  The semantics 
of a property/attribute distinction (in contexts 
such as `IFC;, or `DICOM; public/private) derives 
not from logical models but from 
real-world implementational concerns.    
A metamodel which supports this larger semantic 
context is therefore sufficiently expressive 
to properly encode `IFC; or `DICOM; data; a less expressive model 
(one which collapses attributes and properties 
into a generic notion of `q.fields`/, say), would 
fall short, at least without compensating 
by leveraging its own formal resources 
(e.g., classifying fields as attributes or 
properties via `q.meta-data` fields).  
Here we can appeal again to application-level 
concerns: the paucity of less-expressive 
systems would become evident insofar 
as reifications, indirections, and other ad-hoc 
solutions to representational blind-spots 
can render application-integration more complex 
and time-consuming.      
`p`


`p.
Metamodels are more expressive to the degree that 
they offer a greater range of representational parameters 
with which structural and semantic conventions 
might be communicated.  For example, `JSON; 
can be deemed more expressive than primitive `CSV;-style records because 
`JSON; distinguishes arrays (which are structurally akin 
lists) from `q.objects` (i.e., associative arrays, 
lists indexed by field-names rather than numbers).  
Likewise, `XML; is more expressive than 
`JSON; insofar as elements' data can be asserted 
via attributes or via nested 
elements (for sake of argument, treating `XML; 
as a de-facto superset of `JSON; wherein arrays 
correspond to sequences of similarly-tagged child 
nodes).  Associative arrays in `XML; might 
be coded `i.either` as attribute key-value 
pairs on `i.one` node `i.or` as sibling nodes 
with unique tag-names.  This `q.redundancy` 
allows for conventions to cohere 
(in a given data-sharing protocol) stipulating 
when either of these alternatives should be 
used, thereby supplying an extra layer of 
semantic detail which is not present in `JSON;.  
`p`


`p.
In the case of property graphs and/or hypergraphs, 
data fields can be associated with an `q.object` 
(in the sense of an integral data structure) 
via properties (attributes on a node) or via 
node-to-hypernode relations (sometimes called 
`q.projections`/), a duality reminiscent 
of property/attribute in `IFC;.  Graphs, 
of course, have the further stipulation 
that any two nodes (or hypernodes) may be 
linked by edges (themselves equipped 
with labels, label-namespaces, controlled 
vocabularies, and potentially constraints/axioms 
enforced by `q.Ontologies`/).  Formats such as 
`XML; and `JSON; which are more `q.syntactically` 
oriented tend to be hierarchical, in that 
any specific value in a `JSON; object or array may 
itself be another object/array (rather than atomic 
value) and likewise `XML; elements may have other 
elements as children.  By contrast, formats 
such as `RDF; and property graphs which are 
more `q.semantically` focused tend to be 
graph-like and encode semantic relations via 
edges across nodes (rather than hierarchical nesting).  
Hypergraphs potentially combine both styles of 
representation, with hypernodes containing 
nodes hierarchically `i.and also` edges 
between two (or two-or-more) nodes and/or hypernodes 
(the precise rules as to which constructions are 
possible will vary from one system to another, but 
these are reasonable approximations). 
`p`


`p.
Any representational system, as these examples point out, 
provides a range of parameters that 
can be pressed into service when formalizing a protocol 
for encoding specific kinds of data via structures 
conformant to the specific system.  More expressive 
systems have a wider arsenal of parameters; for 
instance, along the lines of the above gloss, property 
hypergraphs (models which either add hyperedges to property graphs or, 
equivalently, add properties to hypergraphs) 
are more expressive than either property 
graphs or document-style hierarchical trees 
alone, because properties-on-nodes (as in `XML; attributes), 
nested hierarchies (hypernodes containing child nodes akin 
to child `XML; elements), and inter-node connections 
(as in Semantic Web labeled edges) are all potential 
representational devices in the property-hypergraph context.  
One conclusion to be made here is that property-hypergraphs 
form a flexible general-purpose 
metamodel, but the relevant point for the 
moment is that expressivity can be `q.measured` via 
the range of distinct representational parameters afforded by 
the system, at least intuitively.
`p`


`p.
This intuition can be made more precise, insofar as 
I have deferred any rigorous definition for 
`q.representational parameters`/.  That is to say, for a 
reasonably systematic analysis of metamodels we should 
specify building-blocks of constructions 
recognized through any metamodel.  The overall 
concept may be clear enough %-- in general, 
the parameters of a modeling system are the full set 
of structural elements that might potentially 
be employed in fully describing any given 
structure covered by the system %-- but one would 
like a still tighter definition.  For this chapter, 
I approach this problem from the 
perspective of Virtual Machines.
`p`


`subsection.Virtual Machines in the Context of Data Metamodels 
and Database Engineering` 
`p.
The correlation between Virtual Machines and 
representational paradigms should be clear: suppose 
we take any structure instantiating a particular 
metamodel.  Presumably, such a structure 
can be assembled over multiple stages.  Insofar 
as node-hypernode inclusion is a constructional parameter, 
for instance, then a structure can be modified 
by a including a node within the scope of a hypernode.  
Similarly, insofar as inter-node relations (via directed 
edges or hyperedges) are significant constructions, 
then a structure may be modified by adding an edge 
between existing nodes.  In short, any structure 
can be derived from the modification of precursor 
structures.  The full set of structure-modifying 
operations available for a given representational 
paradigm can be enumerated as (at least on part of) 
the opset of a hypothetical (or realized) 
Virtual Machine.  As such, Virtual Machines 
provide a potential formalizing environment 
for analyzing data metamodels.  
`p`

`p.
Conversely, data-models can serve as a prompt for 
motivating the proper scope of a Virtual Machine.  
That is, `VM;s 
may be designed subject to requirements that 
they permit the accumulation of any data structure 
conformant to a given metamodel.  Similarly, `VM;s 
might be characterized in terms of how they support 
various `q.calling conventions`/, in the sense of 
protocols through which computational procedures 
delegate to other procedures (supplying inputs, 
reading outputs, spawning concurrent 
execution paths, and so forth).  This section's chapters
will focus on `VM;s based on hypergraph 
data models, employing such structures 
both from the perspective of data-representations 
and interlocking procedures (i.e., describing 
procedures in terms of sequences of 
calls to other procedures).   
`p`

`p.
Virtual Machines can be useful tools for studying software-interoperability 
insofar as both data-representations and communications protocols 
can be modeled in terms of `VM;s (at least as abstract summaries 
of working code; or, more ambitiously, application-networking 
frameworks can be provide actual `VM;s through which applications 
can route their networking logic, analogous to query languages 
as host-language-agnostic conduits for database access).  
As emphasized earlier, applications typically 
seek to `q.expose` functionality to external 
components.  In order to do so rigorously, 
it is necessary to stipulate preconditions 
on how functionality being externally invoked 
should be designated %-- for instance, if a Computer 
Vision application has multiple algorithms available 
for many processing tasks, external code needs to 
specify which implementation is being requested %-- 
and how input parameters (and then output results) 
should be encoded.  Applications can use 
`VM;s as a kind of neutral environment where 
third-party code can build up a representation 
of exposed-functionality invocations 
incrementally.  Indeed, many programs support 
scripting via languages such as Python; it 
is plausible to generalize this idea to 
`VM; platforms amenable to multiple scripting 
languages, so long as they can be compiled 
to the relevant `q.byte` code.  Alternatively, 
even if applications do not expose `VM;s 
to third parties directly, they could 
use `VM;-backed processes to process 
`API; requests: since `VM;-targeted code could be 
updated without recompiling the application, 
the `API; could then adapt to new networking 
situations.        
`p`


`p.
In this context `VM; models overlap with constructions pertaining to 
interoperability between applications and database engines.  
Consider the general setup of database systems: applications 
store data structures for future reuse by passing some 
(suitably encoded) serialization of the relevant information 
to a database, which arranges the data into a layout 
optimized for storage and retrieval/querying.  Typically the 
database will attempt not merely to preserve the presented 
data structure for future reconstruction, but will 
index or destructure it in such a manner that such specific 
data can be selected as matching a future query.     
`p`


`p.
At any moment in time, an application will be working with 
one or more data structure that might be called `q.live`/; they 
are directly implicated in the state of the application at 
that moment.  The current user (or a different user) might, 
accordingly, be interested in reconstructing that 
application-state (or some relevant subset thereof) at a 
future point in time; at which point database queries are 
typically necessary, because the relevant information is 
no longer in live memory.  To be sure, a database does 
not necessarily store `q.application state` as such 
%-- although developers can potentially 
create `q.application state objects` and persist 
those so that users can resume prior sessions %-- but 
a typical rationale for persistent data storage 
in the first place is functionality supporting 
users' desire to resume prior work, return to 
previously-viewed files, and so forth.  The 
individual values stored in a database derive their 
significance from how they interconnect 
in users' experience in the context of any application.   
`p`


`p.
As a concrete example, suppose we are considering an application 
which (at least as one of its features, and in the context 
of particular `GUI; windows or components accessed through 
the software) supports viewing, tagging, and annotation 
`TwoD; images (e.g., photographs).  Imagine an 
image database allocated for documenting 
ecological and/or infrastructure damage 
from natural or man-made events, such as 
the 2022 Russian invasion of Ukraine, and perhaps 
setting the stage for reconstruction plans.  
A typical image for such an application might be a 
photograph of damaged building or facilities, 
or plots 
of land on which real estate will be rebuilt.  
Potentially,  
images would depict remnants of prior buildings that 
were destroyed, and/or could be annotated with 
data relevant to reconstruction designs 
(e.g., in recreating damaged neighborhoods 
a certain number of residential units might 
be targeted for each parcel of land or each block 
subject to redevelopment, perhaps optimized by 
models measuring the ideal urban density for 
that specific neighborhood based on environmental 
criteria, utility grids, public transit, and so forth).  
A typical session for such an software component 
might involve users viewing individual images, 
previewing image-series depicted via thumbnails, 
searching for images (based on criteria such as 
street address, city/district name, or perhaps 
`GIS; coordinates), switching between `TwoD; image 
and 3D street views, and %-- once in the context 
of a specific picture %-- viewing annotations 
and other associated data in tabular or 
otherwise structured forms (e.g., tables or key-value 
pairs displayed through independent `GUI; windows 
floating above the graphics viewport).  
`p`


`p.
Assuming such an application works with relatively 
large image-collections (enough to be impractical 
for users simply to browse images in a filesystem 
folder, say), functionality for finding and tracking 
images would need to be based on some 
systematical query capabilities, i.e., some 
form of image database (which need not imply 
that images themselves are stored as database 
`q.blobs` %-- binary large objects %-- but 
at least that image file paths, feature sets 
for retrieval/similarity searches, metadata 
and formatting details, etc., can be hosted 
in a database so that images can be selected 
inside large series by variegated query strategies).
Suppose an image depicts a city block where 
damaged buildings have to be replaced; data 
associated with the image could include 
estimates of the number of people who lived in 
that location prior to (for example) 
the Russia/Ukraine war; the number of 
residential units slated for redevelopment; 
cost estimates; links to public transit info, 
street views, data concerning utilities grid, 
etc.  Plausibly, such data would be held 
in a database and loaded alongside the image, 
or in response to user actions signaling an 
interest in the relevant data-points.  The 
database, in effect, is a means to an ends, 
whereas from a user's perspective the 
important detail is that the application 
can enter a state where multiple important 
data-points are visible side-by-side: users 
might view a photograph in one window juxtaposed 
with a window or windows showing civic/residential 
data.     
`p`


`p.
Continuing this specific (hypothetical) example, the 
envisaged scenario has image-viewport components 
serve as an entry-point for a diversity of 
civil/architectural information; presumably 
the specific kinds of data available will vary 
from one image to another, and users will 
signal through interactive `GUI; features 
their interest in accessing certain branches of 
the available data over others.  That is, assume 
there is not a fixed metadata/associated information 
package that automatically accompanies each image, 
but instead that data and images are linked on a 
dynamically changing case-by-case basis.  That setup 
would call for a coding strategy which works to 
organize the available information and 
user-interaction pragmatics coherently.  
The resulting software-design choices would, 
moreover, propagate to `GUI; and database designs 
as well.  Once some aggregate of data is identified 
as a coherent unit, this structural decision 
must be accounted for at the `GUI; level 
(insofar as users request `i.that specific` 
data from application-states where they are 
viewing an image carrying the appropriate 
information) and the database-integration level 
(`q.that specific` data has to be 
queried from the larger database context when needed).  
In other words, the interaction between `GUI;, database, and 
application logic is more complex than if each image were 
given a fixed set of data fields isolated from user pragmatics.
`p`

`subsection.GIS Databases and Digital Cartography`

`p.
This discussion has now touched on themes related 
to flexibly-typed database systems: the idea 
being that expressive database engines support 
`i.strongly typed` data (in the sense that 
all records have type attributions that 
offer guarantees about their internal 
structure, such as a specific set of 
defined fields) but also allow new types 
to be introduced into an active database.  
A good case-study of where such design 
is apropos is that of maintaining 
geospatial databases that track information 
associated with geographical coordinates 
%-- for example, roads, bridges, buildings, 
waterways, transportation infrastructure, 
or land-plots, but also any kind of scientific 
data (environmental, sociodemographic, etc.) 
that can be overlaid on a digital map.  
`lGIS; systems are typically divided into 
two distinct data categories: there are 
`q.basemaps` which represent the most 
common or generic types of `GIS; data 
(roads, buildings, and the like) that are 
then augmented with supplemental `q.data layers` 
that are narrower and more domain-specific 
(such as ecological data).  Digital cartography 
renders `i.basemap` visuals by 
subdividing geographic areas into relatively 
small segments (within a 256`times;256 area, for example)  
translating geospatial (typically latitude/longitude) 
coordinates to pixel-coordinates.  Digital maps 
are composed at multiple scales of resolution; 
in a common format, so-called `q.XYZ` tiles, 
the lowest zoom level produces a `q.map` of the whole 
world (basically an outline of the continents) 
whereas the highest level (around 20, or slightly less 
depending on the environment) is sufficiently 
detailed that maps can show the contours of 
individual buildings and street-intersections.  
In XYZ, each successive zoom level doubles 
the underlying magnification, so that 
each tile at one level splits into four 
tiles at the enxt level.
`p`


`p.
Software known as `q.tile renderers` and `q.tile servers` 
map latitude and longitude coordinates (or 
other `GIS; units, such as those of Marcatur projections) 
to tile-coordinates that include zoom level as 
one axis (e.g., the `q.z` in XYZ).  An XYZ triple 
designates a specific gegraphic area at a specific 
zoom level; individual latitude/longitude and Mercatur 
points can then be identified via fractions of the 
tile width and height.  Via such a mapping, locations 
of objects in a `GIS; database are converted 
to pixel-coordinates, so that features such as 
roads and building can be marked visually.  Tiles 
are rendered according to graphical rules called 
`q.styles`/, which stipulate details such as 
the colors that should be used to outline buildings 
or roadways, or the icons for points of 
interest (transit stops, historical sites, special-purpose buildings 
or areas such as schools, hospitals, parks, 
government offices, and so forth).  Tile-rendering 
requires some computational algorithms because 
streets/highways and other noteworthy spots need 
to be named or labeled, and the positioning 
of these identifiers (unlike the fixed latitude-longitude 
of the labeled locations) is indeterminate, so cartographic 
engines try to calculate how to position street-names 
(for example) so that this text does not intersect with 
other map data (such as roadway lines).  
`p`


`p.
The end result of a tile-rendering pipeline 
is a miniature map in the form of an `i.image`/, 
often in a format such as `PNG; equivalent to 
many photographs; a `GIS; application will 
form maps that users see by composing together 
multiple tiles.  This provides the `q.basemap` 
layer, representing a general-purpose 
view of a given geographic region.  On top of 
these base maps, applications will usually 
superimpose domain-specific data points 
(sometimes called `q.attribute` data) relevant 
in specific contexts: data layers might 
show locations where Ukrainian buildings or infrastructure 
was damaged in the 2022 war; or distributions 
of COVID-19 cases; or environmental hazard sites; 
or tax lots and zoning codes for architecture, 
real estate, urban planning, and 
property management; or sightings of specific plant or animal 
species, and so on.  In effect, whenever 
scientists or researchers have data sets indexed 
by geographic coordinates %-- epidemiological, 
ecological, sociodemographic %-- such information 
can potentially become a Data Layer which 
is visualized by superimposing special-purpose 
icons or colorations on a generic basemap.  
These extra layers can be added at different processing 
stages: for instance, they might be consumed by 
the tile servers themselves, as a post-processing 
step immediately after rendering basemap tiles; 
or they could by superimposed on basemaps 
by `GIS; front-ends,  
immediately prior to showing maps to users 
(in this case applications would typically 
download tiles and data layers separately, 
and merge them together at the last moment).   
`p`


`p.
I provide this digital-cartography overview mostly 
to mention certain details concerning 
`GIS; data systems: although there is a core 
dimension of familiar mappable elements 
(roadways, buildings, and so forth) with common 
presentation guidelines (formalized via tile-rendering 
styles), the space of information that 
could be added on base maps is open-ended.  
Any data set with latitude/longitude coordinates 
(or fields convertible to such coordinaets, such as 
street addresses) can be visualized against 
the backdrop of a `GIS; basemap.  If we consider 
`GIS; data to encompass common basemap info 
`i.together with` special-purpose supplemental 
layers, then `GIS; databases are a good 
example of `q.strong but flexible` typing: it is 
impossible for a `GIS; system to anticipate 
`i.a priori` the full range of data profiles 
evinced by objects visualized in a map 
context, within supplemental data layers.  
Every mappable object will have latitude/longitude 
coordinates (or a collection thereof, giving a 
geometric outline), but in addition objects will 
have other data-points as well, relevant to 
their specific domain (civil engineering, etc.) 
but opaque to mapping applictions themselves.  
In this sense `GIS; systems manage non-`GIS; 
data by tracking opaque objects without 
consuming them directly: it is 
up to individual applications to 
download data within supplemental 
layers and reconstruct the relevant 
domain-specific info, so that 
users can employ street maps as 
entry points for accessing 
information which is then visualized 
through other features in the 
application.  For example, urban planners 
taking on the responsibility of rebuilding 
Ukrainian cities might start with street 
maps showing sites of destroyed 
buildings and infrastructure, and 
then (typically by clicking on a map) 
transition to windows showing structured 
data about individual locations, such as 
the number of families formerly living in a 
damages residential complex, or details 
about utilities and water/gas/electricity 
grids, or estimates of environmental 
hazards (chemical leakages, say, or 
unexploded munitions) resulting from the 
conflict.  The point here is that 
objects containing such domain-specific 
data need to be packaged and stored 
in a `GIS; database even if they are 
not `GIS; data proper, and then 
correctly reconstructed and presented 
to users in conjunction with digital-cartography 
front-ends.  This data-management workflow 
is analogous to the case of routing data 
packages across third-party networks 
discussed above.
`p`



`p.
By way of illustration, suppose one information-bundle that 
could be associated with (some) photographs outlines 
redevelopment plans: data points such as the number 
of residential units targeted, renderings of building 
designs, contractors, contact information, and so forth.  
Presumably, such data would only be applicable 
to images showing blocks or plots where such plans 
are in the works; and moreover such images would link 
to other forms of data as well (about, say, utilities 
grids).  As part of the empirical background, in 
effect, one might conclude that various facts 
pertaining to individual reconstruction projects/contracts 
can both be aggregated (as interconnected data-points) 
and isolated from other information potentially 
relevant to an viewed image.  In general, software 
design depends on sensitivity to how information spaces, 
practically speaking, can be carved and organized.  
The decision to isolate (say) construction-project 
data as integral units would be made against 
that kind of design/decision context.  Having 
this topic reified as a specific `q.category` of data, 
say, affects `GUI; programming and event-handling 
(because user-visible components must be implemented 
enabling users to access information in that 
category, which in turn yields signals like 
context-menu activations and the need for appropriate  
event-handlers) as well as database interop (insofar 
as such data has to be packaged in persistable forms). 
Subsequently, representations of such integral construction-project 
data (in the form of, e.g., a cluster of interrelated 
datatypes) would be manifest as software artifacts 
threaded through a code base.
`p`


`p.
The specific patterns of data organization and programming-language 
types engineered for an application reflect practical 
concerns and aspirations to optimize User Experience; these patterns 
do not necessarily map neatly to native database 
architectures.  Neither relational databases (built up from 
tables with fixed tuples of single-value columns) nor 
conventional graph databases (whose representations are confined to 
one layer of labeled edges) generically match the 
multivariate and multi-level structure of real-world information 
typically managed at the application level.  This is why 
application-level data types generally need 
to be restructured and transformed when routed between applications 
and database back-ends.  
`p`


`p.
Software engineers are responsible for ensuring a proper 
synchronicity between application and database state, although 
(as intimated above) this does not (by and large) entail 
application-state being directly persisted in a back-end.  
Instead, back-end updates are a property of application-state at certain 
moments; insofar as users have performed edits or in general 
made changes resulting a mismatch between the data as 
currently seen by the user and what is stored in the database, 
the latter has to commit such changes for perpetuity. 
Update-worthy application-state then needs to be 
distributed over (potentially) multiple database 
`q.sites` which are collectively implicated in an update.     
`p`


`p.
For sake of argument, consider an update (or part thereof) consolidated 
into a single (application-level) datatype instance; e.g., 
one object of a given `Cpp; class.  Quite possibly, there is 
no one-to-one correspondence between application objects and 
database values or records, particularly if the classes 
in questions contain many data fields and/or multiple 
one-to-many relationships and values which are more 
involved than simple strings or numbers (e.g., pointers 
to other objects).  The structural mismatch between 
application data and database records is evident in 
technologies such as Object-Relation Mapping (`ORM;) 
%-- or `q.Object Triple Mapping` for the Semantic Web %-- 
marshaling data for relational databases or triplestores, 
respectively.  Engines with more flexible 
representation paradigms, needing less reconstruction 
of application data exported to a back-end, can be 
advantageous precisely because data-persistence 
capabilities end up consuming less `q.boilerplate` code.  
Hypergraph databases are a case-in-point: the kind of 
complexity in datatypes' internal orgnanization 
(multiple multivariate fields for a single object, 
for instance) which give rise to `ORM;/`OTM;-style 
transforms map organically to hypernode or hyperedge 
constructions. 
`p`


`p.
Modifying a database entails conveying a package 
of database between applications and the database 
engine; the structure of this `communique; 
in turn reflecting database architecture.  
The `SQL; `INSERT; 
statement, for example, derives its form 
from the layout of table-base data models:  
adding a record entails naming the table to which it 
will belong, which brings on board the specific 
list of fields (columns) whose values have 
to be accounted for in the query.  Our impression that 
relational algebra is a relatively crude or inflexible 
meta-model derives, it would seem, in large part 
from the quantity of bridge code needed to implement 
database updates through query commands such as 
`INSERT; that are restricted to the relational 
architecture.  To the extent that hypergraph 
engines (for example) are more flexible in principle, 
this advantage only becomes concretely 
evident to the degree that hypergraph databases 
support a query system such that updates (and 
analogous modifications to a database instance) 
are initiated with relatively less 
boilerplate code.    
`p`


`p.
As I alluded to earlier, hypergraph data models 
have comparatively greater parameters available 
for representing information; in particular, 
this implies that we have greater 
flexibility in formulating queries 
to modify database instances.  It is worth mentioning 
at this point that `q.queries` need not involve 
instructions passed to a database engine 
in the form of character strings (e.g., 
`SQL; code); indeed, forcing applications 
to build query code on the fly is a often 
an antipattern (spurring boilerplate code-bloat); 
better solutions involve query `q.factories` that 
assemble queries via procedure/method calls 
in a host programming language (perhaps 
through an embedded domain-specific language, 
as one finds with `LINQ; `visavis; `CSharp; and 
its emulations in other languages).  On the 
other hand, in the best case scenario a database 
would `i.also` support a query language that 
could be executed as text strings outside of an 
application context (and without relying on a 
host programming language), for examining 
the contents of a database in situations removed 
from application-based access (debugging, analytics, 
general admin functionality, and so forth).   
In other words, ideally engines will encompass 
a query engine that works with query-structured 
compiled `i.either` from application-code factories 
`i.or` standalone query code, which is one rationale 
for embracing a query-evaluation Virtual Machine.    
`p`


`p.
The specifics of database updates %-- sticking again for 
sake of exposition to single type-instances %-- depends 
of course on types' internal organization.  
For typically atomic types 
(like 1, 2, 4, or 8-byte integers) updates might 
only entail replacing one value with another, but 
more complex values (`q.objects`/, in effect`footnote.Taking 
the perspective that in some systems objects are formally 
defined as aggregate structures (rather than atomic data-points) 
and, even if not precisely stipulated, object/atomic value 
distinctions tend to align `i.de facto` with object-classes 
against, say, built-in types (cf. `Cpp;)`/) with multiple 
and/or multi-value data-fields updates can include 
adding or removing a value from a collections type-instance 
as well as altering such a value, and so on.   
For many compound types the collection of fields 
includes more than one which are in turn `q.collections` 
(e.g., vectors, stacks, queues, deques, and unordered sets/multi-sets, 
plus map-arrays that are pair-lists with possible nonduplication 
restrictions on the first element) subject to add/remove 
operations, in contrast to full-on value-to-value 
replacement.  Some collections have modification-restrictions 
(e.g., values can only be added or removed from one or 
both ends of a list, or, as in typical `q.sets`/, all added 
values must be unique) or enforce constraints such as 
monotone increase and decrease.`footnote.Consider a collections type 
%-- a construction supported by the Virtual Machine I use for 
demo purposes (discussed below) %-- which has only one insertion operation, 
but will automatically place new values either at the beginning or 
end of the list to preserve increase-direction; here, 
new values have to be either greater or less than all 
prior values.  Or, automatically sorted lists need only 
one insertion operation because the insert procedure would 
deduce the proper insertion-point.
`footnote`  All of these are potential paths toward 
legal mappings of type-instances between states 
which initialized typed value can take on, given their 
internal organization.  Nor is this discussion complete; 
we could also mention reclassifying `q.union`/-type values 
(whose instances can be one of several types) or 
various types depending on binary arithmetic 
(cf. tagged/`q.decorated` pointers, or 
enumerations whose value can be members of 
nominal-value lists `i.or` bitwise combinations 
thereof, or unions where multiple type-tags 
are valid by virtue of shared binary encoding, 
in effect using one tagged value to update another 
member of the union %-- a simple case being 
integer/bitset unions where setting the 
integer automatically sets or clears corresponding 
fields in the bitset).  
`p`


`p.
The mechanisms for aggregating multiple values 
into individual type-instances tend to be 
much more complex for general-purpose programming 
languages such as `Cpp; (see unions, pointers, arrays, 
multiple inheritance, enumerations and their 
base types, etc.) compared to databases 
(see `SQL; or `RDF; types); this is a proximate 
cause of complications in persisting application-level 
data.  Conversely, databases with more refined 
type systems can (at least potentially) absorb 
application data more conveniently.  For this 
to work in practice, however, the 
engine needs a query system which can 
duly leverage type-system expressivity; the issues 
involved here are well-demonstrated by 
update-queries as I've mentioned.  Properly recognizing 
application-level intra-type organization 
depends on representing (and then 
exposing to a query interface) the full spectrum 
of morphisms through which a single type-instance 
might be updated.  
`p`


`p.
For complex types, an effective query-system would have 
update operations that are more targeted than 
just replacing one value with another 
`i.tout court`/; instead, updates may only 
involve one or some subset of all data-fields, 
and (for multi-value fields) could involve 
insertions/deletes in a collections context 
rather than a direct value-change.  The degree to 
which a database engine seamlessly interoperates 
with applications depends on the latter 
constructing data-packages (without undo effort) 
that signal the `i.kinds` of updates 
requested alongside the relevant new values 
(notating, e.g., collections-context changes as 
distinct from single-value morphisms).  
Intuitively, flexible architectures 
(e.g., hypergraphs) accelerate the requisite 
implementations, although actually 
supporting a query-interface satisfying 
such ambitions depends on a confluence 
of factors (e.g., underlying database 
architecture but also query-representation 
and query-evaluation protocols and the 
tools to compile code/text or procedurally-generated 
queries to internally-represented structures 
suitable for evaluation).
`p`


`p.
This section's discussion has focused on 
updating a single type-instance centering on 
the point that complex intra-type layout implies 
a diverse set of query-based update options.  
An `UPDATE; statement in `SQL;, say, 
only (directly) supports one 
particular `q.genre` of updates (value-to-value 
edits in one or more discrete columns).  Given application 
state which can be expressed in terms of modifications 
to existing persisted values, keeping the 
back-end in sync entails accounting for the changes 
embodies in the new application-state by 
presenting the back-end engine with (in general) a 
series of updates; the more flexibly updates 
can be encoded, the less development time 
need be expended figuring out how to 
translate application-state changes to updates 
the engine can process.  This is one reason why a 
diversity of data-modeling parameters can 
streamline application integration: a flexibly 
tableau of recognized constructions implies that 
applications can describe updates with 
relatively less boilerplate destructuring.  
Consider the multitude of `q.sites` where 
data associated with a hypernode can 
be asserted, in the context of property-hypergraphs; at least 
(and some systems may have more elaborate 
constructions as well) properties `i.on` a hypernode, 
nodes `i.in` the hypernode, and edges `i.from` a 
hypernode to its peers.  This articulation 
of site-varieties is, self-evidently, also a 
list of update-forms.  Having multiple protocols 
for describing updates allows different forms of 
updates to be recognized with distinct semantics.  
For example %-- consider again the attribute/property 
distinction in `IFC; %-- updates to `i.properties` 
(which would in general be ad-hoc annotations 
on a hypernode less strictly regulated than 
nodes encompassed `i.in` hypernodes) could be 
subject to different validators than updates 
performed via node-insertion or (potentially 
Ontology-constrained) edge-insertion.      
`p`


`p.
In effect, multi-parametric modeling 
tableaus in the database `i.architecture` 
propagate to multi-dimensional 
options for encoding updates, which in 
turn allows for coexisting update 
protocols each with their own semantics.  
Applications can then choose which 
protocol most efficiently describes 
any particular change in application-state.  
`p`


`p.
Of course, these points `visavis; changing 
`i.existing` database value have analogs 
in the context of inserting `i.new` values.  
Ideally, applications will have flexibility 
in how encode data structure for insertion 
into a back-end via database queries.  
This is not only a matter of notating 
all information which should be persisted, 
but also providing cues to the engine 
about how the new data should interact 
with other records (e.g., using 
primary keys or globally-unique 
identifiers to secure inter-record 
links analogous to %-- perhaps 
translating %-- live-memory pointers) 
and subsequent find/select queries.  
What are the criteria through which 
a database record, once deposited, should 
be retrieved again in the future?  Most 
database systems will give nodes/records 
unique id's, but the whole point of 
search queries may be that records 
should be located based on known data 
in contexts where an application does 
`i.not` have the requisite `gid;. 
`p`


`p.
Consider again the case-study of image-curation 
software that could be used in a redevelopment/urban 
planning context, such that photograph resources 
include depictions of future building sites.  
As suggested earlier, data associated with 
each picture could reference construction-project 
data (e.g., the number of units slated for 
construction, or the identity of the firm contracted 
to oversee the project), as well as, perhaps, 
`q.generic` information (image format, dimensions, 
color-depth, plus, say, `GIS; coordinates).  
One consideration when designing such an application 
would be how users would find images 
that they hadn't seen before, or had not 
revisited for an extended period of time 
(so that the presumptive image `gid; is not 
cached in recent history).  In would make sense 
to track images by longitude and latitude, 
for example, assuming that users would know such 
data.  Perhaps street address (accounting for 
the possibility that large-scale redevelopment 
might alter the street grid so that pre-war 
addresses, say, become obsolete; one might 
still maintain a mapping from such addresses 
to `GIS; coordinates so they remain useful 
for queries); or (less granularly) by district 
or city.  We can similarly envisage scenarios 
where architectural details are mentioned 
(`q.find images of sites within a 
10-kilometer radius featuring planned 
buildings over 4 stories tall`/).   
`p`


`p.
For queries along these lines to work, 
back-ends need to structure type-instances 
such that (potentially large collections of) 
values can be filtered into subsets 
meeting specific criteria: `GIS; coordinates 
restricted to a given locale, housing 
matching a given contractor-name, and so forth.  
When exporting info to a back-end, the 
relevant details are not only the specific values 
comprised by the new data but also 
which fields may serve as eventual query-parameters, 
and how they should be indexed.  
Such `q.selectability` criteria have to be 
encoded alongside persisted data structures 
themselves, and convenient application-integration 
entails supporting protocols for 
noting pathways for query-retrieval 
and doing so with minimal boilerplate code 
(for analogous reasons as with update queries).  
`p`


`p.
Of course, selection/retrieval and update protocols 
tend to be defined on types rather than the type-instance 
level.  To the degree that certain data-fields are 
indexed and queryable (for retrieving instances 
when their global id's are not at hand `i.a priori`/) 
decisions as to which fields to thereby expose 
tend to be made for each type %-- as part of the 
type's design and contract %-- rather than 
negotiated on a case-by-case basis per 
instance (though note that properties in property-graphs 
are possible exceptions; indeed this is one 
rationale for property-graphs in the first place).  
Similarly, type-level modeling tends to 
define which update protocols to invoke for 
different state-changes.  Accordingly, an expressive 
query interface should allow stipulations regarding 
updates and searches to be described as attributes 
of `i.types` as well as single instances (e.g., 
records and/or hypernodes) and to be deferred 
from instances to type-contracts (analogously, 
inferred in instance-contexts by virtue of type 
attributions).  An obvious corollary here 
is that query systems have to recognize type 
descriptions as well as encodings of type-instances.  
In effect, query languages need to include 
`q.type-expression` languages where types' 
attributes, internal organization, and 
back-end protocols are duly notated (so that 
type-information can be `q.loaded into` the 
system and consulted as the engine resolves 
how to accommodate insertions, updates, and 
filtering for specific instances).  
`p`


`p.
I will delay further discussion about type-descriptions 
until after examining relevant Virtual Machine 
concepts in greater detail.  Thus far I have 
been alluding to `VM; in the context of query evaluation: 
one way to implement query engines is to decompose 
(the steps needed to execute) queries into 
sequences of primitive or `q.kernel` operations 
supplied through a `VM;.  While this is a productive 
facet of `VM; applications, it overlaps with equally 
consequential issues concerning how `VM; model 
procedures in general (not just those befitting the 
profile of database queries).  Indeed, in general 
a `VM; targeted at query-evaluation should either 
natively extend to or solicit 
(via some kind of native-function interface) 
general-purpose procedures available within 
computing environments where databases and 
applications are situated, because (in principle) 
the results from arbitrary procedures could 
potentially be desired as query parameters.  
If (assuming an object-oriented context) 
back-ends warehouse records encapsulating 
objects with their specific classes, any 
methods called on candidate objects 
(e.g., those not otherwise 
filtered out via the suite of selection-criteria 
in a retrieval query) might plausibly be 
useful as means to narrow result-sets.  
Object-databases proper point to how 
full-fledged method calls may be 
hard to optimize (database contents are 
not typically `q.live` objects that can be 
passed to methods directly), but 
there is no reason `i.a prior` why queries 
should be limited to optimizable  
criteria (for instance, if selective 
stipulations allow results to 
be narrowed to a reasonably small 
set of candidates, fully instantiating 
such potential matches as live-memory 
objects and calling methods accordingly 
would be a reasonable execution strategy).  
In short, even when we are primarily 
interested in Virtual Machines pressed 
into serve as query engines, it would 
be incomplete to exclude consideration 
of general-purpose procedure calls and 
how these are described, validated, and 
executed by concrete `VM;.  I therefore 
turn to procedure-encoding considerations 
in the remainder of this chapter. 
`p`




`p.

`p`








- s=start frame  e=end frame  t=text  y=style 
  p=position 
.

- 

 color:rgba(0,10,37);
 background-color:rgba(200,190,107,250);

.


&type Text_Annotation {7}
  :s:1  :e:3  :t:4  :y:5  :p:6 ;


&type Shape_Annotation {5}
  :k:1  :s:2  :t:4  :d:5 ;
 
&type Circled_Text_Default {15}
  :w:1
  :background-color:2  :foreground-color:6
  :outline-color:10  :font-size:14  :border:15 ;

&type Circled_Text_Annotation {6}
  :s:1  :t:3  :p:4 :pause:6 ;

- s=start frame  i=id



&type Pause_Annotation {3}
  :s:1  :i:2  :t:3 ;



&type Annotation_Settings {6}
  :sa:1  :tr-smaller:3 :tr-larger:5  ;


&/


!/ Annotation_Settings
$sa#  1  1
$tr-smaller#  0  0
$tr-larger#  0  0  
/!
<+>


!/ Circled_Text_Default
$w: 15
$background-color# 250 250 210 255
$foreground-color# 50 50 110   255
$outline-color# 150  150  105  255
$font-size: 8
$border: 2
/!
<+>



!/ Pause_Annotation
$s: 12 
$i: +auto
$t: 55
/!
<+>



!/ Text_Annotation
$s# 10 14
$e: div +span |> ($over-blue) rgba(200, 200, 240, 153)
$t. 
<| XCSD Channel Reductions ... <|
.
$y.
($back2-yellow)
 color:rgba(0,10,37);;font-weight:bold;
 background-color:rgba(7,190,200,50);
.
$p# 22 178
/!
<+>




!/ Pause_Annotation
$s: 17 
$i: +auto
$t: 20
/!
<+>



!/ Pause_Annotation
$s: 22 
$i: +auto
$t: 65
/!
<+>


!/ Text_Annotation
$s# 21 24
$e: div +span |> ($over-yellow) rgba(250,250,207,250)
$t. 
<| Zero-Dimensional Features <|
.
$y.
[$back2-yellow]
.
$p# 22 132
/!
<+>



!/ Pause_Annotation
$s: 29 
$i: +auto
$t: 160
/!
<+>

!/ Text_Annotation
$s# 27  30  
$e: div @7
$t. 
||>
<|| Most image-segmentation and feature-detection algorithms ||>
<|| require that image-data first be reduced from three channels to one ||>
<|| channel. <| The most common equations for this preliminary step ||>
<|| consider the relative lightness or darkness of each color, ||>
<|| ignoring chromatic hues entirely. <| By contrast, XCSD provides ||>
<|| alternative channel-reduction strategies that preserve chromatic ||> 
<|| signals, thereby retaining useful data from the original image. ||>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;
<br>
<|| For many image-processing tasks, channel-reduction algorithms ||>
<|| that use chromatic data are more accurate than those which only ||> 
<|| recognize grayscale quantities. <| The following sections of this ||>
<|| video will show features of the XCSD demo application focused on ||>
<|| comparing and evaluating image-analysis algorithms. <| We will ||>
<|| employ these features to contrast pipeline-results whose ||>
<|| channel-reduction formulae are derived from XCSD metrics ||>
<|| against those based on conventional grayscale mappings. ||>
.
$y.
($white-purple)
 color:rgba(40,10,137);font-size:10;font-weight:normal;
 background-color:rgba(250,250,250,243);
.
$p# 0 15
/!
<+>




!/ Pause_Annotation
$s: 122
$i: +auto
$t: 50
/!
<+>


!/ Text_Annotation
$s# 121  125  
$e: div @7
$t. 
||>
<|| The application now runs through multiple ||>
<|| analyses, generating a series of saved files ||>
<|| representing intermediate processing stages ||>
<|| or visual summaries of intermediate data. ||>
.
$y.
($back-plus-red)
 color:rgb(90,10,37);font-size:10;font-weight:bold;
 background-color:rgba(250,255,250,240);
.
$p# 20 62
/!
<+>


!/ Pause_Annotation
$s: 124
$i: +auto
$t: 20
/!
<+>


!/ Pause_Annotation
$s: 126
$i: +auto
$t: 80
/!
<+>


!/ Text_Annotation
$s# 123  127 
$e: div @7
$t. 
||>
<|| This video will skip over these behind-the-scenes||>
<|| processing stages and will resume when the entire ||>
<|| workflow is complete (which is indicated by passing ||>
<|| a preselected summary file to the main window). ||>
.
$y.
($back-plus-red)
 color:rgb(90,10,37);font-size:10;font-weight:bold;
 background-color:rgba(250,255,250,240);
.
$p# 22 132
/!
<+>




!/ Pause_Annotation
$s: 133
$i: +auto
$t: 30
/!
<+>


!/ Pause_Annotation
$s: 135
$i: +auto
$t: 20
/!
<+>

!/ Text_Annotation
$s# 134  160  
$e: div @7
$t. 
||>
<|| Running analyses ... ||>
.
$y.
 color: rgb(80,35,30); font-size:10;font-weight:normal;
 background-color:200 105 137 250 ~> 130;
.
$p# 20 82
/!
<+>



!/ Circled_Text_Annotation
$s# 136 138
$t: 1
$p# 40 150
/!
<+>

!/ Pause_Annotation
$s: 137
$i: +auto
$t: 14
/!
<+>


!/ Circled_Text_Annotation
$s# 138 140
$t: 2
$p# 60 150
$pause: 13
/!
<+>

!/ Pause_Annotation
$s: 139
$i: +auto
$t: 14
/!
<+>


!/ Circled_Text_Annotation
$s# 140 142
$t: 3
$p# 80 150
$pause: 13
/!
<+>

!/ Pause_Annotation
$s: 141
$i: +auto
$t: 14
/!
<+>


!/ Circled_Text_Annotation
$s# 142 144
$t: 4
$p# 100 150
$pause: 13
/!
<+>

!/ Pause_Annotation
$s: 143
$i: +auto
$t: 14
/!
<+>


!/ Circled_Text_Annotation
$s# 144 146
$t: 5
$p# 120 150
$pause: 13
/!
<+>

!/ Pause_Annotation
$s: 145
$i: +auto
$t: 14
/!
<+>




!/ Pause_Annotation
$s: 567 
$i: +auto
$t: 150
/!
<+>



!/ Text_Annotation
$s# 564  570  
$e: div @7
$t. 
||>
<|| The summary image is marked with zero-dimensional ||>
<|| features (also known as &ldquo;keypoints&rdquo;) detected through ||>
<|| XCSD&rsquo;s channel-reduction technique. ||>
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;
<br><br>
<|| Prior to analyzing the keypoint-distribution mathematically, ||>
<|| it is possible to overview the result-set by checking the ||>
<|| metrics associated with individual keypoints, as seen here. ||>
<br>
<|| In some contexts the keypoint collection could be further ||> 
<|| filtered via these metrics, although the analyses discussed ||>
<|| in this case-study are designed to maximize the extent ||>
<|| of keypoints across a foreground, rather than to filter ||>
<|| and reduce the collection based on geometric properties. ||>
.
$y.
($back-blue)
 color: 0 10 37;
 background-color: 107 190 200 250 ~> 180;
.
$p# 13 11
/!
<+>




!/ Pause_Annotation
$s: 687 
$i: +auto
$t: 40
/!
<+>


!/ Text_Annotation
$s# 680  690  
$e: div @7
$t. 
||>
<|| Next, we examine the distribution of the keypoints ||>
.
$y.
[$back-plus-red]
.
$p# 20 82
/!
<+>




!/ Pause_Annotation
$s: 780 
$i: +auto
$t: 10
/!
<+>


!/ Pause_Annotation
$s: 783
$i: +auto
$t: 120
/!
<+>

!/ Text_Annotation
$s# 782  784  
$e: div @7
$t. 
||>
<||| Many image-processing pipelines are built around zero- |||>
<||| dimensional features; that is, individual locations in an |||>
<||| image where surrounding color and/or color-intensity |||>
<||| variation has a distinct statistical signature. <br><br> 
<||| Preferred algorithms for finding such locations are |||>
<||| usually scale- and rotation-invariant, so that the |||>
<||| same parameters can be reused across a complete |||>
<||| image series (enabling automated analysis). |||>
.
$y.
($red-red)
 color: rgb(30,35,30); font-size:10;font-weight:normal;
 background-color:200 105 137 250 ~> 182;
.
$p# 17 63
/!
<+>



!/ Pause_Annotation
$s: 785 
$i: +auto
$t: 40
/!
<+>



!/ Pause_Annotation
$s: 787 
$i: +auto
$t: 120
/!
<+>


!/ Text_Annotation
$s# 786  788  
$e: div @7
$t. 
||>
<||| Here we compare the accuracy of keypoints identified via grayscale |||>
<||| channel reductions to those based on XCSD formulas for ranking |||> 
<||| pixels in terms of background versus foreground probabilities. |||>
<br> 
<||| The demo application can run such a comparison against many |||>
<||| feature-detection methods, e.g., SIFT, SURF, USURF, AKAZE, |||>
<||| ORB, BRISK, or Sobel/Prewitt and related edge-detection kernels. |||>
<br> 
<||| For this example, BRISK (Binary Robust Invariant Scale Keypoints) |||>

<||| yields the best results, alongside the XCSD channel-reduction. |||>
.
$y.
[$red-red]
.
$p# 7 67
/!
<+>



!/ Pause_Annotation
$s: 789 
$i: +auto
$t: 40
/!
<+>



!/ Pause_Annotation
$s: 791 
$i: +auto
$t: 130
/!
<+>


!/ Text_Annotation
$s#  790   792 
$e: div @7
$t. 
||>
<||| We demonstrate the comparison by marking pixels at BRISK |||>
<||| keypoint-locations via a color-scheme that separates XCSD |||>
<||| from grayscale matches. |||>
<br>
<||| Specifically, cyan shows XCSD matches; red covers XCSD |||>
<||| matches that are filtered out because they are judged to lie |||>
<||| outside the foreground focus area (due to high background/ |||>
<||| low foreground probability); yellow depicts grayscale matches; |||>
<||| and green represents keypoints common to both result-sets. |||>
.
$y.
[$red-red]
.
$p# 7 77
/!
<+>



!/ Pause_Annotation
$s: 1261 
$i: +auto
$t: 100
/!
<+>


!/ Text_Annotation
$s# 1260  1262  
$e: div @7
$t. 
||>
<||| To mathematically test the XCSD/BRISK keypoints, |||>
<||| we load an image-transform series defined by an |||>
<||| NTXH data file &mdash; NTXH being the same custom |||> 
<||| format described in our prior video (re: |||>
<||| Virtual Reality and 3D/360&deg;-photography tours) |||>
<||| in the context of video annotations. |||>
<br> 
<||| This NTXH data encodes a workflow similar to our |||>
<||| image-analysis demonstration from earlier in <i>this</i> |||> 
<||| video (via rotations and color-masks), except that |||>
<||| now we apply the transforms to test an automated |||>
<||| analysis rather than to run a new analysis. |||>
.
$y.
[$red-red]
.
$p# 15 50
/!
<+>




!/ Pause_Annotation
$s: 2215 
$i: +auto
$t: 145
/!
<+>

!/ Text_Annotation
$s#  2214   2216 
$e: div @7
$t. 
||>
<||| Informally, we can visually confirm that the XCSD matches |||>
<||| are spread throughout the foreground and outside the |||> 
<||| background, serving to demarcate the foreground. |||>
<br>
<||| By contrast, traditional grayscale matches are distributed almost |||> 
<||| randomly across the foreground/background division. |||>
<br>
<||| These results suggest that XCSD keypoints can act as textural |||>
<||| feature-markers which correctly isolate the foreground, allowing |||>
<||| its size to be calculated as a percentage of the total image. |||>
<||| The next step is to assess keypoint-accuracy more rigorously, |||>
<||| by comparing statistical evaluations of both result-sets. |||>
.
$y.
[$red-red]
.
$p# 9  51 
/!
<+>




!/ Pause_Annotation
$s: 2588 
$i: +auto
$t: 170
/!
<+>



!/ Text_Annotation
$s# 2587  2589  
$e: div @7
$t. 
||>
<|| We map all keypoints (XCSD and grayscale) alongside the image ||>
<|| transform, working within the XCSD demo-application ||> 
<|| in order to pause and watch each step. ||>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;
<br>
<|| As can be seen, these transforms map the image into 27&times;27 ||>
<|| boxes, which serve to bin and classify all keypoints into||>
<|| foreground and background cells. <| From this mapping we can ||>
<|| calculate the accuracy of the XCSD keypoint algorithm, showing ||>
<|| in particular that 93% of the XCSD keypoints are correctly ||>
<|| binned as foreground, and 88% of foreground bins cover ||>
<|| keypoints. <| In comparison, only 39% of foreground bins have ||>
<|| grayscale keypoints (providing an accuracy less than half of XCSD); ||> 
<|| and moreover, the grayscale metric found only 15% of the ||>
<|| keypoints identified via XCSD (a ratio of more than 6-to-1). ||>
.
$y.
[$white-purple]
.
$p# 4 39
/!
<+>




!/ Pause_Annotation
$s: 2591
$i: +auto
$t: 40
/!
<+>


!/ Pause_Annotation
$s: 2599 
$i: +auto
$t: 180
/!
<+>


!/ Text_Annotation
$s# 2592  2601 
$e: div @7
$t. 
||>
<|| So as to compensate for inaccurate results using grayscale, ||>
<|| a common practice in Computer Vision would be to pre- ||>
<|| transform the target image with a morphological operator, ||>
<|| such as a dilation kernel, or to run a &ldquo;blurring&rdquo; algorithm, ||>
<|| both of which could reduce statistical noise. <| For that kind ||>
<|| of pipeline, the goal would be to push keypoints out ||>
<|| toward the perimeter of foreground segments and then ||> 
<|| consult the keypoints as a <i>de facto</i> contour sampling (e.g., ||>
<|| via a polygon hull) to demarcate the segments&rsquo; boundaries. ||>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;
<br>
<|| The problem with this approach is that morphological ||>
<|| simplification may still yield distorted results for images that ||>
<|| do not have a clearly separated foreground and background, ||>
<|| which is true for most real-world images where glare/ ||>
<|| shadow, textures, occlusions, and other optical and/or ||>
<|| geometric anomalies complicate the segmentation process. ||>
.
$y.
[$white-purple]
.
$p# 7 11
/!
<+>





!/ Pause_Annotation
$s: 2932
$i: +auto
$t: 240
/!
<+>


!/ Text_Annotation
$s# 2931  2953  
$e: div @7
$t. 
||>
<|| For complex images, a reasonable strategy, instead, is to aim ||>
<|| for segment-interior keypoints rather than segment-boundaries. ||> 
<|| If keypoints are mostly localized to foreground interiors and ||>
<|| spread out through the foreground, then the area spanned by ||>
<|| keypoints usefully approximates the foreground&rsquo;s size and shape. ||>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;
<br>
<|| As seen here, the XCSD algorithm is 93% accurate with respect ||>
<|| to foreground true-positives and 88% accurate with respect to ||> 
<|| foreground false-negatives. <| Also, all false-positive keypoints ||>
<|| are adjacent to at least one (usually 3 or more) foreground bins, ||>
<|| so protruding the foreground by one step to these locations ||>
<|| would barely distort the foreground size and shape. <| In this ||>   
<|| sense the entire keypoint set serves as a good approximation ||>
<|| for the foreground. <| Collectively, these numbers suggest that ||>
<|| segment-interior feature detection can work well as an ||>
<|| alternative to segment-boundary keypoints for images where, ||>
<|| due to ground-truth and/or optical complications, ||>
<|| boundary-segmentation yields imprecise results. ||> 
.
$y.
 color: 60 90 0 => 144;;font-weight:normal;
 background-color: 100 240 207 249 ~> 165;
.
$p# 3 -1
/!
<+>






!/ Pause_Annotation
$s: 3052 
$i: +auto
$t: 30
/!
<+>



!/ Text_Annotation
$s# 3050 3154
$e: div +span |> [$over-yellow]
$t. 
<| One Dimensional Features <|
.
$y.
($back2-blue)
 color:rgba(0,10,37);;font-weight:bold;
 background-color:rgba(7,190,200,50);
.
$p# 19 170
/!
<+>






!/ Pause_Annotation
$s: 3584 
$i: +auto
$t: 120
/!
<+>



!/ Text_Annotation
$s# 3581  3588  
$e: div @7
$t. 
||>
<|| In order to demonstrate one-dimensional feature detection, ||>
<|| we next compare a line-detection (Hough) algorithm ||>
<|| utilizing grayscale reductions against a different XCSD ||>
<|| channel-reduction scheme, based on the XCSD toroidal ||>
<|| color model. <| This color model is designed to minimize ||>
<|| the error factor in color-distance comparisons which ||> 
<|| might be caused by optical artifacts (such as glare/shadow ||>
<|| effects or textural variation). <| The toroidal metric generates ||>
<|| a localized channel-reduction which estimates the degree ||>
<|| of ground-truth color fluctuations around each point. ||>
.
$y.
[$white-purple]
.
$p# 3 43
/!
<+>



!/ Pause_Annotation
$s: 3682 
$i: +auto
$t: 160
/!
<+>



!/ Text_Annotation
$s# 3680  3683  
$e: div @7
$t. 
||>
<|| The statistical comparison reveals that XCSD&rsquo;s toroidal ||>
<|| metric generates a Hough spectrum which almost perfectly ||> 
<|| aligns with the predominant angular orientation of our ||>
<|| foreground Region of Interest (this graphic highlights the ||>
<|| median Hough line in purple, and the desired angle that ||>
<|| we previously marked via a rhombus annotation in orange). ||>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;
<br>
<|| Conversely, the generic grayscale spectrum is randomly ||>
<|| distributed among theta-angles. <| Specifically, the toroidal ||>
<|| angle matches the predefined target by 98% (more than ||>
<|| double the grayscale, at just 48%). <| In the prior image, the ||> 
<|| purple and orange lines (representing target and average ||>
<|| angles, respectively) are almost exactly parallel; in the ||>
<|| latter image, they are at unrelated angles to one another. ||>
.
$y.
[$white-purple]
.
$p# 6 36
/!
<+>




!/ Pause_Annotation
$s: 4026 
$i: +auto
$t: 35
/!
<+>



!/ Pause_Annotation
$s: 4028 
$i: +auto
$t: 110
/!
<+>



!/ Text_Annotation
$s# 4027  4029  
$e: div @7
$t. 
||>
<|| The precise fit obtained via the toroidal calculation ||>
<|| confirms that we can use this automated line-detector ||>
<|| to construct a rotation angle for the workflows or ||>
<|| feature-evaluations wherein a series-image is ||>
<|| rotated to yield orthogonal bins aligned with the ||>
<|| foreground's angular orientation ||>

.
$y.
($back-gold)
 color:rgba(0,10,37);
 background-color:rgba(200,190,107,250);
.
$p# 20 92
/!
<+>


/&










- s=start frame  e=end frame  t=text  y=style 
  p=position 
.



&type Text_Annotation {7}
  :s:1  :e:3  :t:4  :y:5  :p:6 ;


&type Shape_Annotation {5}
  :k:1  :s:2  :t:4  :d:5 ;
 
&type Circled_Text_Default {15}
  :w:1
  :background-color:2  :foreground-color:6
  :outline-color:10  :font-size:14  :border:15 ;

&type Circled_Text_Annotation {5}
  :s:1  :t:3  :p:4 ;

- s=start frame  i=id



&type Pause_Annotation {3}
  :s:1  :i:2  :t:3 ;



&type Annotation_Settings {6}
  :sa:1  :tr-smaller:3 :tr-larger:5  ;


&/


!/ Annotation_Settings
$sa#  1  1
$tr-smaller#  0  0
$tr-larger#  0  0  
/!
<+>


!/ Circled_Text_Default
$w: 12
$background-color# 50 50 210 255
$foreground-color# 150 50 10 255
$outline-color# 150 50 10 255
$font-size: 14
$border: 2
/!
<+>



!/ Pause_Annotation
$s: 2 
$i: +auto
$t: 40
/!
<+>




!/ Pause_Annotation
$s: 22 
$i: +auto
$t: 50
/!
<+>



!/ Text_Annotation
$s# 4 47
$e: div +span |> ($over-yellow) rgba(250,250,207,250)
$t. 
<| Two-Dimensional Features <|
.
$y.
($back2-yellow)
 color:rgba(0,10,37);;font-weight:bold;
 background-color:rgba(200,190,7,50);
.
$p# 22 132
/!
<+>




!/ Pause_Annotation
$s: 49 
$i: +auto
$t: 40
/!
<+>




!/ Pause_Annotation
$s: 52 
$i: +auto
$t: 180
/!
<+>

!/ Text_Annotation
$s# 51  90  
$e: div @7
$t. 
||>
<|| Next, we examine superpixel segmentation as an illustration ||>
<|| of two-dimensional feature analysis. <| In particular, these ||>
<|| visuals will show a superpixel subdivision of our original ||>
<|| image superimposed on the map of BRISK keypoints ||>
<|| obtained via the pipeline shown earlier. ||>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;&#9135;
<br>
<|| Superpixels represent one tactic for extrapolating interior- ||>
<|| keypoint features to foreground object-proposals. <| Specifically, ||> 
<|| we can estimate the foreground to be the sum of superpixels ||>
<|| containing keypoints, thereby converting zero-dimensional ||>
<|| point clouds to a two-dimensional area. <| The shape and/or size ||>
<|| of this approximate foreground may then be utilized to ||>
<|| compute the extent of the foreground relative to the whole ||> 
<|| image, and/or to compare the foreground's mereogeometric ||>
<|| profile against predefined keys for object-tracking, ||>
<|| object-recognition, and related &ldquo;semantic&rdquo; analyses.||>
.
$y.
($white-purple)
 color:rgba(40,10,137);font-size:10;font-weight:normal;
 background-color:rgba(250,250,250,243);
.
$p# 2 13
/!
<+>


!/ Pause_Annotation
$s: 98 
$i: +auto
$t: 20
/!
<+>


!/ Pause_Annotation
$s: 102 
$i: +auto
$t: 110
/!
<+>


!/ Text_Annotation
$s# 101  103  
$e: div @7
$t. 
||>
<|| This graphic shows the segmentation and BRISK keypoints ||>
<|| together. <| For purposes of demonstration, superpixels ||>
<|| intersecting the keypoint result-set are highlighted with ||> 
<|| yellow or red outlines, while others (those outlined in light ||> 
<|| blue/pink, which approximate the background) are shaded in red. ||>
.
$y.
 color:rgba(0,10,37);
 background-color:rgba(200,190,107,250);
.
$p# 20 52
/!
<+>




!/ Pause_Annotation
$s: 180 
$i: +auto
$t: 110
/!
<+>



!/ Text_Annotation
$s# 158  182  
$e: div @7
$t. 
||>
<|| We&rsquo;ll then show the same analysis run on a variation ||>
<|| of the image which was more aggressively pre-processed. ||>
<|| Note that the superpixel segmentation is almost identical ||>
<|| when computed against the full-color image and via an ||>
<|| XCSD channel-reduction with toroidal color bins. ||>
<br>
<|| In this case a coarse filter collapses the image&rsquo;s color ||>
<|| space to a small group of predominant colors (fewer than ||>
<|| eight) without affecting the quality of the segmentation. ||>

.
$y.
($back-plus-red)
 color:rgb(90,10,37);font-size:10;font-weight:bold;
 background-color:rgba(250,255,250,240);
.
$p# 7 52
/!
<+>



!/ Pause_Annotation
$s: 465 
$i: +auto
$t: 140
/!
<+>


!/ Text_Annotation
$s# 464  467  
$e: div @7
$t. 
||>
<|| All in all, XCSD can employ a variety of channel-reduction ||>
<|| strategies, each of which depend on novel algorithms. ||>
<|| These strategies, and their underlying color-models, ||>
<|| can be merged in different configurations to improve ||>
<|| the accuracy of numerous feature-detection pipelines, ||>
<|| spanning zero-dimensional, one-dimensional, and ||>
<|| two-dimensional feature profiles. ||>
<br>
<|| These capabilities augment the features provided by the ||>
<|| XCSD framework for manipulating image-series, ||>
<|| multi-media database systems, video/PDF features, ||> 
<|| and desktop/native application-development requirements. ||>
.
$y.
($back-blue)
 color: 0 10 37;
 background-color: 107 190 200 250 ~> 180;
.
$p# 16 53
/!
<+>





!/ Pause_Annotation
$s: 512 
$i: +auto
$t: 60
/!
<+>


!/ Text_Annotation
$s# 511  514
$e: div +i
$t. 
<| Thanks For Watching! <|
.
$y.
 color:rgba(0,26,17);;font-weight:bold;
 background-color:rgba(240,40,187,180);
.
$p# 90 77
/!
<+>





/&








