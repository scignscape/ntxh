
`section.Conclusion`



`p.
Interactive workflows are a prime example of 
how image-processing applications rely on 
`GUI;-level programming, but there are 
numerous other use-cases for which 
similar comments apply.  For example, 
users might want to visually compare 
the results (or intermediate stages) 
of diverse workflows, spanning multiple 
techniques, to determine which approaches 
work best for a particular image-series.  
We can assume that in many cases parameters 
and algorithms which yield promising results 
on sample images within a series may be 
automatically applied to the image series, 
particularly if such images are thematically 
related (such that the series-elements 
have similar color patterns, textural complications, 
perspectival orientation %-- e.g. whether canonical 
background colors tend to arise from the top-center, 
as in outdoor/landscape pictures, or the left/right sides 
%-- etc.).  Figure~`ref<fig:tools-all>; shows a 
variety of `GUI; components associated 
with `XCSD; that demonstrate how 
applications can support users' experimenting 
with different algorithms (e.g., edge-detecting 
methods), visualizing color-schema, examining 
interactive color-histograms, and otherwise 
reviewing and fine-tuning data that will 
ultimately be incorporated into engineered workflows. 
`p`


`p.
The more that applications seek 
to provide `GUI; support for image-processing operations, 
the more complex and expansive becomes the integration 
between Computer Vision libraries themselves 
and the `GUI; components which provide data and 
parameters to Computer Vision workflows.  In this 
scenario one approach to engineering and maintaining 
the proper cross-component interoperability 
would be to support `GUI; controls, event-handlers, 
and data-exchange amongst the relevant software 
libraries via a Virtual Machine.  This could 
entail `VM; code for designing `GUI; classes, during 
testing and development; `VM; intermediaries 
for handling events/signals generated by user 
actions through these `GUI; elements; 
`VM;-based protocols for connecting the `GUI; 
data to image-processing workflows implemented 
via isolated Computer Vision modules; or 
any combination of these.   
`p`

`p.
Section 2 outlined specific image-processing 
workflows, enacted through the 
`XCSD; image format.  That outline 
points to several details within an 
`XCSD; pipeline (arguably indicative 
of common concerns within many 
different Computer Vision workflows) 
which could involve cross-component 
interop, insofar as image-analysis 
is provided via dedicated plugins, 
extensions, or third-party libraries 
adopted by a host application.  As 
mentioned above, a pipeline would 
often defer to the host at least 
for graphics-displays and initial 
image acquisition, but the 
`XCSD; workflow points to 
other moments at which interop 
may be necessary. 
`p`


`p.
First, `IauNC; mentioned the idea of consulting 
local histograms interactively 
so that human users might define 
foreground and background poles 
for sample/reference images in a series.  
In this case the host application would 
need to take responsibility for loading 
histogram displays and processing 
user actions.  For `q.local` histograms 
the color counts are drawn from a small 
area %-- via `XCSD; the image is predivided 
into tierboxes anyhow, but in an interactive 
case users need to select one tierbox 
for which to view histogram data, which 
would be an action handled by a front-end 
component.  Assuming `XCSD; code calculates 
the actual histogram and then sends this 
data back to the front-end, which in turn 
presents it visually, we see a multi-step 
exchange of data between the two components.  
Likewise, histogram displays may themselves 
be interactive %-- given that these 
visuals typically rank colors by showing 
bars filled with a particular color with a 
height documenting its occurrence in the 
histogram-area, the bars themselves 
can serve as color-selectors, so for 
example users could use histograms to select 
colors assigned specific thematic 
roles (such as foreground/background).  Such 
actions would then generate further data 
routed back to the processing component 
(e.g., selected foreground/background 
poles applied to form a new one-channel 
reduction).  
`p`


`p.
In the exchange just described, we assume that a 
front-end exposes capabilities to 
display histograms when provided the requisite 
data, while image-analysis components 
leverage this functionalities by 
assembling histogram data.  Generalizing from this 
example, image-processing front-ends 
could support a variety of features 
relevant to initiating and examining 
Computer Vision pipelines, such as 
displaying images with annotations 
and overlays %-- this would include 
showing intermediate graphics wherein an 
image being analyzed is marked with 
icons, lines, or contours representing 
features extracted by detectors for Hough lines, 
scale/rotation invariant keypoints, boundary-contours, 
and similar algorithms.  Host applications would 
thereby anticipate the general kinds of 
interactive/presentational features which are 
important to provide for an image-processing 
context, but they would remain open-ended 
with respect to the specific analytic 
modules that may target their front-end 
capabilities.  In particular, host applications 
could then support a flexible spectrum of 
analytic methods, insofar as new sorts 
of algorithms could be introduced with their 
own mathematical constructions; each component 
can provide distinct analytic code so long as 
it accepts a common protocol for 
basic functionality involving acquiring, 
displaying, and invoking front-end 
features for analyzed images and image-series. 
`p`



`p.
In short, the interop between image-processing 
host applications and analytic modules  
are a good example of bi-directional 
data sharing between semi-autonomous components, 
and fall under the rubric of interop
situations where protocols may benefit 
from formalization or (at least partial) 
implementation via Virtual Machines.
`p`


`p.
As a concluding observation, readers may be interested 
in checking the chapter's demo code, which includes 
scripts (mostly build-tools) linked to over 100 
cross-platform image-analysis libraries, offering a 
useful overview of the common practices 
and design patterns currently favored by 
Computer Vision developers.  One noteworthy 
insight, reviewing the code for this 
collection of libraries, is that very few 
image-processing resources provide `GUI; 
tools or attempt to interoperate 
with `GUI; front-ends.  Most of these repositories 
are focused on supplying processing 
algorithms (for segmentation, feature detectors, 
image-tagging, and so forth) and implement 
workflows with little connections to outside 
components, after acquiring an initial image to 
work on.  Considering both the vast range of 
research that has been done on Computer Vision 
methods (evinced by the number of distinct 
open-source tools, many of which codify 
methods presented through published research), 
and (by contrast) the paucity of application-integration 
tools, we might conclude that there is room for 
common standards and shared technologies for interoperating 
`GUI;s with image-processing modules to fill 
in a noticeable gap in the current Computer Vision ecosystem. 
`p`




`p.

`p`



