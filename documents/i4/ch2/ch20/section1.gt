`section.Hypergraph Data Modeling`

`p.
I claimed in the introduction that a software 
application's primary role is to await 
user actions and then, in response, 
produce some visual change (in the on-screen display) 
which presents information to the user 
(presumably information relevant to their 
original action), along with possible 
side effects (like saving a file).  
On this account, studies of applications' 
behavior would reasonably focus on 
the starting and ending points of these 
action/reaction cylces: how do we articulate 
the full space of possibilities for users 
to iniatiate actions within the application?  
For mouse-and-keyboard desktop setups, for instance, 
an action like `q.left click` on the mouse 
can be performed at any point in an application's 
window (or windows), and mouse-events could 
click one of several buttons, or turn the 
scrool wheel, and they can be modified by 
pressing certain keys.  In some contexts, likewise, 
users enter data by typing on a keyboard.  
Applications need to systematically model 
all of these possibilities so that they 
can create a data structure which carries 
all relevant details user actions, which 
in turn is requisite for responding correctly 
(left-click and right-click usually have 
different `i.meanings`/, for example).  
At the other end, applications need to subdivide 
their display window into parcels of screen-space 
so that data updates are located in useful 
visual contexts (continuing the above 
example, the Montreal score should be placed 
near the Habs logo, and likewise for Toronto).  This, 
of course, means that the computer screen is 
not just a `q.picture`/; it is an organized system 
which can be analyzed through data models and 
types.  And such analyses can potentially be 
extended to robots and/or Virtual Reality, which 
are not just `TwoD; screens but possess 
`ThreeD; physical or visual-immersive 
(and maybe synaesthetic) configurations. 
`p`


`p.
Well-designed applictions have multiple features and 
are easy or intuitive to use: this means that 
users have a variety of options for 
leveraging applications' capabilities, and 
that it is not difficult for users to 
learn or infer the steps needed to prompt 
their application toward their desired course 
of action.  Applications can generally become 
`q.better` %-- more featureful and intuitive 
%-- by being flexible and subject to continuous 
improvement; that is, applications should be 
designed to acquire more functionality 
over time, and to update their interactive 
interface based on the concrete experience of 
users who may find different features easier 
or harder to access.  For example, specific 
operations might be exposed in different ways, 
in that the user has multiple options for 
initiating certain responses (for example, the 
effects of clicking on a certain button might 
be duplicated by pressing a specific key on 
the keyboard, or by activing the mouse's scroll wheel 
%-- e.g., scrolling down, hitting an on-screen `q.down` 
button, or pressing the down-arrow key).  Many 
applications also allow plugins or extensions to 
adjust the visual displays in ways not envisioned 
by the program's original designers.`footnote.
I adopt the convention that a `q.program` is a 
self-contained software component, something 
that can be executed, and an `q.application` 
is one kind of program: one with a visible 
user interface.  Most programs are applications, 
on these definitions (when discussing technical 
`VM; matters sometimes however we can use 
the word `q.program` in a different sense, as a 
self-contained sequence of `VM; operations).
`footnote`  
This flexibility helps ensure that applications 
can improve and be useful, but more specifically 
they are engineering goals: there are steps 
which developers can take to maximize 
applications' ability to adapt and evolve.     
`p`


`p.
Aside from a generic desire to build `q.quality` 
software, engineering applications for 
future adaptation also prompts develoeprs to 
design software in rigorous, well-documented 
ways.  Applications can be thought of, 
rather metaphorically, as virtual/digital `q.piping` 
linking a tableau of potential user actions (via the 
mouse, keyboard, and etc.) to a space of 
possible screen-configurations.  A software 
engineer's goal is to build up this intermediate 
`q.plumbing` in an orderly rather than haphazard 
manner, so that future programmers have a clear 
picture of how the application's functionality 
can be augmented (without affecting its 
current behavior, unless a conscious decision is 
made to alter the application's pragmatics 
based on user feedback).  Users initiate 
actions so as to invoke application features, 
for example: to organize responses systematically, 
it is important to have an efficient structural 
breakdown of all the functionality which 
the application makes available, by analogy 
to how books might be organized on the 
shelves of a library.  But this structuring 
principle also promotes extensibilty: 
once a system is in place to enumerate 
functionality, it is easier to add 
new features because there is greater 
transparency in how new features can 
`q.slot in` alongside their predecessors.  
Similar points apply to the visual 
display of information: the more 
systematically we model how data types 
recognized by an application are translated 
to visual form, the more readily we can build 
new display units %-- such as isolated 
windows or dialog boxes %-- to display 
`i.new` data types, formulated in the 
course of providing new functionality. 
`p`


`p.
Planning for continuous-adaptation therefore 
implies that application should 
deliberateively model the functionality 
they `i.expose` as features available 
to users: improvements can either 
provide alternative (perhaps more 
user-friendly) ways to invoke these 
same features, or to create 
new features that fit comfortably 
with the existing application 
by honoring its protocols and 
user-pragmatic conventions.  
An important dimension of software design, 
then, is formulating the protocols 
and concrete implementations 
through which applications 
`q.expose` functionality. 
`p`



`p.
Consider an example from the domain of 
image-processing (which will be the focus of 
Chapter 21): Computer Vision software 
will typically have many built-in 
functions that can be used to transform 
and/or extract data from graphics 
images (i.e., pictures, such as 
photographs or satellite images, or individual 
frames lifted from videos).  Exposing 
these capabilities means offering ways 
for users to initiate an image-processing 
workflow.  The result of the workflow 
might be a modified version of the original 
image, or some extracted data structure 
that can be outlined or visualized.  Because 
workflows are often chained together or, 
in general, aggregated to form more complex 
workflows, `q.exposing` functions also means 
allowing operations to be dynamically 
invoked by software, so that although a user 
will manually initiate an overarching 
functionality there may be many 
behind-the-scenes intermediay stages where the 
most users would not directly perceive.  
In this kind of environment applications 
will typically offer an `API; (Application 
Programmable Interface) and/or an 
`ABI; (Application Binary Interface, which 
is more low-level) such that important 
features can be accessed directly through 
user actions `i.and` indirectly 
as intermediate processes launched in response 
to some higher-level user action.`footnote.
I mention `ABI;s here in the sense that 
application-procedures might be exposed 
to be called directly with raw data values, 
in contrast to what I will later call 
`q.meta-procedures` whose inputs and outputs 
are padded with extra layers of indirection.
`footnote`
Moreover, the results of Computer Vision 
workflows will typically be represented 
to users in the same application as 
where they initiate workflows, so 
applications need to expose functionality 
for altering their visual display in 
accord with the details of specific 
pipelines (e.g., presenting a new image 
in a new window).  In short, applications
need to expose both analytic/processing 
functionality and display/visualization 
functionality.   
`p`



`p.
To `q.expose` functionality is to 
offer multiple ways that functionality 
may be accessed: by users directly; by 
engines which step through workflows; 
by application `q.macros`/, which 
are (for some programs) programmable 
sequences of user-actions that typically 
are performed together (the macro 
can applow multiple actions to be 
initiated with one single actio); 
by `q.updates` which can add new 
features without software needing 
to be re-installed; by `q.personalization` 
features which allow programs to enter 
different states depending on the 
identity of their current user; by 
configuration files; and 
by `q.scripting` environments 
where code written in a programming 
langauge (typically one with 
an interpreter that can be embedded 
in standalone software, such as Lisp or 
Python) can modify or fine-tune application state 
and performance.  Supporting such 
personalization and fine-tuning is itself a 
feature that makes software more user-friendly, 
but (for reasons I mentioned `visavis; 
rigorous design) also prompts developers 
to architect software in well-organized ways, 
with a logical model of user actions, visual 
displays, and all the coding that connects 
the one to the other. 
`p`


`p.
An important dimension of application development, 
accordingly, is that of modeling and formalizing 
how applications expose functionality and 
User Interface details.  Virtual Machines, 
in turn, are a useful tool for 
analyzing the features exposed by applications 
(and how they are implementationally tied to 
the application as a whole).  This is the 
primary scenario where I will consider 
`VM; designs as theoretical artifacts in their own right.
`p`


`subsection.Hypergraphs as General-Purpose Data Models`
`p.
Ultimately, all of a program's functionality 
is achieved via procedures, which are provided 
by the software code base (perhaps along 
with third-party libraries that get re-used, 
sometimes as high-level source code and sometimes 
as compiled resources).  As such, one way to  
`q.expose` functionality is simply to allow 
external code (that is, code which is not 
explicitly developed as part of an 
application's core code base) to call 
procedures which `i.are` in the code base.  
The vast majority of such procedures, however, 
are `q.internal,` intermediate computations 
that would not be meaninful for appropriate for 
external access.  Accordingly, applications 
need a more over-arching model of exposed-features 
to ensure that external code utilizes 
internal capabilities in an orderly fashion.  
`p`


`p.
In general, functionality is exposed to 
external components by constructing a specific 
procedure whose role is to be an `q.entry point` 
for externally-invoked features.  That 
is, we assume that any exposed `q.functionality` 
requires multiple procedures to be realized, 
and one entry-point is necessary to 
invoke a larger package of procedures which 
collectively implement an operation that 
we can `i.conceptually` regard as `q.one` 
function.  For example, if an exposed 
capability (in a Computer Vision program) 
is running a superpixel segmentation on a 
`TwoD; image via color-watershed, there will 
be many intermediate procedured needed to 
complete that computation, but we can reason 
about the segmentation as one identifiable 
step in an image-processing pipeline.  
It is a `i.conceptual` function unit even if 
it is not `q.one` function, in the sense of 
one single source-code procedure.  I propose 
to use the term `q.meta-procedure` to 
describe functions that are conceptually 
singular but implementationally multiple, in 
this sense.   
`p`


`p.
Application-level capabilities often require 
certain details to be specified %-- continuing 
the superpixel example, such an operation 
would need to know which image to target, and 
potentially would need certain threshold 
parameters to be specified (superpixels 
are relatively small image-regions of 
similar color, but `q.how` small and similar 
depends on input values that might vary 
from one run to another).  The `q.output` 
of such a segmentation would be a 
data structure (typically a `q.labeling` 
image, which adds an extra number to each 
pixel %-- alongside its existing 
color channels, such as red, green, and blue %-- 
naming the superpixel to which it belongs); 
for visualization, sometimes superpixel 
segmentations will also be displayed by outlining 
the superpixels with a colored boundary 
(visually distinct from the underlying image).  
Thus a superpixel algorithm has inputs and 
outputs analogous to a single procedure.  
However, insofar as such an algorithm is not 
one procedure but rather (in my terminology) 
a `q.meta` procedure, these inputs and outputs 
are not delivered simply as binary 
data values (memory addresses or `CPU; registers) 
but rather need to be marshaled and 
encoded between the software component 
which invokes the metaprocedure and 
the application which exposes it.  
Unlike the execution-sequence `i.within` 
one component, where one procedure 
can call other procedures directly, 
for such `q.meta` procedures there 
needs to be a series of steps 
wherein input parameters are 
built up using a common protocol
which both components can understand, 
and output results likewise 
encoded in reverse.  The procedure/metaprocedure 
contrast is analogous to the difference 
between a face-to-face conversation between 
two parties and a long-distance negotiation 
where diplomats (or lawyers, etc.) exchange 
offers and proposals and counter-offers 
according to a fixed set of rules.  Unlike 
in-person dialog, such indirect 
communication is less open-ended, and 
relies on trustworthy intermediaries 
to convey messages and information without 
distorting their meaning. 
`p`


`p.
What diplomats, lawyers, and mediators 
may be to human communication, their 
analogues in Information Technology 
would be data-sharing protocols 
and `API;s.  Usually, software components 
which interact via these indirect, 
carefully mediated pathways can potentially 
have divergent implementations %-- they may 
be written in different languages, adhere 
to different coding paradigms, and so 
forth.  Therefore, data has to be transferred 
from one component to another via neutral 
formats which are amenable to both 
sides: data in one context should be 
encapsulated in a neutral package and 
decoded (without distortion) on the 
other environment, and vice-versa.  
External-programming interfaces therefore 
depend on data representation systems 
which alow for information to be restructed 
according to the needs of different 
computing environments, while maintaining 
structural integrity (i.e., decoding the 
data back to its original form should 
produce an exact replica of the data prior 
to its originally being encoded). 
`p`


`p.
Ensuring data integrity across divergent 
programming environments is a complex 
task: when being passed between 
components data is necessarily `i.serialized`/, 
or convert from its innate binary/in-memory 
form to a textual or numeric encoding, and 
then reconstituted into a new binary 
package which should be `q.equivalent to` 
the original (we can define `q.equivalence` here 
in terms of bi-directionality: re-encoding the data 
and sending back from target to source, then 
re-decoding, should yield a copy of the original; or, 
more rigorously, modifying a smaller part 
of the received data and then back-sending 
should yield a duplicate of the original 
`i.except for` the specific change).  Data-serialization 
formats need to be designed to ensure that 
information is not lost in the encoding/decoding 
process: for example, a quantity which 
originally has floating-point type (so it `i.could` 
have non-integer values) might get encoded as an integer 
if, in fact, on a specific occasion it has no 
fractional part; then, on decoding, the 
value might be interpreted `i.as` an integer 
(rather than a `b.float` which happens to 
have an integer value), which in turn could 
corrupt future calculations (in some contexts 
arithmetic operations performed on an integer 
paired with a `b.float` will cause the 
floating-point value to be truncated to an 
integer, yielding incorrect results in 
an algorithm which expects both 
values to be `b.float`/s) and/or 
corrupt data sent back to its source.  
Similar incompatibilities may exist 
between expected units of measurement 
(metric versus Imperial, for instance) 
or value-ranges (it is not obvious from a
single number what are the sensible range 
of values which the number could take on, if 
modified: magnitudes for inividual pixel-colors, 
for instance, in most image-formats are 
restricted to the range 0-255; percentages 
are often limited to 0-100; angles 
in degree to 0-359, and so forth).  
Failure to anticipate the full set 
of metadata conventions and standards 
which are prerequiste for multiple 
software components to act on shared 
data is a common source of data-corruption.  
`p`


`p.
For these reasons, data-sharing protocols 
need to be designed around detailed and 
`q.expressive` representations, meaning 
that it is possible to systematically 
describe all facets of data profiles 
(types, ranges, units, scales, metadata) 
that could potentially be sources of 
ambiguity and encoding/decoding errors.  
To be sure, a lot of data-sharing happens 
through relatively simple formats 
(such as `JSON; %-- JavaScript Object Notation 
%-- or `CSV;, comma-separated values) 
which lack these higher-level guidelines, 
but such formats typically work in 
contexts where networking conventions 
are clearly defined %-- effectively 
relying on programmers' discipline and 
informal documentation to take the place 
of stipulations formally encoded in data 
protocols.  In more `q.critical` contexts 
which should be less susceptible to programming errors 
%-- or for more open-ended protocols 
where networking between disparate end-points 
should not depend on programmers diligently 
honoring informal specifications %-- developers 
would tend to prefer more rigorous 
representations, such as `XML; (with 
validators and predefined tag and attribute sets) 
or `RDF; (Resource Description Framework), 
associated with the Semantic Web (in conjunction 
with explicit Ontologies).    
`p`


`p.
In this chapter I will discuss options for `i.hypergraph` 
representations (which in some sense generalize 
`RDF;, considered to be `q.graph-oriented`/, but, 
unlike hypergraphs, not internally multi-scale).  
I claim that hypergraphs are more effective 
at permitting rigorous data profiles to 
be described and confirmed (i.e., we can 
formulate hypergraph data paradigms that are 
more expressive still than, for instance, 
`XML; and `RDF;) while retaining the necessary 
attributes of formal verifiability and 
transparency.  Indeed, hypegraph models 
in various forms have been proposed as 
extensions to both `RDF; (for example, in 
the transition from graph database engines 
to Hypergraph engines such as HyperGraphDB, 
Grakn, or AtomSpace) and `XML; 
(in the context of `q.concurrent` markup 
and related supersets of `XML; trees, 
which tend to focus on allowing tags 
to overlap one another instead of 
being strictly nested, as they are 
in `XML; and its variants, notably `HTML;).   
`p`

`p.
Although data (meta) models are an important 
theoretical topic (particularly when 
the discussion turns to optimization, so that 
we are considering not only `i.whether` 
queries or validations can be completed, but 
how to do so efficiently), here I am 
equally concerned with practical software concerns: 
in particular, the coupling between `i.representing` 
information and `i.exposing` application 
functionality.  The most common reason we seek 
to (digitally) encode data is to send it between 
separate components (including ones designed 
with little or no explicit inter-connections, 
except for joint participation in data-sharing 
capabilities which have to be implemented 
`i.ex post facto`/).  Metamodels are most 
valuable when they permit inter-operative 
capabilities in an additive manner: applications 
should be able to expand the scope of 
other applications with which they might network.  
Representational systems which engender 
computational artifacts (parsers, for syntax, and 
validators, for semantics, let's say) that can be 
implemented, embedded, and leveraged by applications 
as their capabilities are refined to support new 
protocols are most effective when the amount of 
effort consumed by the requisite programming 
is minimized.  Data-sharing protocols should be 
engineered to pass through application-integration 
phases as quickly as possible, but likewise 
applications should be architected to accommodate 
new data-sharing initiatives without 
substantial re-coding.  
`p`


`p.
Generically, we can describe a metamodel as 
relatively `q.expressive` to the degree that 
data structures and their concomitant semantic 
paradigms can be transparently encoded 
according to modeling system's rules.  
Expressivity might imply a level of 
redundancy, or at least superficial 
redundancy when viewed from the 
sole perspective of data encoding.  
For example, so-called `q.Industry 
Foundation Classes` %-- widely used 
in `AEC; (Architecture, Engineering, 
and Construction) technology and 
`BIM; (Building Information 
Management) %-- employ two different 
sorts of data annotations (called 
`q.attributes` and `q.properties) which 
both are roughly analogous to `XML; 
`q.attibutes`/.  The `IFC; attribute/property 
distinction might seem locally superfluous 
in that asserting a given data-point via a 
property rather than an attribute 
(or vice-versa) does not appear to 
convey greater information %-- the 
information is borne by the 
field's value, not by its property-or-attribute 
classification.  However, this distinction  
is not semantically vacuous; 
its significance emerges in the larger 
scale of schema-standardization and validation.  
Data fields asserting properties 
of objects (in the sense of real-world 
physical materials incorporated into building designs) 
are classified as either `i.attributes` or `i.properties`/, 
with the distinction being that attributes are fixed within 
schemata for objects of any given kind, whereas property-sets 
can be introduced in objects' context more flexibly.  
In type-theoretic terms, attributes are immutable parameters 
in types' schema, such that objects of the same type have 
the same attributes, whereas properties are not bound to 
types with equal force (usage patterns might dictate 
that, for example, common type-instances share property-sets 
`i.in some context`/, but these are not essential maxims 
of the type itself).
`p`

`p.
In the realm of bioinformatics, 
A similar distinction is made in the 
context of `DICOM; (Digital Imaging and Commmunications 
in Medicine) wherein `q.tags` (which have descriptive labels 
but also two-part numeric codes) are encoded using a system 
that distinguishes `q.Standard Data Elements` from 
`q.Private Data Elements`/: 
tags encoded with a numeric pair whose `q.Group` 
(first) Number is odd.  `lPACS; (Picture Archiving System) viewers 
(software that recognizes the `DICOM; format) will ignore 
Private Data Elements by default, so the Standad/Private 
distinction is intrinsic to protocols through which 
`DICOM; data is processed.  This distinction is not 
functionally identical to `IFC: attributes/properties, 
but reveals similar motivations insofar as data specifications 
are also guidelines for implementing software which 
manages data structures conformant to a given standard.  
Standardization projects' tasks include definine requirements 
on software as well as data representation, and it is 
logistically significant to distinguish standardized 
parameters that software `i.should` recognize as a 
compliance-criterion from non-standard kinds of values 
that particular users or groups of users working 
within a given protocol may want to introduce internally.   
`p`


`p.
The `BIM; attribute/property and `DICOM; Private/Standard 
distinctions are suggestive illustrations of challenges 
encountered when applying generic data-modeling principles 
to specific domains.  Most general-purpose representation 
frameworks (consider `XML; and `RDF;, for instance) lack a 
mechanism to directly express disjunction in parameters' 
level of standardization, as concretely found in these 
examples (not to imply that such details could 
not be represented indirectly, e.g. via meta-attributes 
or `DTD; stipulations, but the point is that 
one is thereby leveraging the affordances of a 
given representation scheme to accommodate semantic 
distinctions not specifically anticipated by that 
scheme, rather than organically encoding the 
semantics to begin with).  Also, note that for 
fields indexed by character-strings descriptive labels 
are designed to be meaningful for human users/readers, but 
in most modeling approaches labels do not have an 
`q.internal structure` recognized by the framework 
(at least if consider, say, `XML; namespaces as separate 
labels from element names).  The `DICOM; pattern wherein 
two-part numeric codes are employed for something 
akin to namespace/element separation, and then the 
use of an odd/even to signal Private/Standard tag rules, 
is also an idiosyncratic formulation which does 
not have a natural correlate in multi-domain modeling protocols.   
`p`


`p.
Data-representation theories which are grounded 
solely in `q.logical` reasoning, or mathematical 
representation, can miss such real-world 
complications: if we start from symbolic 
logic (or from a mathematical picture of 
graphs or trees as formal systems) we might 
be inclined to recognize `i.properties` 
(essentially metadata on graph sites, which 
is how properties work in conventional 
Property Graph database engines), or `i.attributes` 
in the `XML; sense (metadata on tree-nodes), 
but our theoretical framework could neglect to 
consider the possibility that a data-sharing 
protocol might need two `i.different` 
property/attribute mechanisms.  The semantics 
of a property/attribute distinction (in contexts 
such as `IFC;, or `DICOM; public/private) derives 
not from logical models but from 
real-world implementational concerns.    
A metamodel which supports this larger semantic 
context is therefore sufficiently expressive 
to properly encode `IFC; or `DICOM; data; a less expressive model 
(one which collapses attributes and properties 
into a generic notion of `q.fields`/, say), would 
fall short, at least without compensating 
by leveraging its own formal resources 
(e.g., classifying fields as attributes or 
properties via `q.meta-data` fields).  
Here we can appeal again to application-level 
concerns: the paucity of less-expressive 
systems would become evident insofar 
as reifications, indirections, and other ad-hoc 
solutions to representational blind-spots 
can render application-integration more complex 
and time-consuming.      
`p`


`p.
Metamodels are more expressive to the degree that 
they offer a greater range of representational parameters 
with which structural and semantic conventions 
might be communicated.  For example, `JSON; 
can be deemed more expressive than primitive `CSV;-style records because 
`JSON; distinguishes arrays (which are structurally akin 
lists) from `q.objects` (i.e., associative arrays, 
lists indexed by field-names rather than numbers).  
Likewise, `XML; is more expressive than 
`JSON; insofar as elements' data can be asserted 
via attributes or via nested 
elements (for sake of argument, treating `XML; 
as a de-facto superset of `JSON; wherein arrays 
correspond to sequences of similarly-tagged child 
nodes).  Associative arrays in `XML; might 
be coded `i.either` as attribute key-value 
pairs on `i.one` node `i.or` as sibling nodes 
with unique tag-names.  This `q.redundancy` 
allows for conventions to cohere 
(in a given data-sharing protocol) stipulating 
when either of these alternatives should be 
used, thereby supplying an extra layer of 
semantic detail which is not present in `JSON;.  
`p`


`p.
In the case of property graphs and/or hypergraphs, 
data fields can be associated with an `q.object` 
(in the sense of an integral data structure) 
via properties (attributes on a node) or via 
node-to-hypernode relations (sometimes called 
`q.projections`/), a duality reminiscent 
of property/attribute in `IFC;.  Graphs, 
of course, have the further stipulation 
that any two nodes (or hypernodes) may be 
linked by edges (themselves equipped 
with labels, label-namespaces, controlled 
vocabularies, and potentially constraints/axioms 
enforced by `q.Ontologies`/).  Formats such as 
`XML; and `JSON; which are more `q.syntactically` 
oriented tend to be hierarchical, in that 
any specific value in a `JSON; object or array may 
itself be another object/array (rather than atomic 
value) and likewise `XML; elements may have other 
elements as children.  By contrast, formats 
such as `RDF; and property graphs which are 
more `q.semantically` focused tend to be 
graph-like and encode semantic relations via 
edges across nodes (rather than hierarchical nesting).  
Hypergraphs potentially combine both styles of 
representation, with hypernodes containing 
nodes hierarchically `i.and also` edges 
between two (or two-or-more) nodes and/or hypernodes 
(the precise rules as to which constructions are 
possible will vary from one system to another, but 
these are reasonable approximations). 
`p`


`p.
Any representational system, as these examples point out, 
provides a range of parameters that 
can be pressed into service when formalizing a protocol 
for encoding specific kinds of data via structures 
conformant to the specific system.  More expressive 
systems have a wider arsenal of parameters; for 
instance, along the lines of the above gloss, property 
hypergraphs (models which either add hyperedges to property graphs or, 
equivalently, add properties to hypergraphs) 
are more expressive than either property 
graphs or document-style hierarchical trees 
alone, because properties-on-nodes (as in `XML; attributes), 
nested hierarchies (hypernodes containing child nodes akin 
to child `XML; elements), and inter-node connections 
(as in Semantic Web labeled edges) are all potential 
representational devices in the property-hypergraph context.  
One conclusion to be made here is that property-hypergraphs 
form a flexible general-purpose 
metamodel, but the relevant point for the 
moment is that expressivity can be `q.measured` via 
the range of distinct representational parameters afforded by 
the system, at least intuitively.
`p`


`p.
This intuition can be made more precise, insofar as 
I have deferred any rigorous definition for 
`q.representational parameters`/.  That is to say, for a 
reasonably systematic analysis of metamodels we should 
specify building-blocks of constructions 
recognized through any metamodel.  The overall 
concept may be clear enough %-- in general, 
the parameters of a modeling system are the full set 
of structural elements that might potentially 
be employed in fully describing any given 
structure covered by the system %-- but one would 
like a still tighter definition.  For this chapter, 
I approach this problem from the 
perspective of Virtual Machines.
`p`


`subsection.Virtual Machines in the Context of Data Metamodels 
and Database Engineering` 
`p.
The correlation between Virtual Machines and 
representational paradigms should be clear: suppose 
we take any structure instantiating a particular 
metamodel.  Presumably, such a structure 
can be assembled over multiple stages.  Insofar 
as node-hypernode inclusion is a constructional parameter, 
for instance, then a structure can be modified 
by a including a node within the scope of a hypernode.  
Similarly, insofar as inter-node relations (via directed 
edges or hyperedges) are significant constructions, 
then a structure may be modified by adding an edge 
between existing nodes.  In short, any structure 
can be derived from the modification of precursor 
structures.  The full set of structure-modifying 
operations available for a given representational 
paradigm can be enumerated as (at least on part of) 
the opset of a hypothetical (or realized) 
Virtual Machine.  As such, Virtual Machines 
provide a potential formalizing environment 
for analyzing data metamodels.  
`p`

`p.
Conversely, data-models can serve as a prompt for 
motivating the proper scope of a Virtual Machine.  
That is, `VM;s 
may be designed subject to requirements that 
they permit the accumulation of any data structure 
conformant to a given metamodel.  Similarly, `VM;s 
might be characterized in terms of how they support 
various `q.calling conventions`/, in the sense of 
protocols through which computational procedures 
delegate to other procedures (supplying inputs, 
reading outputs, spawning concurrent 
execution paths, and so forth).  This section's chapters
will focus on `VM;s based on hypergraph 
data models, employing such structures 
both from the perspective of data-representations 
and interlocking procedures (i.e., describing 
procedures in terms of sequences of 
calls to other procedures).   
`p`

`p.
Virtual Machines can be useful tools for studying software-interoperability 
insofar as both data-representations and communications protocols 
can be modeled in terms of `VM;s (at least as abstract summaries 
of working code; or, more ambitiously, application-networking 
frameworks can be provide actual `VM;s through which applications 
can route their networking logic, analogous to query languages 
as host-language-agnostic conduits for database access).  
As emphasized earlier, applications typically 
seek to `q.expose` functionality to external 
components.  In order to do so rigorously, 
it is necessary to stipulate preconditions 
on how functionality being externally invoked 
should be designated %-- for instance, if a Computer 
Vision application has multiple algorithms available 
for many processing tasks, external code needs to 
specify which implementation is being requested %-- 
and how input parameters (and then output results) 
should be encoded.  Applications can use 
`VM;s as a kind of neutral environment where 
third-party code can build up a representation 
of exposed-functionality invocations 
incrementally.  Indeed, many programs support 
scripting via languages such as Python; it 
is plausible to generalize this idea to 
`VM; platforms amenable to multiple scripting 
languages, so long as they can be compiled 
to the relevant `q.byte` code.  Alternatively, 
even if applications do not expose `VM;s 
to third parties directly, they could 
use `VM;-backed processes to process 
`API; requests: since `VM;-targeted code could be 
updated without recompiling the application, 
the `API; could then adapt to new networking 
situations.        
`p`


`p.
In this context `VM; models overlap with constructions pertaining to 
interoperability between applications and database engines.  
Consider the general setup of database systems: applications 
store data structures for future reuse by passing some 
(suitably encoded) serialization of the relevant information 
to a database, which arranges the data into a layout 
optimized for storage and retrieval/querying.  Typically the 
database will attempt not merely to preserve the presented 
data structure for future reconstruction, but will 
index or destructure it in such a manner that such specific 
data can be selected as matching a future query.     
`p`


`p.
At any moment in time, an application will be working with 
one or more data structure that might be called `q.live`/; they 
are directly implicated in the state of the application at 
that moment.  The current user (or a different user) might, 
accordingly, be interested in reconstructing that 
application-state (or some relevant subset thereof) at a 
future point in time; at which point database queries are 
typically necessary, because the relevant information is 
no longer in live memory.  To be sure, a database does 
not necessarily store `q.application state` as such 
%-- although developers can potentially 
create `q.application state objects` and persist 
those so that users can resume prior sessions %-- but 
a typical rationale for persistent data storage 
in the first place is functionality supporting 
users' desire to resume prior work, return to 
previously-viewed files, and so forth.  The 
individual values stored in a database derive their 
significance from how they interconnect 
in users' experience in the context of any application.   
`p`


`p.
As a concrete example, suppose we are considering an application 
which (at least as one of its features, and in the context 
of particular `GUI; windows or components accessed through 
the software) supports viewing, tagging, and annotation 
`TwoD; images (e.g., photographs).  Imagine an 
image database allocated for documenting 
ecological and/or infrastructure damage 
from natural or man-made events, such as 
the 2022 Russian invasion of Ukraine, and perhaps 
setting the stage for reconstruction plans.  
A typical image for such an application might be a 
photograph of damaged building or facilities, 
or plots 
of land on which real estate will be rebuilt.  
Potentially,  
images would depict remnants of prior buildings that 
were destroyed, and/or could be annotated with 
data relevant to reconstruction designs 
(e.g., in recreating damaged neighborhoods 
a certain number of residential units might 
be targeted for each parcel of land or each block 
subject to redevelopment, perhaps optimized by 
models measuring the ideal urban density for 
that specific neighborhood based on environmental 
criteria, utility grids, public transit, and so forth).  
A typical session for such an software component 
might involve users viewing individual images, 
previewing image-series depicted via thumbnails, 
searching for images (based on criteria such as 
street address, city/district name, or perhaps 
`GIS; coordinates), switching between `TwoD; image 
and 3D street views, and %-- once in the context 
of a specific picture %-- viewing annotations 
and other associated data in tabular or 
otherwise structured forms (e.g., tables or key-value 
pairs displayed through independent `GUI; windows 
floating above the graphics viewport).  
`p`


`p.
Assuming such an application works with relatively 
large image-collections (enough to be impractical 
for users simply to browse images in a filesystem 
folder, say), functionality for finding and tracking 
images would need to be based on some 
systematical query capabilities, i.e., some 
form of image database (which need not imply 
that images themselves are stored as database 
`q.blobs` %-- binary large objects %-- but 
at least that image file paths, feature sets 
for retrieval/similarity searches, metadata 
and formatting details, etc., can be hosted 
in a database so that images can be selected 
inside large series by variegated query strategies).
Suppose an image depicts a city block where 
damaged buildings have to be replaced; data 
associated with the image could include 
estimates of the number of people who lived in 
that location prior to (for example) 
the Russia/Ukraine war; the number of 
residential units slated for redevelopment; 
cost estimates; links to public transit info, 
street views, data concerning utilities grid, 
etc.  Plausibly, such data would be held 
in a database and loaded alongside the image, 
or in response to user actions signaling an 
interest in the relevant data-points.  The 
database, in effect, is a means to an ends, 
whereas from a user's perspective the 
important detail is that the application 
can enter a state where multiple important 
data-points are visible side-by-side: users 
might view a photograph in one window juxtaposed 
with a window or windows showing civic/residential 
data.     
`p`


`p.
Continuing this specific (hypothetical) example, the 
envisaged scenario has image-viewport components 
serve as an entry-point for a diversity of 
civil/architectural information; presumably 
the specific kinds of data available will vary 
from one image to another, and users will 
signal through interactive `GUI; features 
their interest in accessing certain branches of 
the available data over others.  That is, assume 
there is not a fixed metadata/associated information 
package that automatically accompanies each image, 
but instead that data and images are linked on a 
dynamically changing case-by-case basis.  That setup 
would call for a coding strategy which works to 
organize the available information and 
user-interaction pragmatics coherently.  
The resulting software-design choices would, 
moreover, propagate to `GUI; and database designs 
as well.  Once some aggregate of data is identified 
as a coherent unit, this structural decision 
must be accounted for at the `GUI; level 
(insofar as users request `i.that specific` 
data from application-states where they are 
viewing an image carrying the appropriate 
information) and the database-integration level 
(`q.that specific` data has to be 
queried from the larger database context when needed).  
In other words, the interaction between `GUI;, database, and 
application logic is more complex than if each image were 
given a fixed set of data fields isolated from user pragmatics.
`p`

`subsection.GIS Databases and Digital Cartography`

`p.
This discussion has now touched on themes related 
to flexibly-typed database systems: the idea 
being that expressive database engines support 
`i.strongly typed` data (in the sense that 
all records have type attributions that 
offer guarantees about their internal 
structure, such as a specific set of 
defined fields) but also allow new types 
to be introduced into an active database.  
A good case-study of where such design 
is apropos is that of maintaining 
geospatial databases that track information 
associated with geographical coordinates 
%-- for example, roads, bridges, buildings, 
waterways, transportation infrastructure, 
or land-plots, but also any kind of scientific 
data (environmental, sociodemographic, etc.) 
that can be overlaid on a digital map.  
`lGIS; systems are typically divided into 
two distinct data categories: there are 
`q.basemaps` which represent the most 
common or generic types of `GIS; data 
(roads, buildings, and the like) that are 
then augmented with supplemental `q.data layers` 
that are narrower and more domain-specific 
(such as ecological data).  Digital cartography 
renders `i.basemap` visuals by 
subdividing geographic areas into relatively 
small segments (within a 256`times;256 area, for example)  
translating geospatial (typically latitude/longitude) 
coordinates to pixel-coordinates.  Digital maps 
are composed at multiple scales of resolution; 
in a common format, so-called `q.XYZ` tiles, 
the lowest zoom level produces a `q.map` of the whole 
world (basically an outline of the continents) 
whereas the highest level (around 20, or slightly less 
depending on the environment) is sufficiently 
detailed that maps can show the contours of 
individual buildings and street-intersections.  
In XYZ, each successive zoom level doubles 
the underlying magnification, so that 
each tile at one level splits into four 
tiles at the enxt level.
`p`


`p.
Software known as `q.tile renderers` and `q.tile servers` 
map latitude and longitude coordinates (or 
other `GIS; units, such as those of Marcatur projections) 
to tile-coordinates that include zoom level as 
one axis (e.g., the `q.z` in XYZ).  An XYZ triple 
designates a specific gegraphic area at a specific 
zoom level; individual latitude/longitude and Mercatur 
points can then be identified via fractions of the 
tile width and height.  Via such a mapping, locations 
of objects in a `GIS; database are converted 
to pixel-coordinates, so that features such as 
roads and building can be marked visually.  Tiles 
are rendered according to graphical rules called 
`q.styles`/, which stipulate details such as 
the colors that should be used to outline buildings 
or roadways, or the icons for points of 
interest (transit stops, historical sites, special-purpose buildings 
or areas such as schools, hospitals, parks, 
government offices, and so forth).  Tile-rendering 
requires some computational algorithms because 
streets/highways and other noteworthy spots need 
to be named or labeled, and the positioning 
of these identifiers (unlike the fixed latitude-longitude 
of the labeled locations) is indeterminate, so cartographic 
engines try to calculate how to position street-names 
(for example) so that this text does not intersect with 
other map data (such as roadway lines).  
`p`


`p.
The end result of a tile-rendering pipeline 
is a miniature map in the form of an `i.image`/, 
often in a format such as `PNG; equivalent to 
many photographs; a `GIS; application will 
form maps that users see by composing together 
multiple tiles.  This provides the `q.basemap` 
layer, representing a general-purpose 
view of a given geographic region.  On top of 
these base maps, applications will usually 
superimpose domain-specific data points 
(sometimes called `q.attribute` data) relevant 
in specific contexts: data layers might 
show locations where Ukrainian buildings or infrastructure 
was damaged in the 2022 war; or distributions 
of COVID-19 cases; or environmental hazard sites; 
or tax lots and zoning codes for architecture, 
real estate, urban planning, and 
property management; or sightings of specific plant or animal 
species, and so on.  In effect, whenever 
scientists or researchers have data sets indexed 
by geographic coordinates %-- epidemiological, 
ecological, sociodemographic %-- such information 
can potentially become a Data Layer which 
is visualized by superimposing special-purpose 
icons or colorations on a generic basemap.  
These extra layers can be added at different processing 
stages: for instance, they might be consumed by 
the tile servers themselves, as a post-processing 
step immediately after rendering basemap tiles; 
or they could by superimposed on basemaps 
by `GIS; front-ends,  
immediately prior to showing maps to users 
(in this case applications would typically 
download tiles and data layers separately, 
and merge them together at the last moment).   
`p`


`p.
I provide this digital-cartography overview mostly 
to mention certain details concerning 
`GIS; data systems: although there is a core 
dimension of familiar mappable elements 
(roadways, buildings, and so forth) with common 
presentation guidelines (formalized via tile-rendering 
styles), the space of information that 
could be added on base maps is open-ended.  
Any data set with latitude/longitude coordinates 
(or fields convertible to such coordinaets, such as 
street addresses) can be visualized against 
the backdrop of a `GIS; basemap.  If we consider 
`GIS; data to encompass common basemap info 
`i.together with` special-purpose supplemental 
layers, then `GIS; databases are a good 
example of `q.strong but flexible` typing: it is 
impossible for a `GIS; system to anticipate 
`i.a priori` the full range of data profiles 
evinced by objects visualized in a map 
context, within supplemental data layers.  
Every mappable object will have latitude/longitude 
coordinates (or a collection thereof, giving a 
geometric outline), but in addition objects will 
have other data-points as well, relevant to 
their specific domain (civil engineering, etc.) 
but opaque to mapping applictions themselves.  
In this sense `GIS; systems manage non-`GIS; 
data by tracking opaque objects without 
consuming them directly: it is 
up to individual applications to 
download data within supplemental 
layers and reconstruct the relevant 
domain-specific info, so that 
users can employ street maps as 
entry points for accessing 
information which is then visualized 
through other features in the 
application.  For example, urban planners 
taking on the responsibility of rebuilding 
Ukrainian cities might start with street 
maps showing sites of destroyed 
buildings and infrastructure, and 
then (typically by clicking on a map) 
transition to windows showing structured 
data about individual locations, such as 
the number of families formerly living in a 
damages residential complex, or details 
about utilities and water/gas/electricity 
grids, or estimates of environmental 
hazards (chemical leakages, say, or 
unexploded munitions) resulting from the 
conflict.  The point here is that 
objects containing such domain-specific 
data need to be packaged and stored 
in a `GIS; database even if they are 
not `GIS; data proper, and then 
correctly reconstructed and presented 
to users in conjunction with digital-cartography 
front-ends.  This data-management workflow 
is analogous to the case of routing data 
packages across third-party networks 
discussed above.
`p`




`p.

`p`


